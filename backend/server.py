from fastapi import FastAPI, APIRouter, Depends, HTTPException, status, UploadFile, File, Form, BackgroundTasks, Query, WebSocket, WebSocketDisconnect
from contextlib import asynccontextmanager
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from fastapi.responses import FileResponse, StreamingResponse
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from starlette.requests import Request # ì¶”ê°€
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging  # Keep for compatibility with existing modules
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timedelta
from passlib.context import CryptContext
from jose import JWTError, jwt
import re
import asyncio
import aiofiles
import io
import base64
from concurrent.futures import ThreadPoolExecutor
import json
import time  # Added for enhanced logging middleware

from cache_service import cache_service  # Import the instance directly

# Placeholder imports for missing models and functions
# These should be adjusted based on actual project structure
import models
from models import (  # Assuming a models.py or schemas.py
    Token, User, UserResponse, UserCreate, 
    SecretarySignupRequest, SecretaryApproval,
    UserInDB, # Assuming UserInDB might be used internally or by CRUD
    EvaluatorCreate, Project, ProjectCreate, Company, CompanyCreate,
    FileMetadata, EvaluationTemplateCreate, EvaluationTemplate,  # Added missing models
    AssignmentCreate, BatchAssignmentCreate, EvaluationScore, EvaluationSubmission,
    EvaluationSheet  # Added additional models
)
import security
from security import (
    create_access_token, 
    get_current_user, 
    get_password_hash, 
    verify_password, 
    check_admin_or_secretary, 
    get_current_user_optional,
    oauth2_scheme as security_oauth2_scheme, # Import with an alias if server.py defines its own
    imported_pwd_context, # Use the correctly named imported context
    generate_evaluator_credentials, # Add missing function import
)
from secure_file_endpoints import check_file_access_permission, log_file_access

# AI ê¸°ëŠ¥ ì„í¬íŠ¸
try:
    from ai_endpoints import ai_router
    from ai_admin_endpoints import ai_admin_router
    from ai_service_enhanced import enhanced_ai_service
    AI_ENABLED = True
    AI_ADMIN_ENABLED = True
except ImportError as e:
    AI_ENABLED = False
    AI_ADMIN_ENABLED = False
    print(f"âš ï¸ AI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
    print("AI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ë ¤ë©´ pip install openai anthropic google-generativeai cryptography ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# í–¥ìƒëœ ê¶Œí•œ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from enhanced_permissions import permission_checker
    from permission_admin_endpoints import permission_admin_router
    ENHANCED_PERMISSIONS_ENABLED = True
except ImportError as e:
    ENHANCED_PERMISSIONS_ENABLED = False
    print(f"âš ï¸ í–¥ìƒëœ ê¶Œí•œ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# í–¥ìƒëœ í…œí”Œë¦¿ ê´€ë¦¬ ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from template_endpoints import template_router
    ENHANCED_TEMPLATES_ENABLED = True
except ImportError as e:
    ENHANCED_TEMPLATES_ENABLED = False
    print(f"âš ï¸ í–¥ìƒëœ í…œí”Œë¦¿ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# ë³´ì•ˆ íŒŒì¼ ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
from secure_file_endpoints import secure_file_router
SECURE_FILE_ENABLED = True

# í‰ê°€í‘œ ì¶œë ¥ ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
try:
    from evaluation_print_endpoints import evaluation_print_router
    EVALUATION_PRINT_ENABLED = True
except ImportError as e:
    EVALUATION_PRINT_ENABLED = False
    print(f"âš ï¸ í‰ê°€í‘œ ì¶œë ¥ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# í–¥ìƒëœ í‰ê°€í‘œ ì¶œë ¥ ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
try:
    from enhanced_export_endpoints import enhanced_export_router
    ENHANCED_EXPORT_ENABLED = True
    print("í–¥ìƒëœ ë‚´ë³´ë‚´ê¸° ì‹œìŠ¤í…œì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    ENHANCED_EXPORT_ENABLED = False
    print(f"âš ï¸ í–¥ìƒëœ ë‚´ë³´ë‚´ê¸° ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# AI í‰ê°€ ì œì–´ ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
try:
    from ai_evaluation_control_endpoints import ai_evaluation_control_router
    AI_EVALUATION_CONTROL_ENABLED = True
except ImportError as e:
    AI_EVALUATION_CONTROL_ENABLED = False
    print(f"âš ï¸ AI í‰ê°€ ì œì–´ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# AI ëª¨ë¸ ì„¤ì • ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
try:
    from ai_model_settings_endpoints import ai_model_settings_router
    AI_MODEL_SETTINGS_ENABLED = True
    print("AI ëª¨ë¸ ì„¤ì • ì‹œìŠ¤í…œì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    AI_MODEL_SETTINGS_ENABLED = False
    print(f"âš ï¸ AI ëª¨ë¸ ì„¤ì • ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")

# ë°°í¬ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ ì„í¬íŠ¸
try:
    from deployment_api_endpoints import deployment_router
    DEPLOYMENT_MANAGER_ENABLED = True
except ImportError as e:
    DEPLOYMENT_MANAGER_ENABLED = False
    print(f"âš ï¸ ë°°í¬ ê´€ë¦¬ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
try:
    import middleware
    from middleware import (
        SecurityMiddleware, RequestValidationMiddleware, CORSSecurityMiddleware,
        IPWhitelistMiddleware, FileUploadSecurityMiddleware
    )
except ImportError:
    middleware = None
    print("Warning: Middleware module not found. Creating placeholder classes.")
# Import new comprehensive security systems
try:
    import security_monitoring
    from security_monitoring import (
        security_monitor, SecurityMiddleware as EnhancedSecurityMiddleware,
        SecurityEvent, SecurityEventType, SecuritySeverity
    )
except ImportError:
    security_monitoring = None
    print("Warning: Security monitoring module not found.")

try:
    import api_security
    from api_security import security_validator, ValidationConfig, SecurityLevel
except ImportError:
    api_security = None
    print("Warning: API security module not found.")

# Import Prometheus metrics and enhanced health monitoring
try:
    import prometheus_metrics
    from prometheus_metrics import setup_prometheus_metrics, get_prometheus_metrics
except ImportError:
    prometheus_metrics = None
    print("Warning: Prometheus metrics module not found.")

# try:
#     import enhanced_health_monitoring
#     from enhanced_health_monitoring import setup_health_monitor, health_router
# except ImportError:
#     enhanced_health_monitoring = None
#     print("Warning: Enhanced health monitoring module not found.")

# Import enhanced logging system
try:
    import enhanced_logging
    from enhanced_logging import (
        setup_logging, get_logger, RequestContext, log_async_performance,
        log_database_operation, log_security_event, log_startup_info, log_shutdown_info,
        request_id_context, user_id_context, session_id_context
    )
except ImportError:
    enhanced_logging = None
    import logging
    def get_logger(name):
        return logging.getLogger(name)
    print("Warning: Enhanced logging module not found. Using standard logging.")

# Import stub services for undefined functions
# try:
#     from stub_services import (
#         calculate_evaluation_scores,
#         notification_service,
#         exporter,
#         EvaluationItem,
#         update_project_statistics,
#         background_file_processing
#     )
#     print("Successfully imported stub services for undefined functions.")
# except ImportError:
#     print("Warning: stub_services.py not found. Some functions may be undefined.")

ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# Initialize enhanced logging system
setup_logging(
    service_name="online-evaluation-backend",
    log_level=os.getenv("LOG_LEVEL", "INFO").upper(),
    log_file="/app/logs/app.log"
)

# Get enhanced logger instance
logger = get_logger(__name__)

# MongoDB connection with connection pooling
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(
    mongo_url,
    maxPoolSize=100,  # Maximum connections in pool
    minPoolSize=10,   # Minimum connections in pool
    maxIdleTimeMS=30000,  # Close connections after 30 seconds of inactivity
    connectTimeoutMS=20000,  # 20 second connection timeout
    serverSelectionTimeoutMS=20000  # 20 second server selection timeout
)
db = client[os.environ['DB_NAME']]

# AI ê´€ë ¨ ì»¬ë ‰ì…˜ ì„¤ì •
ai_providers_collection = db.ai_providers
ai_models_collection = db.ai_models
ai_jobs_collection = db.ai_analysis_jobs

# í–¥ìƒëœ AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
if AI_ENABLED:
    try:
        enhanced_ai_service._setup_database(client)
        logger.info("í–¥ìƒëœ AI ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"AI ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# í–¥ìƒëœ ê¶Œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
if ENHANCED_PERMISSIONS_ENABLED:
    try:
        permission_checker.db = db
        permission_checker.user_permissions_collection = db.user_permissions
        permission_checker.project_members_collection = db.project_members
        logger.info("í–¥ìƒëœ ê¶Œí•œ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ê¶Œí•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")

# Thread pool for CPU-intensive tasks
executor = ThreadPoolExecutor(max_workers=4)

# Initialize health monitor
# health_monitor = HealthMonitor(client) # This line is causing the NameError
# The HealthMonitor class definition or import is missing.
# For now, we will comment this out to allow the server to start.
# It should be properly defined or imported from enhanced_health_monitoring.py later.

# JWT settings - Now using security config with lazy initialization
from security import get_security_config
config = get_security_config()
SECRET_KEY = config.JWT_SECRET_KEY
ALGORITHM = config.JWT_ALGORITHM
ACCESS_TOKEN_EXPIRE_MINUTES = config.JWT_ACCESS_TOKEN_EXPIRE_MINUTES

# Password context - Now using enhanced security
pwd_context = imported_pwd_context # Correctly assign the imported instance
# oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/auth/login") # This can be removed if security_oauth2_scheme from security.py is used

# API Router ì •ì˜
api_router = APIRouter()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan event handler"""
    # Startup
    with RequestContext(request_id="startup", user_id="system"):
        log_startup_info()
        logger.info("FastAPI application startup initiated", extra={
            'custom_event': 'application_startup',
            'custom_environment': os.getenv("ENVIRONMENT", "development"),
            'custom_mongodb_url': mongo_url.split('@')[-1] if '@' in mongo_url else 'localhost',  # Hide credentials
            'custom_services': ['mongodb', 'redis', 'prometheus']
        })
        
        # Initialize the database connection in security module
        from security import set_database
        set_database(db)
        logger.info("Database connection initialized in security module", extra={
            'custom_service': 'security_db_init',
            'custom_status': 'completed'
        })
        
        # Initialize Redis client for performance monitoring
        try:
            await cache_service.connect()
            if cache_service.redis_client:
                await cache_service.redis_client.ping()
                logger.info("Redis connection verified", extra={
                    'custom_service': 'redis_init',
                    'custom_status': 'connected'
                })
            else:
                logger.warning("Redis client not available", extra={
                    'custom_service': 'redis_init',
                    'custom_status': 'unavailable'
                })
        except Exception as e:
            logger.error("Redis connection failed", extra={
                'custom_service': 'redis_init',
                'custom_status': 'failed',
                'custom_error_type': type(e).__name__
            })
        
        # Log enhanced security systems status
        logger.info("Security systems initialized", extra={
            'custom_security_systems': ['rate_limiting', 'input_validation', 'threat_detection'],
            'custom_security_status': 'active'
        })
        
        log_startup_info()
        logger.info("FastAPI application startup completed", extra={
            'custom_event': 'application_startup',
            'custom_environment': os.getenv("ENVIRONMENT", "development"),
            'custom_mongodb_url': mongo_url.split('@')[-1] if '@' in mongo_url else 'localhost'  # Hide credentials
        })
    
    yield  # Application runs here
    
    # Shutdown
    logger.info("FastAPI application shutdown initiated", extra={
        'custom_event': 'application_shutdown'
    })
    log_shutdown_info()

# Create the main app with enhanced security configuration
# Always enable /docs and /redoc for easier debugging
app = FastAPI(
    title=config.API_TITLE if hasattr(config, 'API_TITLE') else "ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ",
    version="2.0.0", # Or "1.0.0" if that was the intended version from the previous edit
    description="Secure Online Evaluation System with comprehensive authentication and authorization",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Request logging middleware for context tracking
@app.middleware("http")
async def logging_middleware(request: Request, call_next):
    """Middleware to track request context and log HTTP requests"""
    import uuid
    from urllib.parse import urlparse
    
    # Generate request ID
    request_id = str(uuid.uuid4())
    
    # Extract user information from request if available
    user_id = None
    session_id = None
    
    # Try to extract user info from Authorization header
    authorization = request.headers.get("authorization")
    if authorization and authorization.startswith("Bearer "):
        try:
            # Decode JWT to get user info (simplified)
            token = authorization.split(" ")[1]
            # Note: In a real scenario, you'd decode the JWT here
            # For now, we'll set it when we have user context
            pass
        except Exception:
            pass
    
    # Extract session info from cookies if available
    session_id = request.cookies.get("session_id")
    
    # Set up request context
    with RequestContext(request_id=request_id, user_id=user_id, session_id=session_id):
        start_time = time.time()
        
        # Log incoming request
        logger.info(f"Incoming request: {request.method} {request.url.path}", extra={
            'custom_http_method': request.method,
            'custom_http_uri': str(request.url.path),
            'custom_http_user_agent': request.headers.get('user-agent', ''),
            'custom_http_remote_ip': request.client.host if request.client else 'unknown'
        })
        
        try:
            # Process request
            response = await call_next(request)
            
            # Calculate duration
            duration = (time.time() - start_time) * 1000
            
            # Log response
            logger.info(f"Request completed: {request.method} {request.url.path}", extra={
                'custom_http_method': request.method,
                'custom_http_uri': str(request.url.path),
                'custom_http_status_code': response.status_code,
                'custom_http_duration': duration
            })
            
            # Add request ID to response headers
            response.headers["X-Request-ID"] = request_id
            
            return response
            
        except Exception as e:
            # Calculate duration for error case
            duration = (time.time() - start_time) * 1000
            
            # Log error
            logger.error(f"Request failed: {request.method} {request.url.path}: {str(e)}", extra={
                'custom_http_method': request.method,
                'custom_http_uri': str(request.url.path),
                'custom_http_duration': duration,
                'custom_error_type': type(e).__name__
            })
            
            raise

# Enhanced logging configuration - replaced with enhanced logging system
# The enhanced logging system is now initialized above with structured logging
# log_level = os.getenv("LOG_LEVEL", "INFO")
# logging.basicConfig(
#     level=getattr(logging, log_level),
#     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
# )
# logger = logging.getLogger(__name__)

# Add security middleware stack - Enhanced with comprehensive monitoring
app.add_middleware(EnhancedSecurityMiddleware, security_monitor)
app.add_middleware(SecurityMiddleware, enable_rate_limiting=True, enable_security_headers=True)
app.add_middleware(RequestValidationMiddleware)
app.add_middleware(FileUploadSecurityMiddleware)
app.add_middleware(IPWhitelistMiddleware, admin_paths=["/api/admin", "/api/init"])

# Enhanced CORS configuration using security config
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.CORS_ORIGINS,
    allow_credentials=config.CORS_ALLOW_CREDENTIALS,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["Authorization", "Content-Type", "X-Requested-With"],
    expose_headers=["X-Total-Count"],
    max_age=3600,
)

# Initialize enhanced health monitoring
try:
    from enhanced_health_monitoring import setup_health_monitor
    health_monitor_instance = setup_health_monitor(client, cache_service.redis_client)
except ImportError:
    print("Warning: Enhanced health monitoring not available")
    health_monitor_instance = None

# Initialize Prometheus metrics (optional)
try:
    from prometheus_metrics import setup_prometheus_metrics
    prometheus_metrics = setup_prometheus_metrics(app, cache_service.redis_client, client)
except (ImportError, AttributeError):
    print("Warning: Prometheus metrics not available")
    prometheus_metrics = None


# api_router registration moved to centralized location to avoid duplicates

# Import and include core API routers
try:
    from evaluation_api import router as evaluation_router
    app.include_router(evaluation_router, prefix="/api", tags=["Evaluations"])
    print("í‰ê°€ API ë¼ìš°í„°ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âš ï¸ í‰ê°€ API ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("âš ï¸ evaluation_api.py íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
print("ëª¨ë“  ë¼ìš°í„°ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# Removed duplicate get_dashboard_statistics - better implementation exists at line 3019

# íŒŒì¼ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ - REMOVED to avoid conflict with secure_file_router
# Files are now handled by secure_file_endpoints.py with prefix /api/files

# ì‚¬ìš©ì ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤
@api_router.get("/users")
async def get_users(current_user: User = Depends(get_current_user)):
    """ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
    check_admin_or_secretary(current_user)
    try:
        users = await db.users.find({}).to_list(1000)
        user_responses = []
        for user in users:
            # Convert _id to id for UserResponse
            user_data = user.copy()
            user_data["id"] = str(user_data.pop("_id"))
            user_responses.append(UserResponse(**user_data))
        return user_responses
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# Removed duplicate get_projects - better implementation exists at line 1082

# Removed duplicate get_companies - better implementation exists at line 1113

# í…œí”Œë¦¿ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤ - REMOVED to avoid conflict with template_router
# Templates are now handled by template_endpoints.py with prefix /api/templates

# ê´€ë¦¬ì ì „ìš© ì—”ë“œí¬ì¸íŠ¸ë“¤
@api_router.get("/admin/users")
async def get_admin_users(current_user: User = Depends(get_current_user)):
    """ê´€ë¦¬ììš© ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
    # ê´€ë¦¬ì ê¶Œí•œ ì²´í¬
    if current_user.role != "admin":
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    try:
        users = await db.users.find({}).to_list(1000)
        user_responses = []
        for user in users:
            # Convert _id to id for UserResponse
            user_data = user.copy()
            user_data["id"] = str(user_data.pop("_id"))
            user_responses.append(UserResponse(**user_data))
        return user_responses
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ê´€ë¦¬ì ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# í‰ê°€ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸ë“¤ì€ evaluation_print_endpoints.pyì—ì„œ ì²˜ë¦¬

# ê¸°ë³¸ API ë¼ìš°í„°ì— ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤ ì¶”ê°€
# ì¸ì¦ ì—”ë“œí¬ì¸íŠ¸ë“¤ì€ ì´ë¯¸ server.pyì— ì •ì˜ë˜ì–´ ìˆìŒ

# Health check endpoint (no prefix)
@app.get("/health", operation_id="health_check", summary="Health Check", tags=["Health"])
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # MongoDB ì—°ê²° í™•ì¸
        await client.admin.command('ping')
        
        # Redis ì—°ê²° í™•ì¸ (cache_serviceë¥¼ í†µí•´)
        redis_status = "healthy"
        try:
            await cache_service.ping()
        except Exception:
            redis_status = "unhealthy"
        
        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "mongodb": "healthy",
                "redis": redis_status,
                "api": "healthy"
            },
            "version": "2.0.0"
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")

# Database status endpoint
@app.get("/db-status", operation_id="database_status")
async def database_status():
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # MongoDB ìƒíƒœ í™•ì¸
        mongodb_status = await client.admin.command('ping')
        
        # Redis ìƒíƒœ í™•ì¸
        redis_status = "healthy"
        redis_info = {}
        try:
            await cache_service.ping()
            redis_info = {"status": "connected", "ping": "pong"}
        except Exception as e:
            redis_status = "unhealthy"
            redis_info = {"status": "disconnected", "error": str(e)}
        
        # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
        db_stats = await db.command("dbStats")
        
        return {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "databases": {
                "mongodb": {
                    "status": "healthy",
                    "ping": mongodb_status,
                    "stats": {
                        "collections": db_stats.get("collections", 0),
                        "dataSize": db_stats.get("dataSize", 0),
                        "storageSize": db_stats.get("storageSize", 0)
                    }
                },
                "redis": {
                    "status": redis_status,
                    "info": redis_info
                }
            }
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Database unhealthy: {str(e)}")

# API Root endpoint
@app.get("/", operation_id="root_endpoint")
async def root():
    """API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "message": "ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ API",
        "version": "2.0.0",
        "status": "running",
        "timestamp": datetime.utcnow().isoformat(),
        "docs": "/docs",
        "health": "/health",
        "db_status": "/db-status"
    }

# Initialize FastAPI app
# TODO: Consider making title and version configurable
# if os.getenv("ENVIRONMENT") == "development":
#     logger.info("Running in development mode, enabling docs and redoc.")
#     app = FastAPI(
#         title="Online Evaluation System API",
#         version="1.0.0",
#         description="API for managing online evaluations, users, and submissions.",
#         docs_url="/docs",
#         redoc_url="/redoc"
#     )
# else:
#     logger.info("Running in non-development mode, disabling docs and redoc.")
#     app = FastAPI(
#         title="Online Evaluation System API",
#         version="1.0.0",
#         description="API for managing online evaluations, users, and submissions.",
#         docs_url=None, # Disable docs
#         redoc_url=None # Disable redoc
#     )

# Enable /docs and /redoc for easier debugging, regardless of ENVIRONMENT
# We can make this conditional again later.
# app = FastAPI(
#     title="Online Evaluation System API",
#     version="1.0.0",
#     description="API for managing online evaluations, users, and submissions.",
#     docs_url="/docs",
#     redoc_url="/redoc"
# )


# Database connection
# client = None # This is initialized globally earlier with AsyncIOMotorClient
# db = None # This is initialized globally earlier

# Connect to MongoDB
async def connect_to_mongo():
    global client, db # client and db are already global and initialized
    # The logic here re-initializes client and db, which might be redundant
    # or could conflict if not handled carefully with the initial global setup.
    # For now, assuming the initial global setup is sufficient.
    # If this function is critical for re-connection or specific setup, it needs review.
    # try:
    #     # Create MongoDB client
    #     client = AsyncIOMotorClient(
    #         mongo_url,
    #         maxPoolSize=100,
    #         minPoolSize=10,
    #         maxIdleTimeMS=30000,
    #         connectTimeoutMS=20000,
    #         serverSelectionTimeoutMS=20000
    #     )
    #     db = client[os.environ['DB_NAME']]
    #     await client.admin.command('ping')
    #     logger.info("Successfully connected to MongoDB (via connect_to_mongo).")
    # except Exception as e:
    #     logger.error(f"Error connecting to MongoDB (via connect_to_mongo): {e}")
    #     raise
    pass # Assuming global client/db are sufficient

# API Router setup (ê¸°ì¡´ api_routerì— ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€)
# api_routerëŠ” ì´ë¯¸ 252ë²ˆì§¸ ì¤„ì—ì„œ ì •ì˜ë¨ - ì¬ì •ì˜í•˜ì§€ ì•ŠìŒ

# Include security and user routes
# Assuming user_routes and other specific route modules are defined elsewhere
# and imported if necessary. For now, focusing on the auth route.

# Authentication routes
@api_router.get("/auth/test")
async def test_auth_router():
    print("ğŸ” TEST: Auth router is working!")
    return {"status": "AUTH_ROUTER_WORKING", "timestamp": "2025-06-22"}

@api_router.post("/auth/login-test")
async def test_login(username: str, password: str):
    print(f"ğŸ” TEST LOGIN: {username} / {password}")
    
    # Direct database check
    user_data = await db.users.find_one({"login_id": username})
    print(f"ğŸ” TEST USER: found={user_data is not None}")
    
    if user_data and username == "admin" and password == "admin123":
        print("ğŸ” TEST: Hardcoded success!")
        return {"status": "SUCCESS", "user": "admin"}
    else:
        print("ğŸ” TEST: Failed!")
        return {"status": "FAILED", "reason": "Invalid credentials"}

# DISABLED: Conflicting login endpoint - using clean_login_endpoint instead
# @api_router.post("/auth/login", response_model=Token)
# async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()):
#     # Set user context for failed login tracking
#     try:
#         user_id_context.set(form_data.username)
#     except:
#         pass
#     
#     print(f"ğŸ” LOGIN: user={form_data.username}, pwd_len={len(form_data.password)}")
#     user_data = await db.users.find_one({"login_id": form_data.username})
#     print(f"ğŸ” USER: found={user_data is not None}")
#     if user_data:
#         pwd_valid = verify_password(form_data.password, user_data["password_hash"])
#         print(f"ğŸ” PWD: valid={pwd_valid}")
#     if not user_data or not verify_password(form_data.password, user_data["password_hash"]):
#         raise HTTPException(
#             status_code=status.HTTP_401_UNAUTHORIZED,
#             detail="ì•„ì´ë”” ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤",
#             headers={"WWW-Authenticate": "Bearer"},
#         )
#     
#     # Convert MongoDB document to User object
#     user = User.from_mongo(user_data)
#     if not user:
#         raise HTTPException(
#             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
#             detail="ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜"
#         )
#     
#     # Update last login time using _id
#     await db.users.update_one(
#         {"_id": user_data["_id"]},
#         {"$set": {"last_login": datetime.utcnow()}}
#     )
#     
#     # Set user context for successful login
#     user_id_context.set(user.id)
#     
#     access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
#     access_token = create_access_token(
#         data={"sub": user.id}, expires_delta=access_token_expires
#     )
#     user_response = UserResponse(**user.dict())
#     return {"access_token": access_token, "token_type": "bearer", "user": user_response}

@api_router.post("/auth/secretary-signup")
async def secretary_signup(request: SecretarySignupRequest):
    """ê°„ì‚¬ íšŒì›ê°€ì… ì‹ ì²­"""
    # ì¤‘ë³µ ì´ë©”ì¼ ë˜ëŠ” ì „í™”ë²ˆí˜¸ ì²´í¬
    existing_user = await db.users.find_one({
        "$or": [
            {"email": request.email},
            {"phone": request.phone}
        ]
    })
    
    if existing_user:
        raise HTTPException(
            status_code=400,
            detail="ì´ë¯¸ ë“±ë¡ëœ ì´ë©”ì¼ ë˜ëŠ” ì „í™”ë²ˆí˜¸ì…ë‹ˆë‹¤"
        )
    
    # ì´ë¯¸ ì‹ ì²­í•œ ë‚´ì—­ì´ ìˆëŠ”ì§€ ì²´í¬
    existing_request = await db.secretary_requests.find_one({
        "$or": [
            {"email": request.email},
            {"phone": request.phone}
        ]
    })
    
    if existing_request:
        raise HTTPException(
            status_code=400,
            detail="ì´ë¯¸ ì‹ ì²­í•œ ë‚´ì—­ì´ ìˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ì„ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."
        )
    
    # ì‹ ì²­ ë‚´ì—­ ì €ì¥
    approval_request = SecretaryApproval(
        name=request.name,
        phone=request.phone,
        email=request.email,
        reason=request.reason
    )
    await db.secretary_requests.insert_one(approval_request.dict())
    return {
        "message": "ê°„ì‚¬ íšŒì›ê°€ì… ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ì ìŠ¹ì¸ í›„ ë¡œê·¸ì¸ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
        "request_id": approval_request.id
    }

@api_router.get("/admin/secretary-requests")
async def get_secretary_requests(current_user: User = Depends(get_current_user)):
    """ê°„ì‚¬ ì‹ ì²­ ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬ìë§Œ)"""
    if current_user.role != "admin":
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    requests = await db.secretary_requests.find({"status": "pending"}).to_list(None)
    return requests

@api_router.post("/admin/secretary-requests/{request_id}/approve")
async def approve_secretary_request(
    request_id: str, 
    current_user: User = Depends(get_current_user)
):
    """ê°„ì‚¬ ì‹ ì²­ ìŠ¹ì¸ (ê´€ë¦¬ìë§Œ)"""
    if current_user.role != "admin":
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # ì‹ ì²­ ë‚´ì—­ ì°¾ê¸°
    request_data = await db.secretary_requests.find_one({"id": request_id})
    if not request_data:
        raise HTTPException(status_code=404, detail="ì‹ ì²­ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    if request_data["status"] != "pending":
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì²˜ë¦¬ëœ ì‹ ì²­ì…ë‹ˆë‹¤")
    
    # ì‚¬ìš©ì ê³„ì • ìƒì„±
    user_id = str(uuid.uuid4())
    login_id = request_data["name"]  # ì´ë¦„ì„ ë¡œê·¸ì¸ IDë¡œ ì‚¬ìš©
    password_hash = get_password_hash(request_data["phone"].replace("-", ""))  # ì „í™”ë²ˆí˜¸ë¥¼ ë¹„ë°€ë²ˆí˜¸ë¡œ ì‚¬ìš©
    
    user_data = {
        "id": user_id,
        "login_id": login_id,
        "password_hash": password_hash,
        "user_name": request_data["name"],
        "email": request_data["email"],
        "phone": request_data["phone"],
        "role": "secretary",
        "created_at": datetime.utcnow(),
        "is_active": True
    }
    
    # ì‚¬ìš©ì ìƒì„±
    await db.users.insert_one(user_data)
    
    # ì‹ ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.secretary_requests.update_one(
        {"id": request_id},
        {
            "$set": {
                "status": "approved",
                "reviewed_at": datetime.utcnow(),
                "reviewed_by": current_user.id
            }
        }
    )
    
    return {
        "message": "ê°„ì‚¬ ê³„ì •ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
        "login_id": login_id,
        "user_id": user_id
    }

@api_router.post("/admin/secretary-requests/{request_id}/reject")
async def reject_secretary_request(
    request_id: str,
    current_user: User = Depends(get_current_user)
):
    """ê°„ì‚¬ ì‹ ì²­ ê±°ë¶€ (ê´€ë¦¬ìë§Œ)"""
    if current_user.role != "admin":
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥í•©ë‹ˆë‹¤")
    
    # ì‹ ì²­ ë‚´ì—­ ì°¾ê¸°
    request_data = await db.secretary_requests.find_one({"id": request_id})
    if not request_data:
        raise HTTPException(status_code=404, detail="ì‹ ì²­ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    if request_data["status"] != "pending":
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì²˜ë¦¬ëœ ì‹ ì²­ì…ë‹ˆë‹¤")
    
    # ì‹ ì²­ ìƒíƒœ ì—…ë°ì´íŠ¸
    await db.secretary_requests.update_one(
        {"id": request_id},
        {
            "$set": {
                "status": "rejected",
                "reviewed_at": datetime.utcnow(),
                "reviewed_by": current_user.id
            }
        }
    )
    
    return {"message": "ê°„ì‚¬ ì‹ ì²­ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤"}

@api_router.get("/auth/me", response_model=UserResponse)
async def read_users_me(current_user: User = Depends(get_current_user)):
    return UserResponse(**current_user.dict())

# User management routes
@api_router.post("/users", response_model=UserResponse)
async def create_user(user_data: UserCreate, current_user: User = Depends(get_current_user)):
    check_admin_or_secretary(current_user)
    
    # Check if user already exists
    existing_user = await db.users.find_one({"login_id": user_data.login_id})
    if existing_user:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì•„ì´ë””ì…ë‹ˆë‹¤")
    
    hashed_password = get_password_hash(user_data.password)
    user = User(
        login_id=user_data.login_id,
        password_hash=hashed_password,
        user_name=user_data.user_name,
        email=user_data.email,
        phone=user_data.phone,
        role=user_data.role
    )
    
    await db.users.insert_one(user.dict())
    return UserResponse(**user.dict())

# Get all users (for admin and verification)
# REMOVED: Duplicate /users endpoint that was causing authentication conflicts

# Get all tests/evaluations (basic list)
@api_router.get("/tests")
async def get_tests(current_user: Optional[User] = Depends(get_current_user_optional)):
    """í‰ê°€/í…ŒìŠ¤íŠ¸ ëª©ë¡ ì¡°íšŒ (ì¸ì¦ëœ ì‚¬ìš©ììš© ë˜ëŠ” ê²€ì¦ìš©)"""
    # ê²€ì¦ìš©ìœ¼ë¡œ í˜¸ì¶œëœ ê²½ìš° ê°„ë‹¨í•œ ì •ë³´ë§Œ ë°˜í™˜
    if not current_user:
        projects_count = await db.projects.count_documents({})
        sample_projects = await db.projects.find({}, {"name": 1, "description": 1, "created_at": 1}).limit(5).to_list(5)
        return {
            "status": "success",
            "total_projects": projects_count,
            "sample_projects": sample_projects,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    # Get evaluation sheets based on user role
    if current_user.role == "evaluator":
        # Evaluators can only see their assigned evaluations
        sheets = await db.evaluation_sheets.find({"evaluator_id": current_user.id}).to_list(1000)
    else:
        # Admin and secretary can see all evaluations
        sheets = await db.evaluation_sheets.find({}).to_list(1000)
    
    # Return simplified test/evaluation data
    tests = []
    for sheet in sheets:
        tests.append({
            "id": sheet.get("id"),
            "company_id": sheet.get("company_id"),
            "template_id": sheet.get("template_id"),
            "status": sheet.get("status", "assigned"),
            "created_at": sheet.get("created_at"),
            "submitted_at": sheet.get("submitted_at"),
            "total_score": sheet.get("total_score", 0)
        })
    
    return tests

@api_router.post("/evaluators")
async def create_evaluator(evaluator_data: EvaluatorCreate, current_user: User = Depends(get_current_user)):
    check_admin_or_secretary(current_user)
    
    # Generate credentials
    login_id, password = generate_evaluator_credentials(evaluator_data.user_name, evaluator_data.phone)
    
    # Check if user already exists
    existing_user = await db.users.find_one({"login_id": login_id})
    if existing_user:
        raise HTTPException(status_code=400, detail="ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í‰ê°€ìœ„ì›ì…ë‹ˆë‹¤ (ì´ë¦„/ì „í™”ë²ˆí˜¸ ì¤‘ë³µ)")
    
    hashed_password = get_password_hash(password)
    user = User(
        login_id=login_id,
        password_hash=hashed_password,
        user_name=evaluator_data.user_name,
        email=evaluator_data.email,
        phone=evaluator_data.phone,
        role="evaluator"
    )
    
    await db.users.insert_one(user.dict())
    response = UserResponse(**user.dict())
    
    # Return with generated credentials for display
    return {
        **response.dict(), 
        "generated_login_id": login_id, 
        "generated_password": password,
        "message": f"í‰ê°€ìœ„ì›ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ì´ë””: {login_id}, ë¹„ë°€ë²ˆí˜¸: {password}"
    }

@api_router.get("/evaluators", response_model=List[UserResponse])
async def get_evaluators(current_user: User = Depends(get_current_user)):
    check_admin_or_secretary(current_user)
    
    evaluators = await db.users.find({"role": "evaluator", "is_active": True}).to_list(1000)
    return [UserResponse(**evaluator) for evaluator in evaluators]

# Batch operations
@api_router.post("/evaluators/batch")
async def create_evaluators_batch(
    evaluators_data: List[EvaluatorCreate], 
    current_user: User = Depends(get_current_user)
):
    check_admin_or_secretary(current_user)
    
    created_evaluators = []
    errors = []
    
    # Process in parallel using asyncio.gather
    async def create_single_evaluator(evaluator_data):
        try:
            login_id, password = generate_evaluator_credentials(evaluator_data.user_name, evaluator_data.phone)
            
            existing_user = await db.users.find_one({"login_id": login_id})
            if existing_user:
                return {"error": f"ì´ë¯¸ ì¡´ì¬í•˜ëŠ” í‰ê°€ìœ„ì›: {evaluator_data.user_name}"}
            
            hashed_password = get_password_hash(password)
            user = User(
                login_id=login_id,
                password_hash=hashed_password,
                user_name=evaluator_data.user_name,
                email=evaluator_data.email,
                phone=evaluator_data.phone,
                role="evaluator"
            )
            
            await db.users.insert_one(user.dict())
            return {
                "user": UserResponse(**user.dict()).dict(),
                "credentials": {"login_id": login_id, "password": password}
            }
        except Exception as e:
            return {"error": f"í‰ê°€ìœ„ì› ìƒì„± ì‹¤íŒ¨ ({evaluator_data.user_name}): {str(e)}"}
    
    # Execute all operations concurrently
    results = await asyncio.gather(*[create_single_evaluator(evaluator) for evaluator in evaluators_data])
    
    for result in results:
        if "error" in result:
            errors.append(result["error"])
        else:
            created_evaluators.append(result)
    
    return {
        "created_count": len(created_evaluators),
        "error_count": len(errors),
        "created_evaluators": created_evaluators,
        "errors": errors
    }

# Project routes
@api_router.get("/projects", response_model=List[Project])
async def get_projects(current_user: User = Depends(get_current_user)):
    projects = await db.projects.find({"is_active": True}).to_list(1000)
    return [Project(**project) for project in projects]

@api_router.post("/projects", response_model=Project)
@log_async_performance("create_project")
@log_database_operation("projects")
async def create_project(
    project_data: ProjectCreate, 
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user)
):
    check_admin_or_secretary(current_user)
    
    deadline_dt = datetime.fromisoformat(project_data.deadline.replace('Z', '+00:00'))
    project = Project(
        name=project_data.name,
        description=project_data.description,
        deadline=deadline_dt,
        created_by=current_user.id
    )
    
    await db.projects.insert_one(project.dict())
    
    # Background task to initialize project statistics
    background_tasks.add_task(update_project_statistics, project.id)
    
    return project

# Company routes with enhanced file handling
@api_router.get("/companies", response_model=List[Company])
async def get_companies(project_id: Optional[str] = None, current_user: User = Depends(get_current_user)):
    query = {}
    if project_id:
        query["project_id"] = project_id
    
    companies = await db.companies.find(query).to_list(1000)
    return [Company(**company) for company in companies]

@api_router.post("/companies", response_model=Company)
@log_async_performance("create_company")
@log_database_operation("companies")
async def create_company(
    company_data: CompanyCreate, 
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user)
):
    check_admin_or_secretary(current_user)
    
    company = Company(**company_data.dict())
    await db.companies.insert_one(company.dict())
    
    # Update project statistics in background
    background_tasks.add_task(update_project_statistics, company.project_id)
    
    return company

# Enhanced file upload with async processing and comprehensive error handling
@api_router.post("/upload")
@log_async_performance("file_upload")
@log_database_operation("file_metadata")
async def upload_file(
    background_tasks: BackgroundTasks,
    company_id: str = Form(...),
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    try:
        check_admin_or_secretary(current_user)
        
        # Input validation
        if not file.filename:
            raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        if not company_id or not company_id.strip():
            raise HTTPException(status_code=400, detail="íšŒì‚¬ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # File size validation (50MB limit)
        MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
        content = await file.read()
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(status_code=413, detail="íŒŒì¼ í¬ê¸°ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        
        if len(content) == 0:
            raise HTTPException(status_code=400, detail="ë¹ˆ íŒŒì¼ì€ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # File type validation
        ALLOWED_EXTENSIONS = {'.pdf', '.doc', '.docx', '.xls', '.xlsx', '.txt', '.png', '.jpg', '.jpeg'}
        file_extension = Path(file.filename).suffix.lower()
        if file_extension not in ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=415, 
                detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í—ˆìš©ëœ í˜•ì‹: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # Check if company exists
        company = await db.companies.find_one({"id": company_id})
        if not company:
            raise HTTPException(status_code=404, detail="ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íšŒì‚¬ì…ë‹ˆë‹¤.")
        
        # Create uploads directory if it doesn't exist
        upload_dir = Path("uploads")
        try:
            upload_dir.mkdir(exist_ok=True)
        except OSError as e:
            logging.error(f"Failed to create uploads directory: {e}")
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ ê³µê°„ì„ ì¤€ë¹„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # Generate unique filename with proper encoding
        file_id = str(uuid.uuid4())
        # Sanitize filename to prevent directory traversal
        safe_filename = re.sub(r'[^\w\s.-]', '', file.filename)
        unique_filename = f"{company_id}_{file_id}_{safe_filename}"
        file_path = upload_dir / unique_filename
        
        # Save file asynchronously with error handling
        try:
            async with aiofiles.open(file_path, 'wb') as f:
                await f.write(content)
        except OSError as e:
            logging.error(f"Failed to save file {file_path}: {e}")
            raise HTTPException(status_code=500, detail="íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # Create file metadata
        try:
            file_metadata = FileMetadata(
                id=file_id,
                filename=unique_filename,
                original_filename=file.filename,
                file_path=str(file_path),
                file_size=len(content),
                file_type=file.content_type,
                uploaded_by=current_user.id,
                company_id=company_id
            )
            
            # Save metadata to database with error handling
            await db.file_metadata.insert_one(file_metadata.dict())
            
            # Update company's files list
            await db.companies.update_one(
                {"id": company_id},
                {"$push": {"files": file_metadata.dict()}}
            )
            
        except Exception as e:
            # If database operation fails, clean up the uploaded file
            try:
                if file_path.exists():
                    file_path.unlink()
            except OSError:
                pass  # File cleanup failed, but don't raise another exception
            
            logging.error(f"Database operation failed for file upload: {e}")
            raise HTTPException(status_code=500, detail="íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # Add background task for file processing
        try:
            # background_tasks.add_task(background_file_processing, str(file_path), file_id)
            pass
        except Exception as e:
            logging.warning(f"Failed to add background task for file processing: {e}")
            # Don't fail the upload just because background task failed
        
        return {
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "file_id": file_id,
            "filename": file.filename,
            "file_size": len(content),
            "file_type": file.content_type
        }
        
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        logging.error(f"Unexpected error in file upload: {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# File management endpoints
@api_router.get("/files", response_model=List[Dict[str, Any]])
async def get_files(
    company_id: Optional[str] = Query(None, description="íšŒì‚¬ IDë¡œ í•„í„°ë§"),
    project_id: Optional[str] = Query(None, description="í”„ë¡œì íŠ¸ IDë¡œ í•„í„°ë§"),
    current_user: User = Depends(get_current_user)
):
    """íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    filter_criteria = {}
    
    if company_id:
        filter_criteria["company_id"] = company_id
    
    # í”„ë¡œì íŠ¸ë³„ í•„í„°ë§ì„ ìœ„í•´ íšŒì‚¬ë¥¼ í†µí•´ ê°„ì ‘ ì¡°íšŒ
    if project_id:
        companies = await db.companies.find({"project_id": project_id}).to_list(1000)
        company_ids = [str(company["_id"]) for company in companies]
        if company_ids:
            filter_criteria["company_id"] = {"$in": company_ids}
        else:
            return []  # í”„ë¡œì íŠ¸ì— íšŒì‚¬ê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
    
    files = await db.file_metadata.find(filter_criteria).to_list(1000)
    
    # íŒŒì¼ ì •ë³´ì™€ íšŒì‚¬ ì •ë³´ë¥¼ ì¡°í•©í•˜ì—¬ ë°˜í™˜
    result = []
    for file_doc in files:
        company = await db.companies.find_one({"_id": file_doc["company_id"]})
        file_info = {
            "id": file_doc["id"],
            "filename": file_doc["original_filename"],
            "file_size": file_doc["file_size"],
            "file_type": file_doc["file_type"],
            "uploaded_at": file_doc["uploaded_at"],
            "uploaded_by": file_doc["uploaded_by"],
            "company_id": file_doc["company_id"],
            "company_name": company["name"] if company else "ì•Œ ìˆ˜ ì—†ìŒ"
        }
        result.append(file_info)
    
    return result

@api_router.get("/files/{file_id}")
async def get_file(
    file_id: str, 
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """ë³´ì•ˆ ê°•í™”ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ - ê¶Œí•œ ê²€ì‚¬ ë° ì ‘ê·¼ ë¡œê·¸ í¬í•¨"""
    try:
        # ì…ë ¥ ê²€ì¦
        if not file_id or not file_id.strip():
            raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê¶Œí•œ ê²€ì‚¬
        if not await check_file_access_permission(current_user, file_id):
            # ê¶Œí•œ ì—†ëŠ” ì ‘ê·¼ ì‹œë„ ë¡œê·¸ ê¸°ë¡
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="download_denied",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ"
            )
            raise HTTPException(status_code=403, detail="ì´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        file_metadata = await db.file_metadata.find_one({"id": file_id})
        if not file_metadata:
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="download_failed",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            )
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ê²½ë¡œ ë³´ì•ˆ ê²€ì¦
        file_path_str = file_metadata["file_path"]
        if ".." in file_path_str or file_path_str.startswith("/"):
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="download_blocked",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œ"
            )
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.")
        
        file_path = Path(file_path_str)
        if not file_path.exists():
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="download_failed",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ"
            )
            raise HTTPException(status_code=404, detail="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # ì„±ê³µì ì¸ ë‹¤ìš´ë¡œë“œ ë¡œê·¸ ê¸°ë¡
        await log_file_access(
            user_id=current_user.id,
            file_id=file_id,
            action="download_success",
            ip_address=request.client.host,
            user_agent=request.headers.get("user-agent"),
            success=True
        )
        
        # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„± (í•œê¸€ íŒŒì¼ëª… ì²˜ë¦¬)
        safe_filename = file_metadata["original_filename"]
        try:
            # UTF-8ë¡œ ì¸ì½”ë”© ê°€ëŠ¥í•œì§€ í™•ì¸
            safe_filename.encode('utf-8')
        except UnicodeEncodeError:
            # ì¸ì½”ë”© ì‹¤íŒ¨ ì‹œ íŒŒì¼ IDë¡œ ëŒ€ì²´
            extension = Path(safe_filename).suffix
            safe_filename = f"file_{file_id}{extension}"
        
        return FileResponse(
            path=file_path,
            filename=safe_filename,
            media_type=file_metadata.get("file_type", "application/octet-stream"),
            headers={
                "X-User": current_user.user_name,
                "X-Download-Time": datetime.utcnow().isoformat(),
                "X-File-ID": file_id
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë¡œê·¸ ê¸°ë¡
        await log_file_access(
            user_id=current_user.id if 'current_user' in locals() else "unknown",
            file_id=file_id,
            action="download_error",
            ip_address=request.client.host if 'request' in locals() else "unknown",
            user_agent=request.headers.get("user-agent") if 'request' in locals() else "unknown",
            success=False,
            error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
        )
        logging.error(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ ê´€ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@api_router.get("/files/access-logs")
async def get_file_access_logs(
    file_id: Optional[str] = Query(None, description="íŠ¹ì • íŒŒì¼ì˜ ë¡œê·¸ë§Œ ì¡°íšŒ"),
    user_id: Optional[str] = Query(None, description="íŠ¹ì • ì‚¬ìš©ìì˜ ë¡œê·¸ë§Œ ì¡°íšŒ"),
    action: Optional[str] = Query(None, description="íŠ¹ì • ì•¡ì…˜ì˜ ë¡œê·¸ë§Œ ì¡°íšŒ"),
    start_date: Optional[str] = Query(None, description="ì‹œì‘ ë‚ ì§œ (ISO í˜•ì‹)"),
    end_date: Optional[str] = Query(None, description="ì¢…ë£Œ ë‚ ì§œ (ISO í˜•ì‹)"),
    limit: int = Query(100, description="ì¡°íšŒí•  ë¡œê·¸ ìˆ˜ ì œí•œ"),
    current_user: User = Depends(get_current_user)
):
    """íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ ì¡°íšŒ (ê´€ë¦¬ì ë° ê°„ì‚¬ë§Œ ì ‘ê·¼ ê°€ëŠ¥)"""
    try:
        # ê´€ë¦¬ì ë° ê°„ì‚¬ë§Œ ì ‘ê·¼ ê°€ëŠ¥
        if current_user.role not in ["admin", "secretary"]:
            raise HTTPException(status_code=403, detail="íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ë¥¼ ì¡°íšŒí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¿¼ë¦¬ ì¡°ê±´ êµ¬ì„±
        query = {}
        if file_id:
            query["file_id"] = file_id
        if user_id:
            query["user_id"] = user_id
        if action:
            query["action"] = action
        
        # ë‚ ì§œ ë²”ìœ„ í•„í„°
        if start_date or end_date:
            date_filter = {}
            if start_date:
                try:
                    date_filter["$gte"] = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                except ValueError:
                    raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì‹œì‘ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤.")
            if end_date:
                try:
                    date_filter["$lte"] = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
                except ValueError:
                    raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì¢…ë£Œ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤.")
            query["access_time"] = date_filter
        
        # ë¡œê·¸ ì¡°íšŒ (ìµœì‹ ìˆœ ì •ë ¬)
        logs = await db.file_access_logs.find(query).sort("access_time", -1).limit(limit).to_list(limit)
        
        # ì‚¬ìš©ì ì •ë³´ ë° íŒŒì¼ ì •ë³´ ë³´ê°•
        enhanced_logs = []
        for log in logs:
            # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
            user_info = await db.users.find_one({"id": log["user_id"]})
            user_name = user_info.get("user_name", "ì•Œ ìˆ˜ ì—†ìŒ") if user_info else "ì•Œ ìˆ˜ ì—†ìŒ"
            
            # íŒŒì¼ ì •ë³´ ì¡°íšŒ
            file_info = await db.file_metadata.find_one({"id": log["file_id"]})
            file_name = file_info.get("original_filename", "ì•Œ ìˆ˜ ì—†ìŒ") if file_info else "ì•Œ ìˆ˜ ì—†ìŒ"
            
            enhanced_log = {
                **log,
                "user_name": user_name,
                "file_name": file_name,
                "access_time_formatted": log["access_time"].strftime("%Y-%m-%d %H:%M:%S")
            }
            enhanced_logs.append(enhanced_log)
        
        return {
            "logs": enhanced_logs,
            "total_count": len(enhanced_logs),
            "query_params": {
                "file_id": file_id,
                "user_id": user_id,
                "action": action,
                "start_date": start_date,
                "end_date": end_date,
                "limit": limit
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì ‘ê·¼ ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@api_router.get("/files/security-analytics")
async def get_file_security_analytics(
    current_user: User = Depends(get_current_user)
):
    """íŒŒì¼ ë³´ì•ˆ ë¶„ì„ ì •ë³´ (ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥)"""
    try:
        # ê´€ë¦¬ìë§Œ ì ‘ê·¼ ê°€ëŠ¥
        if current_user.role != "admin":
            raise HTTPException(status_code=403, detail="ë³´ì•ˆ ë¶„ì„ ì •ë³´ë¥¼ ì¡°íšŒí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìµœê·¼ 24ì‹œê°„ í†µê³„
        yesterday = datetime.utcnow() - timedelta(days=1)
        
        # íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í†µê³„ ì§‘ê³„
        pipeline = [
            {"$match": {"access_time": {"$gte": yesterday}}},
            {"$group": {
                "_id": "$action",
                "count": {"$sum": 1},
                "success_count": {"$sum": {"$cond": [{"$eq": ["$success", True]}, 1, 0]}},
                "failure_count": {"$sum": {"$cond": [{"$eq": ["$success", False]}, 1, 0]}}
            }}
        ]
        
        action_stats = await db.file_access_logs.aggregate(pipeline).to_list(None)
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í™œë™ ê°ì§€
        suspicious_pipeline = [
            {"$match": {
                "access_time": {"$gte": yesterday},
                "$or": [
                    {"success": False},
                    {"action": {"$in": ["download_denied", "preview_denied", "download_blocked", "preview_blocked"]}}
                ]
            }},
            {"$group": {
                "_id": "$user_id",
                "failed_attempts": {"$sum": 1},
                "actions": {"$push": "$action"}
            }},
            {"$match": {"failed_attempts": {"$gte": 3}}}  # 3íšŒ ì´ìƒ ì‹¤íŒ¨í•œ ì‚¬ìš©ì
        ]
        
        suspicious_users = await db.file_access_logs.aggregate(suspicious_pipeline).to_list(None)
        
        # ê°€ì¥ ë§ì´ ì ‘ê·¼ëœ íŒŒì¼
        popular_files_pipeline = [
            {"$match": {
                "access_time": {"$gte": yesterday},
                "success": True,
                "action": {"$in": ["download_success", "preview_success"]}
            }},
            {"$group": {
                "_id": "$file_id",
                "access_count": {"$sum": 1}
            }},
            {"$sort": {"access_count": -1}},
            {"$limit": 10}
        ]
        
        popular_files = await db.file_access_logs.aggregate(popular_files_pipeline).to_list(None)
        
        # íŒŒì¼ ì •ë³´ ë³´ê°•
        for file_stat in popular_files:
            file_info = await db.file_metadata.find_one({"id": file_stat["_id"]})
            file_stat["file_name"] = file_info.get("original_filename", "ì•Œ ìˆ˜ ì—†ìŒ") if file_info else "ì•Œ ìˆ˜ ì—†ìŒ"
        
        # ì‚¬ìš©ì ì •ë³´ ë³´ê°•
        for user_stat in suspicious_users:
            user_info = await db.users.find_one({"id": user_stat["_id"]})
            user_stat["user_name"] = user_info.get("user_name", "ì•Œ ìˆ˜ ì—†ìŒ") if user_info else "ì•Œ ìˆ˜ ì—†ìŒ"
        
        return {
            "period": "ìµœê·¼ 24ì‹œê°„",
            "action_statistics": action_stats,
            "suspicious_activities": suspicious_users,
            "popular_files": popular_files,
            "security_recommendations": [
                "ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í™œë™ì´ ê°ì§€ëœ ì‚¬ìš©ìì˜ ê³„ì •ì„ ì ê²€í•˜ì„¸ìš”.",
                "ìì£¼ ì ‘ê·¼ë˜ëŠ” íŒŒì¼ì˜ ë³´ì•ˆ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.",
                "ì‹¤íŒ¨í•œ ì ‘ê·¼ ì‹œë„ê°€ ë§ì€ íŒŒì¼ì˜ ê¶Œí•œ ì„¤ì •ì„ ì¬ê²€í† í•˜ì„¸ìš”."
            ] if suspicious_users else ["í˜„ì¬ íŠ¹ë³„í•œ ë³´ì•ˆ ìœ„í—˜ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"íŒŒì¼ ë³´ì•ˆ ë¶„ì„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ë³´ì•ˆ ë¶„ì„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")



@api_router.get("/files/{file_id}/preview")
async def preview_file(
    file_id: str, 
    request: Request,
    current_user: User = Depends(get_current_user)
):
    """ë³´ì•ˆ ê°•í™”ëœ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° - ê¶Œí•œ ê²€ì‚¬ ë° ì ‘ê·¼ ë¡œê·¸ í¬í•¨"""
    try:
        # ì…ë ¥ ê²€ì¦
        if not file_id or not file_id.strip():
            raise HTTPException(status_code=400, detail="íŒŒì¼ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ê¶Œí•œ ê²€ì‚¬
        if not await check_file_access_permission(current_user, file_id):
            # ê¶Œí•œ ì—†ëŠ” ì ‘ê·¼ ì‹œë„ ë¡œê·¸ ê¸°ë¡
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="preview_denied",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ"
            )
            raise HTTPException(status_code=403, detail="ì´ íŒŒì¼ì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        file_metadata = await db.file_metadata.find_one({"id": file_id})
        if not file_metadata:
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="preview_failed",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
            )
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ê²½ë¡œ ë³´ì•ˆ ê²€ì¦
        file_path_str = file_metadata["file_path"]
        if ".." in file_path_str or file_path_str.startswith("/"):
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="preview_blocked",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œ"
            )
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.")
        
        file_path = Path(file_path_str)
        if not file_path.exists():
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="preview_failed",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ"
            )
            raise HTTPException(status_code=404, detail="íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ í¬ê¸° ê²€ì‚¬ (ëŒ€ìš©ëŸ‰ íŒŒì¼ ë°©ì§€)
        MAX_PREVIEW_SIZE = 100 * 1024 * 1024  # 100MB
        if file_metadata.get("file_size", 0) > MAX_PREVIEW_SIZE:
            await log_file_access(
                user_id=current_user.id,
                file_id=file_id,
                action="preview_blocked",
                ip_address=request.client.host,
                user_agent=request.headers.get("user-agent"),
                success=False,
                error_message="íŒŒì¼ í¬ê¸° ì œí•œ ì´ˆê³¼"
            )
            raise HTTPException(status_code=413, detail="íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ë¯¸ë¦¬ë³´ê¸°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # PDF íŒŒì¼ ì²˜ë¦¬
        if file_metadata["file_type"] == "application/pdf":
            try:
                async with aiofiles.open(file_path, 'rb') as f:
                    content = await f.read()
                    base64_content = base64.b64encode(content).decode('utf-8')
                    
                    # ì„±ê³µì ì¸ ì ‘ê·¼ ë¡œê·¸ ê¸°ë¡
                    await log_file_access(
                        user_id=current_user.id,
                        file_id=file_id,
                        action="preview_success",
                        ip_address=request.client.host,
                        user_agent=request.headers.get("user-agent"),
                        success=True
                    )
                    
                    return {
                        "content": base64_content,
                        "type": "pdf",
                        "filename": file_metadata["original_filename"],
                        "watermark": {
                            "user": current_user.user_name,
                            "date": datetime.utcnow().strftime("%Y-%m-%d %H:%M"),
                            "ip": request.client.host
                        }
                    }
            except Exception as e:
                await log_file_access(
                    user_id=current_user.id,
                    file_id=file_id,
                    action="preview_error",
                    ip_address=request.client.host,
                    user_agent=request.headers.get("user-agent"),
                    success=False,
                    error_message=f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"
                )
                raise HTTPException(status_code=500, detail="íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê¸°íƒ€ íŒŒì¼ ì²˜ë¦¬
        await log_file_access(
            user_id=current_user.id,
            file_id=file_id,
            action="metadata_access",
            ip_address=request.client.host,
            user_agent=request.headers.get("user-agent"),
            success=True
        )
        
        return {
            "type": "other",
            "filename": file_metadata["original_filename"],
            "size": file_metadata["file_size"],
            "file_type": file_metadata["file_type"],
            "download_url": f"/api/files/{file_id}",
            "watermark": {
                "user": current_user.user_name,
                "date": datetime.utcnow().strftime("%Y-%m-%d %H:%M"),
                "ip": request.client.host
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë¡œê·¸ ê¸°ë¡
        await log_file_access(
            user_id=current_user.id if 'current_user' in locals() else "unknown",
            file_id=file_id,
            action="preview_error",
            ip_address=request.client.host if 'request' in locals() else "unknown",
            user_agent=request.headers.get("user-agent") if 'request' in locals() else "unknown",
            success=False,
            error_message=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
        )
        logging.error(f"íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ë¯¸ë¦¬ë³´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# Enhanced assignment system
@api_router.post("/assignments")
async def create_assignments(
    assignment_data: AssignmentCreate, 
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user)
):
    check_admin_or_secretary(current_user)
    
    deadline = None
    if assignment_data.deadline:
        deadline = datetime.fromisoformat(assignment_data.deadline.replace('Z', '+00:00'))
    
    created_sheets = []
    
    # Create evaluation sheets for each evaluator-company combination
    tasks = []
    for evaluator_id in assignment_data.evaluator_ids:
        for company_id in assignment_data.company_ids:
            tasks.append(create_single_assignment(evaluator_id, company_id, assignment_data.template_id, deadline))
      # Execute assignments concurrently
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"Assignment creation failed: {result}", extra={
                'custom_operation': 'assignment_creation',
                'custom_error_type': type(result).__name__
            })
        elif result:
            created_sheets.append(result)
    
    # Update project statistics in background
    if created_sheets:
        company_data = await db.companies.find_one({"id": assignment_data.company_ids[0]})
        if company_data:
            background_tasks.add_task(update_project_statistics, company_data["project_id"])
    
    return {"message": f"{len(created_sheets)}ê°œì˜ í‰ê°€ê°€ í• ë‹¹ë˜ì—ˆìŠµë‹ˆë‹¤", "count": len(created_sheets)}

async def create_single_assignment(evaluator_id: str, company_id: str, template_id: str, deadline: datetime):
    """Helper function to create a single assignment"""
    try:
        # Get company to find project_id
        company_data = await db.companies.find_one({"id": company_id})
        if not company_data:
            return None
            
        # Check if assignment already exists
        existing_sheet = await db.evaluation_sheets.find_one({
            "evaluator_id": evaluator_id,
            "company_id": company_id,
            "template_id": template_id
        })
        
        if not existing_sheet:
            sheet = EvaluationSheet(
                evaluator_id=evaluator_id,
                company_id=company_id,
                project_id=company_data["project_id"],
                template_id=template_id,
                status="draft",
                deadline=deadline            )
            
            await db.evaluation_sheets.insert_one(sheet.dict())
            return sheet
    except Exception as e:
        logger.error(f"Failed to create assignment: {e}", extra={
            'custom_operation': 'create_single_assignment',
            'custom_evaluator_id': evaluator_id,
            'custom_company_id': company_id,
            'custom_template_id': template_id,
            'custom_error_type': type(e).__name__
        })
        return None

@api_router.post("/assignments/batch")
async def create_batch_assignments(
    batch_data: BatchAssignmentCreate,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user)
):
    check_admin_or_secretary(current_user)
    
    total_created = 0
    
    # Process all assignments concurrently
    tasks = []
    for assignment in batch_data.assignments:
        tasks.append(create_assignments(assignment, background_tasks, current_user))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for result in results:
        if isinstance(result, Exception):
            logger.error(f"Batch assignment failed: {result}", extra={
                'custom_operation': 'batch_assignment',
                'custom_error_type': type(result).__name__
            })
        else:
            total_created += result.get("count", 0)
    
    return {"message": f"ì´ {total_created}ê°œì˜ í‰ê°€ê°€ ì¼ê´„ í• ë‹¹ë˜ì—ˆìŠµë‹ˆë‹¤", "total_count": total_created}

# Enhanced evaluation system
@api_router.get("/evaluation/{sheet_id}")
async def get_evaluation_sheet(sheet_id: str, current_user: User = Depends(get_current_user)):
    sheet_data = await db.evaluation_sheets.find_one({"id": sheet_id})
    if not sheet_data:
        raise HTTPException(status_code=404, detail="í‰ê°€ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    sheet = EvaluationSheet(**sheet_data)
    
    # Check permissions
    if current_user.role == "evaluator" and sheet.evaluator_id != current_user.id:
        raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
    
    # Get related data concurrently
    company_task = db.companies.find_one({"id": sheet.company_id})
    project_task = db.projects.find_one({"id": sheet.project_id})
    template_task = db.evaluation_templates.find_one({"id": sheet.template_id})
    scores_task = db.evaluation_scores.find({"sheet_id": sheet_id}).to_list(1000)
    
    company_data, project_data, template_data, scores = await asyncio.gather(
        company_task, project_task, template_task, scores_task
    )
    
    return {
        "sheet": sheet,
        "company": Company(**company_data) if company_data else None,
        "project": Project(**project_data) if project_data else None,
        "template": EvaluationTemplate(**template_data) if template_data else None,
        "scores": [EvaluationScore(**score) for score in scores]
    }

@api_router.post("/evaluation/submit")
@log_async_performance("submit_evaluation")
@log_database_operation("evaluation_sheets")
async def submit_evaluation(
    submission: EvaluationSubmission, 
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user)
):
    sheet_data = await db.evaluation_sheets.find_one({"id": submission.sheet_id})
    if not sheet_data:
        raise HTTPException(status_code=404, detail="í‰ê°€ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    sheet = EvaluationSheet(**sheet_data)
    
    # Check permissions
    if current_user.role == "evaluator" and sheet.evaluator_id != current_user.id:
        raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
    
    # Calculate scores
    total_score, weighted_score = await calculate_evaluation_scores(submission.sheet_id, submission.scores)
    
    # Delete existing scores and save new ones concurrently
    delete_task = db.evaluation_scores.delete_many({"sheet_id": submission.sheet_id})
    
    # Prepare new scores
    new_scores = []
    for score_data in submission.scores:
        score = EvaluationScore(
            sheet_id=submission.sheet_id,
            item_id=score_data["item_id"],
            score=score_data["score"],
            opinion=score_data.get("opinion", "")
        )
        new_scores.append(score.dict())
    
    # Execute operations
    await delete_task
    if new_scores:
        await db.evaluation_scores.insert_many(new_scores)    # Update sheet status
    await db.evaluation_sheets.update_one(
        {"id": submission.sheet_id},
        {"$set": {
            "status": "submitted",
            "submitted_at": datetime.utcnow(),
            "last_modified": datetime.utcnow(),
            "total_score": total_score,
            "weighted_score": weighted_score
        }}
    )
    
    # Invalidate cache for the evaluator
    await cache_service.invalidate_user_cache(current_user.id)
    
    # Send real-time notification
    evaluation_data = {
        "sheet_id": submission.sheet_id,
        "project_id": sheet.project_id,
        "total_score": total_score,
        "weighted_score": weighted_score,
        "evaluator_name": current_user.user_name
    }
    
    # Notify the evaluator
    await notification_service.send_evaluation_complete_notification(
        current_user.id, 
        evaluation_data
    )
    
    # Notify project room members (admins, secretaries)
    await notification_service.send_project_update_notification(
        sheet.project_id,
        {
            "title": "í‰ê°€ ì™„ë£Œ",
            "message": f"{current_user.user_name}ë‹˜ì´ í‰ê°€ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤",
            "type": "evaluation_submitted",
            "data": evaluation_data
        }
    )
    
    # Update project statistics in background
    background_tasks.add_task(update_project_statistics, sheet.project_id)
    
    return {"message": "í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤", "total_score": total_score, "weighted_score": weighted_score}

@api_router.post("/evaluation/save")
async def save_evaluation(submission: EvaluationSubmission, current_user: User = Depends(get_current_user)):
    sheet_data = await db.evaluation_sheets.find_one({"id": submission.sheet_id})
    if not sheet_data:
        raise HTTPException(status_code=404, detail="í‰ê°€ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    sheet = EvaluationSheet(**sheet_data)
    
    # Check permissions
    if current_user.role == "evaluator" and sheet.evaluator_id != current_user.id:
        raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
    
    # Delete existing scores and save new ones
    await db.evaluation_scores.delete_many({"sheet_id": submission.sheet_id})
    
    # Save new scores
    new_scores = []
    for score_data in submission.scores:
        score = EvaluationScore(
            sheet_id=submission.sheet_id,
            item_id=score_data["item_id"],
            score=score_data["score"],
            opinion=score_data.get("opinion", "")
        )
        new_scores.append(score.dict())
    
    if new_scores:
        await db.evaluation_scores.insert_many(new_scores)
    
    # Update last modified time
    await db.evaluation_sheets.update_one(
        {"id": submission.sheet_id},
        {"$set": {"last_modified": datetime.utcnow()}}
    )
    
    return {"message": "í‰ê°€ê°€ ì„ì‹œì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"}

# Enhanced dashboard routes
@api_router.get("/dashboard/evaluator")
async def get_evaluator_dashboard(current_user: User = Depends(get_current_user)):
    if current_user.role != "evaluator":
        raise HTTPException(status_code=403, detail="í‰ê°€ìœ„ì›ë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    # Try to get cached dashboard data
    cached_data = await cache_service.get_cached_dashboard_data(current_user.id)
    if cached_data:
        logger.info(f"ğŸš€ Returning cached dashboard data for user {current_user.id}")
        return cached_data
    
    # Get assigned evaluation sheets
    sheets = await db.evaluation_sheets.find({"evaluator_id": current_user.id}).to_list(1000)
    
    # Get related data for all sheets concurrently
    tasks = []
    for sheet_data in sheets:
        sheet = EvaluationSheet(**sheet_data)
        company_task = db.companies.find_one({"id": sheet.company_id})
        project_task = db.projects.find_one({"id": sheet.project_id})
        template_task = db.evaluation_templates.find_one({"id": sheet.template_id})
        tasks.extend([company_task, project_task, template_task])
    
    if tasks:
        results = await asyncio.gather(*tasks)
        # Reorganize results into groups of 3 (company, project, template)
        result_groups = [results[i:i+3] for i in range(0, len(results), 3)]
    else:
        result_groups = []
    
    # Build response
    response = []
    for i, sheet_data in enumerate(sheets):
        sheet = EvaluationSheet(**sheet_data)
        if i < len(result_groups):
            company_data, project_data, template_data = result_groups[i]
            if company_data and project_data and template_data:
                response.append({
                    "sheet": sheet,
                    "company": Company(**company_data),
                    "project": Project(**project_data),
                    "template": EvaluationTemplate(**template_data)
                })
    
    # Cache the dashboard data for 5 minutes
    await cache_service.cache_dashboard_data(current_user.id, response, ttl=300)
    
    return response

@api_router.get("/dashboard/admin")
async def get_admin_dashboard(current_user: User = Depends(get_current_user)):
    if current_user.role not in ["admin", "secretary"]:
        raise HTTPException(status_code=403, detail="ê´€ë¦¬ì ë˜ëŠ” ê°„ì‚¬ë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
    
    # Get all statistics concurrently
    stats_tasks = [
        db.projects.count_documents({"is_active": True}),
        db.companies.count_documents({}),
        db.users.count_documents({"role": "evaluator", "is_active": True}),
        db.evaluation_sheets.count_documents({}),
        db.evaluation_sheets.count_documents({"status": "submitted"}),
        db.projects.find({"is_active": True}).sort("created_at", -1).limit(5).to_list(5)
    ]
    
    projects_count, companies_count, evaluators_count, total_sheets, completed_sheets, recent_projects = await asyncio.gather(*stats_tasks)
    
    return {
        "stats": {
            "projects": projects_count,
            "companies": companies_count,
            "evaluators": evaluators_count,
            "total_evaluations": total_sheets,
            "completed_evaluations": completed_sheets,
            "completion_rate": round((completed_sheets / total_sheets * 100) if total_sheets > 0 else 0, 1)
        },
        "recent_projects": [Project(**project) for project in recent_projects]
    }

# Analytics and reporting
@api_router.get("/analytics/project/{project_id}")
async def get_project_analytics(project_id: str, current_user: User = Depends(get_current_user)):
    check_admin_or_secretary(current_user)
    
    # Get project analytics concurrently
    tasks = [
        db.evaluation_sheets.find({"project_id": project_id, "status": "submitted"}).to_list(1000),
        db.companies.find({"project_id": project_id}).to_list(1000),
        db.evaluation_templates.find({"project_id": project_id}).to_list(1000)
    ]
    
    sheets, companies, templates = await asyncio.gather(*tasks)
    
    # Calculate analytics
    total_evaluations = len(sheets)
    companies_evaluated = len(set(sheet["company_id"] for sheet in sheets))
    
    # Score analytics
    avg_scores = {}
    if sheets:
        for sheet in sheets:
            if sheet.get("total_score"):
                template_name = next((t["name"] for t in templates if t["id"] == sheet["template_id"]), "Unknown")
                if template_name not in avg_scores:
                    avg_scores[template_name] = []
                avg_scores[template_name].append(sheet["total_score"])
    
    for template_name in avg_scores:
        scores = avg_scores[template_name]
        avg_scores[template_name] = {
            "average": sum(scores) / len(scores),
            "min": min(scores),
            "max": max(scores),
            "count": len(scores)
        }
    
    return {
        "project_id": project_id,
        "total_companies": len(companies),
        "companies_evaluated": companies_evaluated,
        "total_evaluations": total_evaluations,
        "completion_rate": round((companies_evaluated / len(companies) * 100) if companies else 0, 1),
        "score_analytics": avg_scores
    }

# Export routes for comprehensive evaluation reports
@api_router.get("/evaluations/{evaluation_id}/export")
async def export_single_evaluation(
    evaluation_id: str,
    format: str = Query(..., pattern="^(pdf|excel)$", description="Export format: pdf or excel"),
    current_user: User = Depends(get_current_user)
):
    """ë‹¨ì¼ í‰ê°€ ë°ì´í„°ë¥¼ PDF ë˜ëŠ” Excelë¡œ ì¶”ì¶œ"""
    check_admin_or_secretary(current_user)
    
    try:
        # Get evaluation sheet data
        sheet_data = await db.evaluation_sheets.find_one({"id": evaluation_id})
        if not sheet_data:
            raise HTTPException(status_code=404, detail="í‰ê°€ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        sheet = EvaluationSheet(**sheet_data)
        
        # Only export submitted evaluations
        if sheet.status != "submitted":
            raise HTTPException(status_code=400, detail="ì œì¶œëœ í‰ê°€ë§Œ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        # Get related data concurrently
        company_task = db.companies.find_one({"id": sheet.company_id})
        project_task = db.projects.find_one({"id": sheet.project_id})
        template_task = db.evaluation_templates.find_one({"id": sheet.template_id})
        scores_task = db.evaluation_scores.find({"sheet_id": evaluation_id}).to_list(1000)
        evaluator_task = db.users.find_one({"id": sheet.evaluator_id})
        
        company_data, project_data, template_data, scores, evaluator_data = await asyncio.gather(
            company_task, project_task, template_task, scores_task, evaluator_task
        )
        
        if not all([company_data, project_data, template_data, evaluator_data]):
            raise HTTPException(status_code=404, detail="ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # Prepare evaluation data
        evaluation_data = {
            "sheet": sheet.dict(),
            "company": company_data,
            "project": project_data,
            "template": template_data,
            "scores": [{"item_id": s["item_id"], "score": s["score"], "opinion": s["opinion"]} for s in scores],
            "evaluator": evaluator_data
        }
        
        # Generate filename
        submitted_date = sheet.submitted_at or datetime.utcnow()
        filename = exporter.generate_filename(
            project_data["name"],
            company_data["name"],
            submitted_date,
            format
        )
        
        # Export based on format
        if format == "pdf":
            buffer = await exporter.export_single_evaluation_pdf(evaluation_data)
            media_type = "application/pdf"
        else:  # excel
            buffer = await exporter.export_single_evaluation_excel(evaluation_data)
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        
        return StreamingResponse(
            io.BytesIO(buffer.read()),
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename*=UTF-8''{filename}"}
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Export error: {str(e)}", extra={
                'custom_operation': 'export_evaluation',
                'custom_error_type': type(e).__name__
            })
        raise HTTPException(status_code=500, detail="íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@api_router.post("/evaluations/bulk-export")
async def export_bulk_evaluations(
    export_request: dict,
    current_user: User = Depends(get_current_user)
):
    """ì—¬ëŸ¬ í‰ê°€ ë°ì´í„°ë¥¼ ì¼ê´„ ì¶”ì¶œ"""
    check_admin_or_secretary(current_user)
    
    try:
        project_id = export_request.get("project_id")
        template_id = export_request.get("template_id")
        format_type = export_request.get("format", "excel")
        export_type = export_request.get("export_type", "separate")  # separate, combined
        
        if not project_id:
            raise HTTPException(status_code=400, detail="í”„ë¡œì íŠ¸ IDê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # Build query for submitted evaluations
        query = {
            "project_id": project_id,
            "status": "submitted"
        }
        
        if template_id:
            query["template_id"] = template_id
        
        # Get evaluation sheets
        sheets = await db.evaluation_sheets.find(query).to_list(1000)
        
        if not sheets:
            raise HTTPException(status_code=404, detail="ì¶”ì¶œí•  í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # Get all related data
        evaluation_data_list = []
        for sheet_data in sheets:
            sheet = EvaluationSheet(**sheet_data)
            
            # Get related data concurrently
            company_task = db.companies.find_one({"id": sheet.company_id})
            project_task = db.projects.find_one({"id": sheet.project_id})
            template_task = db.evaluation_templates.find_one({"id": sheet.template_id})
            scores_task = db.evaluation_scores.find({"sheet_id": sheet.id}).to_list(1000)
            evaluator_task = db.users.find_one({"id": sheet.evaluator_id})
            
            company_data, project_data, template_data, scores, evaluator_data = await asyncio.gather(
                company_task, project_task, template_task, scores_task, evaluator_task
            )
            
            if all([company_data, project_data, template_data, evaluator_data]):
                evaluation_data = {
                    "sheet": sheet.dict(),
                    "company": company_data,
                    "project": project_data,
                    "template": template_data,
                    "scores": [{"item_id": s["item_id"], "score": s["score"], "opinion": s["opinion"]} for s in scores],
                    "evaluator": evaluator_data
                }
                evaluation_data_list.append(evaluation_data)
        
        if not evaluation_data_list:
            raise HTTPException(status_code=404, detail="ìœ íš¨í•œ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        if export_type == "combined":
            # í•˜ë‚˜ì˜ Excel íŒŒì¼ë¡œ ê²°í•©
            if format_type == "pdf":
                raise HTTPException(status_code=400, detail="PDFëŠ” ê°œë³„ íŒŒì¼ë¡œë§Œ ì¶”ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
            
            buffer = await exporter.export_bulk_evaluations_excel(evaluation_data_list)
            project_name = evaluation_data_list[0]["project"]["name"]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{project_name}_ì¢…í•©í‰ê°€ì„œ_{timestamp}.xlsx"
            
            return StreamingResponse(
                io.BytesIO(buffer.read()),
                media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                headers={"Content-Disposition": f"attachment; filename*=UTF-8''{filename}"}
            )
        else:
            # ê°œë³„ íŒŒì¼ë“¤ì„ ZIPìœ¼ë¡œ ì••ì¶•
            import zipfile
            
            zip_buffer = io.BytesIO()
            
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                for eval_data in evaluation_data_list:
                    # Generate individual file
                    submitted_date = eval_data["sheet"]["submitted_at"] or datetime.utcnow()
                    filename = exporter.generate_filename(
                        eval_data["project"]["name"],
                        eval_data["company"]["name"],
                        submitted_date,
                        format_type
                    )
                    
                    if format_type == "pdf":
                        file_buffer = await exporter.export_single_evaluation_pdf(eval_data)
                    else:
                        file_buffer = await exporter.export_single_evaluation_excel(eval_data)
                    
                    zip_file.writestr(filename, file_buffer.read())
            
            zip_buffer.seek(0)
            project_name = evaluation_data_list[0]["project"]["name"]
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            zip_filename = f"{project_name}_ì¢…í•©í‰ê°€ì„œ_ì¼ê´„ì¶”ì¶œ_{timestamp}.zip"
            
            return StreamingResponse(
                zip_buffer,
                media_type="application/zip",
                headers={"Content-Disposition": f"attachment; filename*=UTF-8''{zip_filename}"}
            )
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Bulk export error: {str(e)}", extra={
                'custom_operation': 'bulk_export',
                'custom_error_type': type(e).__name__
            })
        raise HTTPException(status_code=500, detail="ì¼ê´„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@api_router.get("/evaluations")
async def get_evaluations_list(
    project_id: Optional[str] = Query(None, description="í”„ë¡œì íŠ¸ ID í•„í„°"),
    status: Optional[str] = Query(None, description="ìƒíƒœ í•„í„°"),
    evaluator_id: Optional[str] = Query(None, description="í‰ê°€ì ID í•„í„°"),
    current_user: User = Depends(get_current_user)
):
    """í‰ê°€ ëª©ë¡ ì¡°íšŒ - í–¥ìƒëœ í•„í„°ë§ ì§€ì›"""
    try:
        query = {}
        if project_id:
            query["project_id"] = project_id
        if status:
            query["status"] = status
        if evaluator_id:
            query["evaluator_id"] = evaluator_id
            
        # í‰ê°€ ì‹œíŠ¸ ì¡°íšŒ
        evaluations = await db.evaluation_sheets.find(query).to_list(1000)
        
        # ê´€ë ¨ ë°ì´í„° ì¡°íšŒí•˜ì—¬ ì™„ì „í•œ ì •ë³´ ì œê³µ
        result = []
        for eval_data in evaluations:
            # í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ
            project = await db.projects.find_one({"id": eval_data.get("project_id")})
            # íšŒì‚¬ ì •ë³´ ì¡°íšŒ
            company = await db.companies.find_one({"id": eval_data.get("company_id")})
            # í‰ê°€ì ì •ë³´ ì¡°íšŒ
            evaluator = await db.users.find_one({"id": eval_data.get("evaluator_id")})
            
            result.append({
                "id": eval_data.get("id", eval_data.get("_id")),
                "project_id": eval_data.get("project_id"),
                "project_name": project.get("name") if project else "ì•Œ ìˆ˜ ì—†ìŒ",
                "company_id": eval_data.get("company_id"),
                "company_name": company.get("name") if company else "ì•Œ ìˆ˜ ì—†ìŒ",
                "evaluator_id": eval_data.get("evaluator_id"),
                "evaluator_name": evaluator.get("user_name") if evaluator else "ì•Œ ìˆ˜ ì—†ìŒ",
                "evaluatee_id": eval_data.get("company_id"),  # í”¼í‰ê°€ìëŠ” íšŒì‚¬
                "status": eval_data.get("status", "pending"),
                "created_at": eval_data.get("created_at"),
                "evaluation_date": eval_data.get("submitted_at"),
                "scores": eval_data.get("scores", {}),
                "comments": eval_data.get("comments", "")
            })
        
        return result
    except Exception as e:
        logger.error(f"í‰ê°€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@api_router.get("/evaluations/export-list")
async def get_exportable_evaluations(
    project_id: Optional[str] = None,
    template_id: Optional[str] = None,
    current_user: User = Depends(get_current_user)
):
    """ì¶”ì¶œ ê°€ëŠ¥í•œ í‰ê°€ ëª©ë¡ ì¡°íšŒ (ì œì¶œëœ í‰ê°€ë§Œ)"""
    check_admin_or_secretary(current_user)
    
    try:
        # Build query for submitted evaluations
        query = {"status": "submitted"}
        
        if project_id:
            query["project_id"] = project_id
        if template_id:
            query["template_id"] = template_id
        
        # Get evaluation sheets
        sheets = await db.evaluation_sheets.find(query).to_list(1000)
        
        # Get related data for display
        result = []
        for sheet_data in sheets:
            sheet = EvaluationSheet(**sheet_data)
            
            # Get related data concurrently
            company_task = db.companies.find_one({"id": sheet.company_id})
            project_task = db.projects.find_one({"id": sheet.project_id})
            template_task = db.evaluation_templates.find_one({"id": sheet.template_id})
            evaluator_task = db.users.find_one({"id": sheet.evaluator_id})
            
            company_data, project_data, template_data, evaluator_data = await asyncio.gather(
                company_task, project_task, template_task, evaluator_task
            )
            
            if all([company_data, project_data, template_data, evaluator_data]):
                result.append({
                    "evaluation_id": sheet.id,
                    "project_name": project_data["name"],
                    "company_name": company_data["name"],
                    "template_name": template_data["name"],
                    "evaluator_name": evaluator_data["user_name"],
                    "submitted_at": sheet.submitted_at,
                    "total_score": sheet.total_score,
                    "weighted_score": sheet.weighted_score
                })
        
        return result
        
    except Exception as e:
        logger.error(f"Get exportable evaluations error: {str(e)}", extra={
                'custom_operation': 'get_exportable_evaluations',
                'custom_error_type': type(e).__name__
            })
        raise HTTPException(status_code=500, detail="ì¶”ì¶œ ê°€ëŠ¥í•œ í‰ê°€ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

# Template routes - REMOVED: Now handled by template_endpoints.py with enhanced features

# POST template endpoint - REMOVED: Now handled by template_endpoints.py with enhanced features

# Security monitoring and management endpoints
@api_router.get("/security/health")
async def security_health_check():
    """Public endpoint to check security system health"""
    try:
        # Check Redis connection
        redis_status = "healthy"
        try:
            if security_monitor.redis_client:
                security_monitor.redis_client.ping()
        except:
            redis_status = "unavailable"
        
        # Check MongoDB connection
        mongo_status = "healthy"
        try:
            if security_monitor.mongo_client:
                security_monitor.mongo_client.admin.command('ping')
        except:
            mongo_status = "unavailable"
        
        return {
            "status": "healthy",
            "components": {
                "security_monitor": "active",
                "redis": redis_status,
                "mongodb": mongo_status,
                "rate_limiting": "active",
                "threat_detection": "active"
            },
            "timestamp": datetime.utcnow()
        }
        
    except Exception as e:
        return {
            "status": "degraded",
            "error": str(e),
            "timestamp": datetime.utcnow()
        }

@api_router.get("/security/metrics")
async def get_security_metrics(
    hours: int = Query(24, ge=1, le=168),  # 1 hour to 1 week
    current_user: User = Depends(get_current_user)
):
    """Get security metrics for the specified time period (admin only)"""
    if current_user.role != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    
    metrics = await security_monitor.get_security_metrics(hours)
    return {"metrics": metrics, "generated_at": datetime.utcnow()}

@api_router.get("/security/threat-intelligence")
async def get_threat_intelligence_report(current_user: User = Depends(get_current_user)):
    """Get comprehensive threat intelligence report (admin only)"""
    if current_user.role != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    
    report = await security_monitor.get_threat_intelligence_report()
    return {"report": report}

# Additional security endpoints for comprehensive monitoring
@api_router.get("/security/events")
async def get_security_events(
    limit: int = Query(100, ge=1, le=1000),
    event_type: Optional[str] = Query(None),
    severity: Optional[str] = Query(None),
    current_user: User = Depends(get_current_user)
):
    """Get recent security events (admin only)"""
    if current_user.role != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Admin access required"
        )
    
    try:
        events = await security_monitor.get_security_events(
            limit=limit,
            event_type=event_type,
            severity=severity
        )
        return {
            "events": events,
            "total": len(events),
            "filters": {
                "event_type": event_type,
                "severity": severity,
                "limit": limit
            },
            "timestamp": datetime.utcnow()
        }
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve security events: {str(e)}"
        )

@api_router.post("/security/validate")
async def validate_input_security(
    request: Request,
    data: dict,
    current_user: User = Depends(get_current_user)
):
    """Validate input data against security policies"""
    try:
        # Use the security validator to check the request
        validation_results = security_validator.validate_api_request(request)
        
        # Validate JSON data if provided
        if data:
            validated_data = security_validator.validate_json_input(data)
            validation_results["data_validation"] = "passed"
        
        return {
            "validation_results": validation_results,
            "timestamp": datetime.utcnow()
        }
        
    except Exception as e:
        return {
            "validation_results": {"valid": False, "error": str(e)},
            "timestamp": datetime.utcnow()
        }

# AI ë¹„ìš© ìµœì í™” ì—”ë“œí¬ì¸íŠ¸ë“¤
@api_router.get("/ai/cost-optimization")
async def get_ai_cost_optimization_stats(current_user: User = Depends(check_admin_or_secretary)):
    """AI ëª¨ë¸ë³„ ë¹„ìš© ìµœì í™” í†µê³„ ì¡°íšŒ"""
    if AI_ENABLED and enhanced_ai_service:
        stats = enhanced_ai_service.get_cost_optimization_stats()
        return {"success": True, "data": stats}
    else:
        return {"success": False, "message": "AI ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤"}

@api_router.post("/ai/cost-estimate")
async def estimate_ai_analysis_cost(
    request: Dict[str, Any] = None,
    current_user: User = Depends(get_current_user)
):
    """AI ë¶„ì„ ë¹„ìš© ì˜ˆìƒ ê³„ì‚°"""
    if not AI_ENABLED or not enhanced_ai_service:
        return {"success": False, "message": "AI ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤"}
    
    try:
        document_text = request.get("document_text", "")
        analysis_type = request.get("analysis_type", "standard")
        budget_priority = request.get("budget_priority", "balanced")
        
        if not document_text:
            raise HTTPException(400, "document_textê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ìµœì  ëª¨ë¸ ì„ íƒ
        optimal_model = enhanced_ai_service._select_optimal_groq_model(
            document_length=len(document_text),
            analysis_type=analysis_type,
            budget_priority=budget_priority
        )
        
        # ë¹„ìš© ê³„ì‚°
        cost_info = enhanced_ai_service._calculate_token_cost(document_text, optimal_model)
        
        return {
            "success": True,
            "data": {
                "recommended_model": optimal_model,
                "document_length": len(document_text),
                "analysis_type": analysis_type,
                "budget_priority": budget_priority,
                "cost_estimate": cost_info,
                "alternatives": [
                    {
                        "model": "llama3.1-8b-instant",
                        "cost": enhanced_ai_service._calculate_token_cost(document_text, "llama3.1-8b-instant"),
                        "pros": ["ìµœì € ë¹„ìš©", "ìµœê³  ì†ë„"],
                        "cons": ["ê¸°ë³¸ ì„±ëŠ¥"]
                    },
                    {
                        "model": "qwq-32b-preview", 
                        "cost": enhanced_ai_service._calculate_token_cost(document_text, "qwq-32b-preview"),
                        "pros": ["ê· í˜•ì¡íŒ ì„±ëŠ¥", "íˆ´ ì‚¬ìš© ê°•ì "],
                        "cons": ["ì¤‘ê°„ ë¹„ìš©"]
                    },
                    {
                        "model": "llama3.3-70b-versatile",
                        "cost": enhanced_ai_service._calculate_token_cost(document_text, "llama3.3-70b-versatile"),
                        "pros": ["ìµœê³  ì„±ëŠ¥", "ì •í™•ë„ ë†’ìŒ"],
                        "cons": ["ë†’ì€ ë¹„ìš©"]
                    }
                ]
            }
        }
        
    except Exception as e:
        logger.error(f"AI ë¹„ìš© ì˜ˆìƒ ê³„ì‚° ì˜¤ë¥˜: {e}")
        raise HTTPException(500, f"ë¹„ìš© ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@api_router.get("/ai/usage-analytics")
async def get_ai_usage_analytics(current_user: User = Depends(check_admin_or_secretary)):
    """AI ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ë¶„ì„"""
    if not AI_ENABLED:
        return {"success": False, "message": "AI ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤"}
    
    try:
        # ì‹¤ì œ êµ¬í˜„ì‹œì—ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì‚¬ìš© ë‚´ì—­ ì¡°íšŒ
        # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
        analytics_data = {
            "current_month": {
                "total_requests": 1247,
                "total_tokens": 2856420,
                "total_cost_usd": 15.67,
                "total_cost_krw": 20371,
                "average_cost_per_request": 0.0126
            },
            "model_usage": [
                {"model": "llama3.1-8b-instant", "requests": 856, "tokens": 1234567, "cost_usd": 1.60, "percentage": 68.7},
                {"model": "qwq-32b-preview", "requests": 298, "tokens": 1105820, "cost_usd": 7.52, "percentage": 23.9},
                {"model": "llama3.3-70b-versatile", "requests": 93, "tokens": 516033, "cost_usd": 6.55, "percentage": 7.4}
            ],
            "daily_trend": [
                {"date": "2025-06-15", "requests": 45, "cost_usd": 0.67},
                {"date": "2025-06-16", "requests": 52, "cost_usd": 0.84},
                {"date": "2025-06-17", "requests": 38, "cost_usd": 0.52},
                {"date": "2025-06-18", "requests": 61, "cost_usd": 1.23},
                {"date": "2025-06-19", "requests": 49, "cost_usd": 0.78},
                {"date": "2025-06-20", "requests": 56, "cost_usd": 0.95},
                {"date": "2025-06-21", "requests": 42, "cost_usd": 0.63}
            ],
            "cost_optimization_suggestions": [
                {
                    "type": "model_switching",
                    "message": "ê°„ë‹¨í•œ ë¬¸ì„œ ë¶„ì„ 856ê±´ì„ llama3.1-8bë¡œ ì²˜ë¦¬í•˜ì—¬ ì›” $14.07 ì ˆì•½ ì¤‘",
                    "savings_potential": 14.07
                },
                {
                    "type": "batch_processing", 
                    "message": "ìœ ì‚¬í•œ ë¬¸ì„œë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•˜ë©´ ì¶”ê°€ë¡œ 10-15% ì ˆì•½ ê°€ëŠ¥",
                    "savings_potential": 2.35
                }
            ]
        }
        
        return {"success": True, "data": analytics_data}
        
    except Exception as e:
        logger.error(f"AI ì‚¬ìš©ëŸ‰ ë¶„ì„ ì˜¤ë¥˜: {e}")
        raise HTTPException(500, f"ì‚¬ìš©ëŸ‰ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# TEST ENDPOINT - Check if direct app endpoints work
@app.post("/api/test/direct")
async def test_direct_endpoint():
    """Test if direct app endpoints are accessible"""
    print("ğŸš€ DIRECT ENDPOINT CALLED!")
    return {"status": "success", "message": "Direct endpoint working"}

# SIMPLE LOGIN TEST ENDPOINT
@app.post("/api/auth/login-simple")
async def simple_login_test(form_data: OAuth2PasswordRequestForm = Depends()):
    """Simple login test without complex error handling"""
    try:
        import bcrypt
        
        username = form_data.username.strip().lower()
        password = form_data.password
        
        # DB ì¡°íšŒ
        user_data = await db.users.find_one({"login_id": username})
        if not user_data:
            return {"error": "user_not_found", "username": username}
        
        # ë¹„ë°€ë²ˆí˜¸ í•´ì‹œ í™•ì¸
        stored_hash = user_data.get("password_hash", "")
        if not stored_hash:
            return {"error": "no_password_hash", "fields": list(user_data.keys())}
        
        # bcrypt ì§ì ‘ ê²€ì¦
        password_valid = bcrypt.checkpw(password.encode('utf-8'), stored_hash.encode('utf-8'))
        
        if password_valid:
            # í† í° ìƒì„±
            access_token = create_access_token(data={"sub": str(user_data["_id"])})
            return {"access_token": access_token, "token_type": "bearer", "status": "success"}
        else:
            return {"error": "invalid_password", "hash_length": len(stored_hash)}
            
    except Exception as e:
        return {"error": "exception", "message": str(e)}

# CLEAN AUTH ENDPOINT - Direct to main app to bypass router conflicts
@app.post("/api/auth/login", operation_id="login_user", response_model=Token)
async def clean_login_endpoint(form_data: OAuth2PasswordRequestForm = Depends()):
    """Clean login endpoint with enhanced validation and security"""
    
    try:
        # Input validation
        if not form_data.username or not form_data.username.strip():
            raise HTTPException(status_code=400, detail="ì‚¬ìš©ìëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if not form_data.password:
            raise HTTPException(status_code=400, detail="ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # Rate limiting could be implemented here
        # For now, just log the attempt
        logging.info(f"Login attempt for user: {form_data.username}")
        
        # Sanitize username to prevent injection attacks
        username = form_data.username.strip().lower()
        
        # Database query with error handling
        try:
            logging.warning(f"DEBUG: Searching for user with login_id: '{username}'")
            user_data = await db.users.find_one({"login_id": username})
            logging.warning(f"DEBUG: User search result: {'Found' if user_data else 'Not found'}")
            if user_data:
                logging.warning(f"DEBUG: User fields: {list(user_data.keys())}")
        except Exception as e:
            logging.error(f"Database error during login for user {username}: {e}")
            raise HTTPException(status_code=500, detail="ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        if not user_data:
            logging.warning(f"Login failed - user not found: {username}")
            # Don't reveal whether user exists or not for security
            raise HTTPException(status_code=401, detail="ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # Check if user account is active
        if not user_data.get("is_active", True):
            logging.warning(f"Login failed - inactive account: {username}")
            raise HTTPException(status_code=401, detail="ê³„ì •ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        
        # Verify password using bcrypt directly
        try:
            import bcrypt
            logging.warning(f"DEBUG: Attempting password verification for user: {username}")
            logging.warning(f"DEBUG: Password hash exists: {'password_hash' in user_data}")
            logging.warning(f"DEBUG: Password hash length: {len(user_data.get('password_hash', ''))}")
            
            stored_hash = user_data["password_hash"]
            password_valid = bcrypt.checkpw(form_data.password.encode('utf-8'), stored_hash.encode('utf-8'))
            
            logging.warning(f"DEBUG: Password verification result: {password_valid}")
        except Exception as e:
            logging.error(f"Password verification error for user {username}: {e}")
            raise HTTPException(status_code=500, detail="ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        if not password_valid:
            logging.warning(f"Login failed - invalid password for user: {username}")
            # Use same message as user not found for security
            raise HTTPException(status_code=401, detail="ì‚¬ìš©ìëª… ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # Create token with error handling
        try:
            access_token = create_access_token(data={"sub": str(user_data["_id"])})
        except Exception as e:
            logging.error(f"Token creation error for user {username}: {e}")
            raise HTTPException(status_code=500, detail="ì¸ì¦ í† í° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        # Update last login timestamp
        try:
            await db.users.update_one(
                {"_id": user_data["_id"]},
                {"$set": {"last_login": datetime.utcnow()}}
            )
        except Exception as e:
            logging.warning(f"Failed to update last login for user {username}: {e}")
            # Don't fail the login just because we can't update last login
        
        # Create user response with validation
        try:
            user_response = UserResponse(
                id=str(user_data["_id"]),
                login_id=user_data["login_id"],
                user_name=user_data["user_name"],
                email=user_data["email"],
                role=user_data["role"],
                is_active=user_data["is_active"],
                created_at=user_data.get("created_at", datetime.utcnow()),
                last_login=datetime.utcnow()
            )
        except Exception as e:
            logging.error(f"User response creation error for user {username}: {e}")
            raise HTTPException(status_code=500, detail="ì‚¬ìš©ì ì •ë³´ êµ¬ì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        logging.info(f"Login successful for user: {username}")
        return Token(access_token=access_token, token_type="bearer", user=user_response)
        
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        # Log unexpected errors securely (don't expose sensitive details)
        logging.error(f"Unexpected error during login: {e}")
        raise HTTPException(status_code=500, detail="ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# API router will be included later with /api prefix

# Router registrations moved to centralized location below to avoid duplicates

# AI ëª¨ë¸ ì„¤ì • ë¼ìš°í„° ì¶”ê°€
if AI_MODEL_SETTINGS_ENABLED:
    app.include_router(ai_model_settings_router)
    print("AI ëª¨ë¸ ì„¤ì • ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ê¶Œí•œ ê´€ë¦¬ ë¼ìš°í„° ì¶”ê°€ (í–¥ìƒëœ ê¶Œí•œ ì‹œìŠ¤í…œì´ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ)
if ENHANCED_PERMISSIONS_ENABLED:
    app.include_router(permission_admin_router)
    print("í–¥ìƒëœ ê¶Œí•œ ê´€ë¦¬ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í–¥ìƒëœ í…œí”Œë¦¿ ê´€ë¦¬ ë¼ìš°í„° ì¶”ê°€ - MOVED to after api_router registration

# í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ë¼ìš°í„° ì¶”ê°€
# if enhanced_health_monitoring:
#     app.include_router(health_router)
#     print("âœ… í–¥ìƒëœ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í‰ê°€ ì›Œí¬í”Œë¡œìš° ì™„ì„±ì„ ìœ„í•œ ì¶”ê°€ ì—”ë“œí¬ì¸íŠ¸ë“¤

@api_router.post("/evaluations/create")
async def create_evaluation_assignment(
    assignment_data: dict,
    current_user: User = Depends(get_current_user)
):
    """ìƒˆë¡œìš´ í‰ê°€ ë°°ì • ìƒì„±"""
    check_admin_or_secretary(current_user)
    
    try:
        # í‰ê°€ ì‹œíŠ¸ ìƒì„±
        evaluation_sheet = {
            "id": str(uuid.uuid4()),
            "project_id": assignment_data["project_id"],
            "company_id": assignment_data["company_id"],
            "evaluator_id": assignment_data["evaluator_id"],
            "template_id": assignment_data.get("template_id"),
            "status": "assigned",
            "created_at": datetime.utcnow(),
            "created_by": current_user.id,
            "scores": {},
            "comments": ""
        }
        
        await db.evaluation_sheets.insert_one(evaluation_sheet)
        return {"message": "í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ë°°ì •ë˜ì—ˆìŠµë‹ˆë‹¤", "evaluation_id": evaluation_sheet["id"]}
    
    except Exception as e:
        logger.error(f"í‰ê°€ ë°°ì • ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ë°°ì • ì‹¤íŒ¨: {str(e)}")

@api_router.get("/evaluations/{evaluation_id}")
async def get_evaluation_detail(
    evaluation_id: str,
    current_user: User = Depends(get_current_user)
):
    """í‰ê°€ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        evaluation = await db.evaluation_sheets.find_one({"id": evaluation_id})
        if not evaluation:
            raise HTTPException(status_code=404, detail="í‰ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê¶Œí•œ í™•ì¸
        if current_user.role == "evaluator" and evaluation["evaluator_id"] != current_user.id:
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ê´€ë ¨ ì •ë³´ ì¡°íšŒ
        project = await db.projects.find_one({"id": evaluation["project_id"]})
        company = await db.companies.find_one({"id": evaluation["company_id"]})
        evaluator = await db.users.find_one({"id": evaluation["evaluator_id"]})
        template = await db.evaluation_templates.find_one({"id": evaluation.get("template_id")})
        
        return {
            "evaluation": evaluation,
            "project": project,
            "company": company,
            "evaluator": evaluator,
            "template": template
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í‰ê°€ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

@api_router.put("/evaluations/{evaluation_id}")
async def update_evaluation(
    evaluation_id: str,
    update_data: dict,
    current_user: User = Depends(get_current_user)
):
    """í‰ê°€ ì—…ë°ì´íŠ¸ (ì„ì‹œ ì €ì¥)"""
    try:
        evaluation = await db.evaluation_sheets.find_one({"id": evaluation_id})
        if not evaluation:
            raise HTTPException(status_code=404, detail="í‰ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê¶Œí•œ í™•ì¸
        if current_user.role == "evaluator" and evaluation["evaluator_id"] != current_user.id:
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ì—…ë°ì´íŠ¸ ë°ì´í„° ì¤€ë¹„
        update_fields = {
            "scores": update_data.get("scores", evaluation["scores"]),
            "comments": update_data.get("comments", evaluation["comments"]),
            "status": update_data.get("status", "in_progress"),
            "updated_at": datetime.utcnow(),
            "updated_by": current_user.id
        }
        
        # ì œì¶œì¸ ê²½ìš° ì œì¶œ ì‹œê°„ ê¸°ë¡
        if update_data.get("status") == "submitted":
            update_fields["submitted_at"] = datetime.utcnow()
        
        await db.evaluation_sheets.update_one(
            {"id": evaluation_id},
            {"$set": update_fields}
        )
        
        return {"message": "í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"}
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í‰ê°€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")

@api_router.delete("/evaluations/{evaluation_id}")
async def delete_evaluation(
    evaluation_id: str,
    current_user: User = Depends(get_current_user)
):
    """í‰ê°€ ì‚­ì œ"""
    check_admin_or_secretary(current_user)
    
    try:
        result = await db.evaluation_sheets.delete_one({"id": evaluation_id})
        if result.deleted_count == 0:
            raise HTTPException(status_code=404, detail="í‰ê°€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ê´€ë ¨ ì ìˆ˜ ë°ì´í„°ë„ ì‚­ì œ
        await db.evaluation_scores.delete_many({"sheet_id": evaluation_id})
        
        return {"message": "í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í‰ê°€ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")

@api_router.get("/dashboard/statistics")
async def get_dashboard_statistics(
    current_user: User = Depends(get_current_user)
):
    """ëŒ€ì‹œë³´ë“œ í†µê³„ ë°ì´í„° ì¡°íšŒ"""
    try:
        # ê¸°ë³¸ í†µê³„ ë°ì´í„° ì¡°íšŒ
        total_projects = await db.projects.count_documents({})
        total_companies = await db.companies.count_documents({})
        total_evaluators = await db.users.count_documents({"role": "evaluator"})
        total_evaluations = await db.evaluation_sheets.count_documents({})
        
        # ìƒíƒœë³„ í‰ê°€ ì§‘ê³„
        pending_evaluations = await db.evaluation_sheets.count_documents({"status": "assigned"})
        in_progress_evaluations = await db.evaluation_sheets.count_documents({"status": "in_progress"})
        completed_evaluations = await db.evaluation_sheets.count_documents({"status": "submitted"})
        
        # ìµœê·¼ í™œë™
        recent_evaluations = await db.evaluation_sheets.find(
            {},
            sort=[("created_at", -1)],
            limit=5
        ).to_list(5)
        
        return {
            "overview": {
                "total_projects": total_projects,
                "total_companies": total_companies,
                "total_evaluators": total_evaluators,
                "total_evaluations": total_evaluations
            },
            "evaluation_status": {
                "pending": pending_evaluations,
                "in_progress": in_progress_evaluations,
                "completed": completed_evaluations,
                "completion_rate": round((completed_evaluations / max(total_evaluations, 1)) * 100, 1)
            },
            "recent_activity": recent_evaluations
        }
    
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")

# Duplicate router registrations removed - centralized below

# ë°°í¬ ê´€ë¦¬ ë¼ìš°í„° ì¶”ê°€
if DEPLOYMENT_MANAGER_ENABLED:
    app.include_router(deployment_router)
    print("âœ… ë°°í¬ ê´€ë¦¬ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# WebSocket ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
try:
    from websocket_service import connection_manager, notification_service as ws_notification_service
    
    @app.websocket("/ws/{user_id}")
    async def websocket_endpoint(websocket: WebSocket, user_id: str):
        """WebSocket ì—°ê²° ì—”ë“œí¬ì¸íŠ¸"""
        await connection_manager.connect(websocket, user_id)
        try:
            while True:
                # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ 
                data = await websocket.receive_text()
                try:
                    message = json.loads(data)
                    
                    # ë©”ì‹œì§€ íƒ€ì…ë³„ ì²˜ë¦¬
                    if message.get("type") == "join_room":
                        room_id = message.get("room_id")
                        if room_id:
                            await connection_manager.join_room(websocket, room_id)
                    
                    elif message.get("type") == "leave_room":
                        room_id = message.get("room_id")
                        if room_id:
                            await connection_manager.leave_room(websocket, room_id)
                    
                    elif message.get("type") == "ping":
                        # ì—°ê²° ìƒíƒœ í™•ì¸
                        await connection_manager.send_personal_message({
                            "type": "pong",
                            "timestamp": datetime.utcnow().isoformat()
                        }, websocket)
                    
                except json.JSONDecodeError:
                    # ì˜ëª»ëœ JSON ë©”ì‹œì§€ ë¬´ì‹œ
                    pass
                    
        except WebSocketDisconnect:
            connection_manager.disconnect(websocket)
    
    @app.get("/api/notifications/active-connections")
    async def get_active_connections(current_user: User = Depends(get_current_user)):
        """í™œì„± WebSocket ì—°ê²° ìƒíƒœ ì¡°íšŒ (ê´€ë¦¬ì ì „ìš©)"""
        if current_user.role != "admin":
            raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ì—°ê²° ìƒíƒœë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return {
            "active_users": connection_manager.get_active_users(),
            "total_connections": connection_manager.get_connection_count(),
            "rooms": list(connection_manager.rooms.keys())
        }
    
    @app.post("/api/notifications/send-broadcast")
    async def send_broadcast_notification(
        message: dict,
        current_user: User = Depends(get_current_user)
    ):
        """ì „ì²´ ì‚¬ìš©ìì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì•Œë¦¼ ì „ì†¡ (ê´€ë¦¬ì ì „ìš©)"""
        if current_user.role != "admin":
            raise HTTPException(status_code=403, detail="ê´€ë¦¬ìë§Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì•Œë¦¼ì„ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        notification_message = {
            "type": "admin_broadcast",
            "title": message.get("title", "ê´€ë¦¬ì ê³µì§€"),
            "message": message.get("message", ""),
            "priority": message.get("priority", "info"),
            "timestamp": datetime.utcnow().isoformat(),
            "sender": current_user.user_name
        }
        
        await connection_manager.broadcast_to_all(notification_message)
        
        return {"message": "ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì•Œë¦¼ì´ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤"}
    
    print("âœ… WebSocket ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
except ImportError as e:
    print(f"âš ï¸ WebSocket ì„œë¹„ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

# ê¸°ë³¸ API ë¼ìš°í„° ì¶”ê°€ (ì¤‘ìš”í•œ ì—”ë“œí¬ì¸íŠ¸ë“¤)
try:
    app.include_router(api_router, prefix="/api", tags=["Main API"])
    print("âœ… ê¸°ë³¸ API ë¼ìš°í„°ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âš ï¸ API ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")
    print("API ë¼ìš°í„°ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸ë“¤ì€ ì§ì ‘ ë“±ë¡ë©ë‹ˆë‹¤.")

# í–¥ìƒëœ í…œí”Œë¦¿ ê´€ë¦¬ ë¼ìš°í„° ì¶”ê°€ (prefix ì—†ì´ ë“±ë¡í•˜ì—¬ ìš°ì„ ìˆœìœ„ í™•ë³´)
if ENHANCED_TEMPLATES_ENABLED:
    app.include_router(template_router, prefix="")
    print("âœ… í–¥ìƒëœ í…œí”Œë¦¿ ê´€ë¦¬ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (prefix ì—†ì´ ë“±ë¡í•˜ì—¬ ìš°ì„ ìˆœìœ„ í™•ë³´).")

# Main entry point for Uvicorn (if running directly)
if __name__ == "__main__":
    import uvicorn
    
    # Production-ready server configuration
    config = {
        "host": "0.0.0.0",
        "port": int(os.getenv("PORT", 8080)),
        "log_level": os.getenv("LOG_LEVEL", "info").lower(),
        "access_log": True,
        "use_colors": False,
        "server_header": False,  # Hide server information
        "date_header": False,    # Don't include date header
    }
    
    # Add SSL configuration for production
    if os.getenv("ENVIRONMENT") == "production":
        config.update({
            "ssl_keyfile": os.getenv("SSL_KEY_FILE"),
            "ssl_certfile": os.getenv("SSL_CERT_FILE"),
            "ssl_ca_certs": os.getenv("SSL_CA_CERTS"),
        })
    
    logger.info(f"ğŸš€ Starting Online Evaluation System on {config['host']}:{config['port']}")
    uvicorn.run(app, **config)
