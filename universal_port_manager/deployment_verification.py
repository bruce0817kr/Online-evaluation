#!/usr/bin/env python3
"""
ì‹¤ì œ ë°°í¬ í™˜ê²½ ë™ì‘ ê²€ì¦
=======================

Universal Port Managerê°€ ì‹¤ì œ ë°°í¬ í™˜ê²½ì—ì„œ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” ì¢…í•© í…ŒìŠ¤íŠ¸
ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œì˜ ì‹¤ì œ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ëª¨ì‚¬í•˜ì—¬ ê²€ì¦
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
from pathlib import Path
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class DeploymentVerifier:
    """ë°°í¬ í™˜ê²½ ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.test_root = Path(tempfile.mkdtemp(prefix='deployment_test_'))
        self.project_root = Path(__file__).parent.parent
        self.results = []
        
        # ì‹¤ì œ ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ë“¤
        self.online_eval_services = [
            'frontend', 'backend', 'mongodb', 'redis', 
            'nginx', 'elasticsearch', 'kibana'
        ]
        
        logger.info(f"ë°°í¬ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {self.test_root}")
        
    def run_all_verifications(self):
        """ëª¨ë“  ë°°í¬ ê²€ì¦ ì‹¤í–‰"""
        logger.info("ğŸš€ ì‹¤ì œ ë°°í¬ í™˜ê²½ ë™ì‘ ê²€ì¦ ì‹œì‘")
        logger.info("=" * 60)
        
        verifications = [
            self.verify_online_eval_deployment,
            self.verify_multi_environment_deployment,
            self.verify_production_ready_features,
            self.verify_docker_compose_generation,
            self.verify_scaling_scenarios,
            self.verify_backup_and_recovery,
            self.verify_monitoring_integration
        ]
        
        for verification in verifications:
            try:
                logger.info(f"\nğŸ“‹ {verification.__name__} ì‹¤í–‰ ì¤‘...")
                result = verification()
                self.results.append(result)
                
                if result['success']:
                    logger.info(f"âœ… {verification.__name__} ì„±ê³µ")
                else:
                    logger.error(f"âŒ {verification.__name__} ì‹¤íŒ¨: {result.get('error')}")
                    
            except Exception as e:
                self.results.append({
                    'test': verification.__name__,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                logger.error(f"ğŸ’¥ {verification.__name__} ì˜ˆì™¸: {e}")
        
        return self.generate_deployment_report()
    
    def verify_online_eval_deployment(self):
        """ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦"""
        logger.info("ğŸ” ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ë°°í¬ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦")
        
        try:
            # ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡° ëª¨ì‚¬
            eval_project_dir = self.test_root / 'online-evaluation'
            eval_project_dir.mkdir()
            
            # ê¸°ë³¸ ì„¤ì • íŒŒì¼ë“¤ ìƒì„±
            self._create_project_structure(eval_project_dir)
            
            # í¬íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            from universal_port_manager.core.port_manager_config import PortManagerConfig
            from universal_port_manager.core.port_manager_docker import PortManagerDocker
            
            allocator = ImprovedPortAllocator()
            
            # ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤ í• ë‹¹
            allocated_ports = allocator.allocate_project_ports(
                'online-evaluation', 
                self.online_eval_services
            )
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            config_manager = PortManagerConfig(eval_project_dir, 'online-evaluation')
            env_files = config_manager.generate_env_files(allocated_ports, ['docker', 'bash', 'json'])
            start_script_created = config_manager.generate_start_script(allocated_ports)
            
            # Docker Compose íŒŒì¼ ìƒì„±
            docker_manager = PortManagerDocker(eval_project_dir, 'online-evaluation')
            compose_created = docker_manager.generate_compose_file(allocated_ports, include_override=True)
            
            # ê²€ì¦
            all_services_allocated = len(allocated_ports) == len(self.online_eval_services)
            unique_ports = len(set(p.port for p in allocated_ports.values())) == len(self.online_eval_services)
            env_files_created = len(env_files) >= 2
            compose_file_exists = (eval_project_dir / 'docker-compose.yml').exists()
            
            # í¬íŠ¸ ë²”ìœ„ ê²€ì¦ (ì‹¤ì œ ì„œë¹„ìŠ¤ë³„ ì ì ˆí•œ í¬íŠ¸)
            port_ranges_ok = self._verify_port_ranges(allocated_ports)
            
            return {
                'test': 'online_eval_deployment',
                'success': all([
                    all_services_allocated, unique_ports, env_files_created,
                    start_script_created, compose_created, port_ranges_ok
                ]),
                'details': {
                    'services_allocated': len(allocated_ports),
                    'services_requested': len(self.online_eval_services),
                    'all_services_allocated': all_services_allocated,
                    'unique_ports': unique_ports,
                    'env_files_created': env_files_created,
                    'start_script_created': start_script_created,
                    'compose_created': compose_created,
                    'compose_file_exists': compose_file_exists,
                    'port_ranges_ok': port_ranges_ok,
                    'allocated_ports': {name: port.port for name, port in allocated_ports.items()}
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'online_eval_deployment',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_multi_environment_deployment(self):
        """ë‹¤ì¤‘ í™˜ê²½ ë°°í¬ ê²€ì¦ (dev, staging, prod)"""
        logger.info("ğŸ” ë‹¤ì¤‘ í™˜ê²½ ë°°í¬ ê²€ì¦")
        
        try:
            environments = ['development', 'staging', 'production']
            env_results = {}
            all_allocated_ports = []
            
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            
            allocator = ImprovedPortAllocator()
            
            for env in environments:
                # í™˜ê²½ë³„ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
                env_dir = self.test_root / f'online-eval-{env}'
                env_dir.mkdir()
                
                # í™˜ê²½ë³„ ì„œë¹„ìŠ¤ (prodëŠ” ë” ë§ì€ ì„œë¹„ìŠ¤)
                if env == 'production':
                    services = self.online_eval_services + ['prometheus', 'grafana', 'alertmanager']
                elif env == 'staging':
                    services = self.online_eval_services
                else:  # development
                    services = ['frontend', 'backend', 'mongodb', 'redis']
                
                # í¬íŠ¸ í• ë‹¹
                allocated = allocator.allocate_project_ports(f'online-eval-{env}', services)
                
                env_results[env] = {
                    'services_count': len(services),
                    'allocated_count': len(allocated),
                    'ports': {name: port.port for name, port in allocated.items()}
                }
                
                # ëª¨ë“  í• ë‹¹ëœ í¬íŠ¸ ìˆ˜ì§‘
                all_allocated_ports.extend([port.port for port in allocated.values()])
            
            # í™˜ê²½ ê°„ í¬íŠ¸ ì¶©ëŒ ê²€ì‚¬
            unique_ports = len(set(all_allocated_ports)) == len(all_allocated_ports)
            
            # ê° í™˜ê²½ì´ ëª¨ë“  ì„œë¹„ìŠ¤ í• ë‹¹ë°›ì•˜ëŠ”ì§€ í™•ì¸
            all_env_success = all(
                result['allocated_count'] == result['services_count']
                for result in env_results.values()
            )
            
            return {
                'test': 'multi_environment_deployment',
                'success': unique_ports and all_env_success,
                'details': {
                    'environments': environments,
                    'total_ports_allocated': len(all_allocated_ports),
                    'unique_ports': unique_ports,
                    'all_env_success': all_env_success,
                    'env_results': env_results
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'multi_environment_deployment',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_production_ready_features(self):
        """í”„ë¡œë•ì…˜ ì¤€ë¹„ ê¸°ëŠ¥ ê²€ì¦"""
        logger.info("ğŸ” í”„ë¡œë•ì…˜ ì¤€ë¹„ ê¸°ëŠ¥ ê²€ì¦")
        
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            from universal_port_manager.core.port_manager_config import PortManagerConfig
            from universal_port_manager.dependency_manager import DependencyManager
            
            # ì˜ì¡´ì„± ê²€ì¦
            dm = DependencyManager()
            dependency_status = dm.get_dependency_status('full')
            
            # í¬íŠ¸ í• ë‹¹ ë° ë°±ì—…
            allocator = ImprovedPortAllocator()
            allocated = allocator.allocate_project_ports('prod-test', ['frontend', 'backend', 'database'])
            
            # ì„¤ì • ë°±ì—…
            prod_dir = self.test_root / 'production-test'
            prod_dir.mkdir()
            
            config_manager = PortManagerConfig(prod_dir, 'prod-test')
            backup_path = config_manager.backup_config('prod-backup')
            
            # í”„ë¡œë•ì…˜ ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸
            checks = {
                'dependency_management': dependency_status['is_functional'],
                'port_allocation': len(allocated) > 0,
                'configuration_backup': Path(backup_path).exists(),
                'port_persistence': self._check_port_persistence(allocator, 'prod-test'),
                'conflict_resolution': self._check_conflict_resolution(),
                'security_compliance': self._check_security_compliance(allocated)
            }
            
            all_checks_passed = all(checks.values())
            
            return {
                'test': 'production_ready_features',
                'success': all_checks_passed,
                'details': {
                    'checks': checks,
                    'dependency_completeness': dependency_status['completeness'],
                    'backup_location': backup_path,
                    'allocated_services': len(allocated)
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'production_ready_features',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_docker_compose_generation(self):
        """Docker Compose íŒŒì¼ ìƒì„± ê²€ì¦"""
        logger.info("ğŸ” Docker Compose íŒŒì¼ ìƒì„± ê²€ì¦")
        
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            from universal_port_manager.core.port_manager_docker import PortManagerDocker
            
            docker_test_dir = self.test_root / 'docker-test'
            docker_test_dir.mkdir()
            
            # Dockerfile ìƒ˜í”Œ ìƒì„±
            self._create_sample_dockerfiles(docker_test_dir)
            
            allocator = ImprovedPortAllocator()
            allocated = allocator.allocate_project_ports(
                'docker-test', 
                ['frontend', 'backend', 'mongodb', 'redis']
            )
            
            docker_manager = PortManagerDocker(docker_test_dir, 'docker-test')
            
            # Docker Compose íŒŒì¼ ìƒì„±
            compose_created = docker_manager.generate_compose_file(
                allocated, 
                include_override=True
            )
            
            # ìƒì„±ëœ íŒŒì¼ë“¤ ê²€ì¦
            compose_file = docker_test_dir / 'docker-compose.yml'
            override_file = docker_test_dir / 'docker-compose.override.yml'
            
            files_exist = compose_file.exists() and override_file.exists()
            
            # Docker Compose íŒŒì¼ ë‚´ìš© ê²€ì¦
            compose_valid = False
            if compose_file.exists():
                compose_valid = self._validate_docker_compose(compose_file, allocated)
            
            # ì„œë¹„ìŠ¤ ìƒíƒœ ì²´í¬ (Dockerê°€ ìˆìœ¼ë©´)
            docker_available = docker_manager._check_docker_availability() if hasattr(docker_manager, '_check_docker_availability') else self._check_docker_available()
            
            return {
                'test': 'docker_compose_generation',
                'success': compose_created and files_exist and compose_valid,
                'details': {
                    'compose_created': compose_created,
                    'compose_file_exists': compose_file.exists(),
                    'override_file_exists': override_file.exists(),
                    'compose_valid': compose_valid,
                    'docker_available': docker_available,
                    'services_count': len(allocated)
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'docker_compose_generation',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_scaling_scenarios(self):
        """ìŠ¤ì¼€ì¼ë§ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦"""
        logger.info("ğŸ” ìŠ¤ì¼€ì¼ë§ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦")
        
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            
            allocator = ImprovedPortAllocator()
            scaling_results = {}
            
            # ì†Œê·œëª¨ ë°°í¬ (5ê°œ ì„œë¹„ìŠ¤)
            small_services = ['frontend', 'backend', 'database', 'redis', 'nginx']
            small_allocated = allocator.allocate_project_ports('small-scale', small_services)
            
            # ì¤‘ê·œëª¨ ë°°í¬ (10ê°œ ì„œë¹„ìŠ¤)
            medium_services = small_services + ['elasticsearch', 'kibana', 'prometheus', 'grafana', 'alertmanager']
            medium_allocated = allocator.allocate_project_ports('medium-scale', medium_services)
            
            # ëŒ€ê·œëª¨ ë°°í¬ (15ê°œ ì„œë¹„ìŠ¤)
            large_services = medium_services + ['jaeger', 'consul', 'vault', 'rabbitmq', 'memcached']
            large_allocated = allocator.allocate_project_ports('large-scale', large_services)
            
            scaling_results = {
                'small': {
                    'requested': len(small_services),
                    'allocated': len(small_allocated),
                    'success': len(small_allocated) == len(small_services)
                },
                'medium': {
                    'requested': len(medium_services),
                    'allocated': len(medium_allocated),
                    'success': len(medium_allocated) == len(medium_services)
                },
                'large': {
                    'requested': len(large_services),
                    'allocated': len(large_allocated),
                    'success': len(large_allocated) == len(large_services)
                }
            }
            
            # ëª¨ë“  í¬íŠ¸ê°€ ìœ ë‹ˆí¬í•œì§€ í™•ì¸
            all_ports = []
            for allocated in [small_allocated, medium_allocated, large_allocated]:
                all_ports.extend([port.port for port in allocated.values()])
            
            unique_ports = len(set(all_ports)) == len(all_ports)
            all_scales_success = all(result['success'] for result in scaling_results.values())
            
            return {
                'test': 'scaling_scenarios',
                'success': unique_ports and all_scales_success,
                'details': {
                    'scaling_results': scaling_results,
                    'total_ports_allocated': len(all_ports),
                    'unique_ports': unique_ports,
                    'all_scales_success': all_scales_success
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'scaling_scenarios',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_backup_and_recovery(self):
        """ë°±ì—… ë° ë³µêµ¬ ê²€ì¦"""
        logger.info("ğŸ” ë°±ì—… ë° ë³µêµ¬ ê²€ì¦")
        
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            from universal_port_manager.core.port_manager_config import PortManagerConfig
            
            backup_test_dir = self.test_root / 'backup-test'
            backup_test_dir.mkdir()
            
            # ì›ë³¸ êµ¬ì„± ìƒì„±
            allocator = ImprovedPortAllocator()
            original_allocated = allocator.allocate_project_ports(
                'backup-test', 
                ['frontend', 'backend', 'database']
            )
            
            config_manager = PortManagerConfig(backup_test_dir, 'backup-test')
            
            # ì„¤ì • íŒŒì¼ ìƒì„±
            env_files = config_manager.generate_env_files(original_allocated)
            
            # ë°±ì—… ìƒì„±
            backup_name = 'test-backup'
            backup_path = config_manager.backup_config(backup_name)
            backup_exists = Path(backup_path).exists()
            
            # ë°±ì—… ëª©ë¡ í™•ì¸
            backups = config_manager.list_backups()
            backup_listed = any(b['backup_name'] == backup_name for b in backups)
            
            # í¬íŠ¸ ë³€ê²½ (ë³µêµ¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´)
            modified_allocated = allocator.allocate_project_ports(
                'backup-test-modified', 
                ['frontend', 'backend', 'database', 'redis']
            )
            
            # ë³µêµ¬ í…ŒìŠ¤íŠ¸
            recovery_success = config_manager.restore_config(backup_name)
            
            return {
                'test': 'backup_and_recovery',
                'success': backup_exists and backup_listed and recovery_success,
                'details': {
                    'backup_created': backup_exists,
                    'backup_listed': backup_listed,
                    'recovery_success': recovery_success,
                    'backup_path': backup_path,
                    'original_services': len(original_allocated),
                    'modified_services': len(modified_allocated),
                    'total_backups': len(backups)
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'backup_and_recovery',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def verify_monitoring_integration(self):
        """ëª¨ë‹ˆí„°ë§ í†µí•© ê²€ì¦"""
        logger.info("ğŸ” ëª¨ë‹ˆí„°ë§ í†µí•© ê²€ì¦")
        
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            from universal_port_manager.core.port_scanner import ImprovedPortScanner
            
            # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„œë¹„ìŠ¤ë“¤
            monitoring_services = ['prometheus', 'grafana', 'alertmanager', 'elasticsearch', 'kibana']
            
            allocator = ImprovedPortAllocator()
            scanner = ImprovedPortScanner()
            
            # ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ í¬íŠ¸ í• ë‹¹
            monitoring_allocated = allocator.allocate_project_ports(
                'monitoring-stack', 
                monitoring_services
            )
            
            # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í¬íŠ¸ í• ë‹¹
            app_allocated = allocator.allocate_project_ports(
                'main-app',
                ['frontend', 'backend', 'database']
            )
            
            # í¬íŠ¸ ì¶©ëŒ ê²€ì‚¬
            all_monitoring_ports = [port.port for port in monitoring_allocated.values()]
            all_app_ports = [port.port for port in app_allocated.values()]
            
            no_conflicts = len(set(all_monitoring_ports + all_app_ports)) == len(all_monitoring_ports + all_app_ports)
            
            # í¬íŠ¸ ìŠ¤ìº”ìœ¼ë¡œ ìƒíƒœ í™•ì¸
            scanned_ports = scanner.scan_system_ports(force_refresh=True)
            scan_successful = len(scanned_ports) > 0
            
            # í• ë‹¹ ë³´ê³ ì„œ ìƒì„±
            allocation_report = allocator.get_allocation_report()
            report_generated = len(allocation_report) > 0
            
            return {
                'test': 'monitoring_integration',
                'success': no_conflicts and scan_successful and report_generated,
                'details': {
                    'monitoring_services': len(monitoring_allocated),
                    'app_services': len(app_allocated),
                    'no_conflicts': no_conflicts,
                    'scan_successful': scan_successful,
                    'scanned_ports_count': len(scanned_ports),
                    'report_generated': report_generated,
                    'monitoring_ports': all_monitoring_ports,
                    'app_ports': all_app_ports
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'test': 'monitoring_integration',
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _create_project_structure(self, project_dir: Path):
        """ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±"""
        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ë“¤
        dirs = ['frontend', 'backend', 'config', 'scripts', 'logs']
        for dir_name in dirs:
            (project_dir / dir_name).mkdir()
        
        # ê¸°ë³¸ íŒŒì¼ë“¤
        (project_dir / 'README.md').write_text('# Online Evaluation System\n')
        (project_dir / 'package.json').write_text('{"name": "online-evaluation"}\n')
        (project_dir / 'requirements.txt').write_text('fastapi\nuvicorn\n')
    
    def _create_sample_dockerfiles(self, docker_dir: Path):
        """ìƒ˜í”Œ Dockerfileë“¤ ìƒì„±"""
        # Frontend Dockerfile
        frontend_dir = docker_dir / 'frontend'
        frontend_dir.mkdir()
        (frontend_dir / 'Dockerfile').write_text("""
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 3000
CMD ["npm", "start"]
""")
        
        # Backend Dockerfile
        backend_dir = docker_dir / 'backend'
        backend_dir.mkdir()
        (backend_dir / 'Dockerfile').write_text("""
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
""")
    
    def _verify_port_ranges(self, allocated_ports):
        """í¬íŠ¸ ë²”ìœ„ê°€ ì„œë¹„ìŠ¤ì— ì ì ˆí•œì§€ í™•ì¸"""
        for service_name, port_info in allocated_ports.items():
            port = port_info.port
            
            # ì„œë¹„ìŠ¤ë³„ ì ì ˆí•œ í¬íŠ¸ ë²”ìœ„ í™•ì¸
            if service_name == 'frontend' and not (3000 <= port <= 3999):
                return False
            elif service_name == 'backend' and not (8000 <= port <= 8999):
                return False
            elif service_name == 'mongodb' and not (27000 <= port <= 27999):
                return False
            elif service_name == 'redis' and not (6000 <= port <= 6999):
                return False
            
        return True
    
    def _check_port_persistence(self, allocator, project_name):
        """í¬íŠ¸ í• ë‹¹ì´ ì§€ì†ë˜ëŠ”ì§€ í™•ì¸"""
        try:
            # ì²« ë²ˆì§¸ í• ë‹¹
            first_allocation = allocator.allocate_project_ports(project_name, ['frontend', 'backend'])
            
            # ë‘ ë²ˆì§¸ í• ë‹¹ (ê°™ì€ í”„ë¡œì íŠ¸)
            second_allocation = allocator.allocate_project_ports(project_name, ['frontend', 'backend'])
            
            # í¬íŠ¸ê°€ ë™ì¼í•œì§€ í™•ì¸
            return (first_allocation['frontend'].port == second_allocation['frontend'].port and
                    first_allocation['backend'].port == second_allocation['backend'].port)
        except Exception:
            return False
    
    def _check_conflict_resolution(self):
        """ì¶©ëŒ í•´ê²° ê¸°ëŠ¥ í™•ì¸"""
        try:
            sys.path.insert(0, str(self.project_root))
            from universal_port_manager.core.port_allocator import ImprovedPortAllocator
            
            allocator = ImprovedPortAllocator()
            
            # ì¶©ëŒ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
            conflicts = allocator.get_port_conflicts([3000, 8000, 5432])
            alternatives = allocator.suggest_alternative_ports([3000, 8000])
            
            return len(alternatives) > 0
        except Exception:
            return False
    
    def _check_security_compliance(self, allocated_ports):
        """ë³´ì•ˆ ì»´í”Œë¼ì´ì–¸ìŠ¤ í™•ì¸"""
        for port_info in allocated_ports.values():
            # privileged í¬íŠ¸ (1024 ë¯¸ë§Œ) ì‚¬ìš© ê¸ˆì§€
            if port_info.port < 1024:
                return False
            
            # ë§¤ìš° ë†’ì€ í¬íŠ¸ (65000 ì´ìƒ) ì‚¬ìš© ê¸ˆì§€
            if port_info.port >= 65000:
                return False
        
        return True
    
    def _validate_docker_compose(self, compose_file: Path, allocated_ports):
        """Docker Compose íŒŒì¼ ìœ íš¨ì„± í™•ì¸"""
        try:
            content = compose_file.read_text()
            
            # ê¸°ë³¸ êµ¬ì¡° í™•ì¸
            required_elements = ['version:', 'services:', 'networks:']
            has_required = all(element in content for element in required_elements)
            
            # í¬íŠ¸ ë§¤í•‘ í™•ì¸
            port_mappings = []
            for port_info in allocated_ports.values():
                port_mapping = f"{port_info.port}:"
                if port_mapping in content:
                    port_mappings.append(port_mapping)
            
            has_port_mappings = len(port_mappings) > 0
            
            return has_required and has_port_mappings
        except Exception:
            return False
    
    def _check_docker_available(self):
        """Docker ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            result = subprocess.run(['docker', '--version'], 
                                  capture_output=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False
    
    def generate_deployment_report(self):
        """ë°°í¬ ê²€ì¦ ë³´ê³ ì„œ ìƒì„±"""
        successful_tests = sum(1 for r in self.results if r['success'])
        total_tests = len(self.results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        # ë°°í¬ ì¤€ë¹„ë„ í‰ê°€
        deployment_readiness = self._assess_deployment_readiness()
        
        report = {
            'overall_success': success_rate >= 85,  # 85% ì´ìƒ ì„±ê³µ
            'deployment_readiness': deployment_readiness,
            'summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': total_tests - successful_tests,
                'success_rate': success_rate
            },
            'test_results': self.results,
            'environment': {
                'test_directory': str(self.test_root),
                'online_eval_services': self.online_eval_services
            },
            'recommendations': self._generate_recommendations(),
            'timestamp': datetime.now().isoformat()
        }
        
        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_file = Path.cwd() / f'deployment_verification_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š ë°°í¬ ê²€ì¦ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        return report
    
    def _assess_deployment_readiness(self):
        """ë°°í¬ ì¤€ë¹„ë„ í‰ê°€"""
        readiness_checks = {
            'core_functionality': any(r['test'] == 'online_eval_deployment' and r['success'] for r in self.results),
            'multi_environment': any(r['test'] == 'multi_environment_deployment' and r['success'] for r in self.results),
            'production_features': any(r['test'] == 'production_ready_features' and r['success'] for r in self.results),
            'docker_integration': any(r['test'] == 'docker_compose_generation' and r['success'] for r in self.results),
            'scalability': any(r['test'] == 'scaling_scenarios' and r['success'] for r in self.results),
            'backup_recovery': any(r['test'] == 'backup_and_recovery' and r['success'] for r in self.results),
            'monitoring': any(r['test'] == 'monitoring_integration' and r['success'] for r in self.results)
        }
        
        readiness_score = sum(readiness_checks.values()) / len(readiness_checks) * 100
        
        if readiness_score >= 90:
            readiness_level = "í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ"
        elif readiness_score >= 75:
            readiness_level = "í”„ë¡œë•ì…˜ ì¤€ë¹„ ê±°ì˜ ì™„ë£Œ"
        elif readiness_score >= 60:
            readiness_level = "ì¶”ê°€ ê°œì„  í•„ìš”"
        else:
            readiness_level = "ìƒë‹¹í•œ ê°œì„  í•„ìš”"
        
        return {
            'score': readiness_score,
            'level': readiness_level,
            'checks': readiness_checks
        }
    
    def _generate_recommendations(self):
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        failed_tests = [r for r in self.results if not r['success']]
        
        for failed_test in failed_tests:
            test_name = failed_test['test']
            
            if test_name == 'online_eval_deployment':
                recommendations.append("ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ë°°í¬ êµ¬ì„±ì„ ì¬ê²€í† í•˜ì„¸ìš”.")
            elif test_name == 'multi_environment_deployment':
                recommendations.append("ë‹¤ì¤‘ í™˜ê²½ ë°°í¬ ì „ëµì„ ê°œì„ í•˜ì„¸ìš”.")
            elif test_name == 'production_ready_features':
                recommendations.append("í”„ë¡œë•ì…˜ í™˜ê²½ì— í•„ìš”í•œ ê¸°ëŠ¥ë“¤ì„ ì¶”ê°€ êµ¬í˜„í•˜ì„¸ìš”.")
            elif test_name == 'docker_compose_generation':
                recommendations.append("Docker Compose íŒŒì¼ ìƒì„± ë¡œì§ì„ ê°œì„ í•˜ì„¸ìš”.")
            elif test_name == 'scaling_scenarios':
                recommendations.append("ìŠ¤ì¼€ì¼ë§ ì§€ì›ì„ ê°•í™”í•˜ì„¸ìš”.")
            elif test_name == 'backup_and_recovery':
                recommendations.append("ë°±ì—… ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ì„ ê°œì„ í•˜ì„¸ìš”.")
            elif test_name == 'monitoring_integration':
                recommendations.append("ëª¨ë‹ˆí„°ë§ í†µí•©ì„ ê°•í™”í•˜ì„¸ìš”.")
        
        # ì¼ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
        if not recommendations:
            recommendations.extend([
                "ì •ê¸°ì ì¸ í¬íŠ¸ ì‚¬ìš© í˜„í™© ëª¨ë‹ˆí„°ë§ì„ ì„¤ì •í•˜ì„¸ìš”.",
                "í¬íŠ¸ í• ë‹¹ ì •ì±…ì„ ë¬¸ì„œí™”í•˜ì„¸ìš”.",
                "ì¬í•´ ë³µêµ¬ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”."
            ])
        
        return recommendations
    
    def cleanup(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        try:
            if self.test_root.exists():
                shutil.rmtree(self.test_root)
                logger.info(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬: {self.test_root}")
        except Exception as e:
            logger.warning(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """ë°°í¬ ê²€ì¦ ë©”ì¸"""
    verifier = DeploymentVerifier()
    
    try:
        report = verifier.run_all_verifications()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 70)
        print("ğŸ¯ ì‹¤ì œ ë°°í¬ í™˜ê²½ ë™ì‘ ê²€ì¦ ê²°ê³¼")
        print("=" * 70)
        
        if report['overall_success']:
            print("âœ… ë°°í¬ í™˜ê²½ ê²€ì¦ ì„±ê³µ!")
        else:
            print("âŒ ì¼ë¶€ ë°°í¬ ê²€ì¦ ì‹¤íŒ¨")
        
        summary = report['summary']
        print(f"\nğŸ“Š ìš”ì•½:")
        print(f"  ì „ì²´ ê²€ì¦: {summary['total_tests']}ê°œ")
        print(f"  ì„±ê³µ: {summary['successful_tests']}ê°œ")
        print(f"  ì‹¤íŒ¨: {summary['failed_tests']}ê°œ")
        print(f"  ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        
        # ë°°í¬ ì¤€ë¹„ë„
        readiness = report['deployment_readiness']
        print(f"\nğŸš€ ë°°í¬ ì¤€ë¹„ë„:")
        print(f"  ì ìˆ˜: {readiness['score']:.1f}/100")
        print(f"  ìˆ˜ì¤€: {readiness['level']}")
        
        # ì¤€ë¹„ë„ ì²´í¬ ìƒì„¸
        print(f"\nğŸ“‹ ì¤€ë¹„ë„ ì²´í¬:")
        for check_name, passed in readiness['checks'].items():
            status = "âœ…" if passed else "âŒ"
            check_display = check_name.replace('_', ' ').title()
            print(f"  {status} {check_display}")
        
        # ì‹¤íŒ¨í•œ ê²€ì¦ ìƒì„¸
        failed_tests = [r for r in report['test_results'] if not r['success']]
        if failed_tests:
            print(f"\nâŒ ì‹¤íŒ¨í•œ ê²€ì¦:")
            for test in failed_tests:
                print(f"  - {test['test']}: {test.get('error', 'Unknown error')}")
        
        # ê¶Œì¥ì‚¬í•­
        if report['recommendations']:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"  {i}. {rec}")
        
        # ìµœì¢… ê²°ë¡ 
        if report['overall_success']:
            print(f"\nğŸ‰ Universal Port Managerê°€ ì‹¤ì œ ë°°í¬ í™˜ê²½ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤!")
            print(f"   ì˜¨ë¼ì¸ í‰ê°€ ì‹œìŠ¤í…œ ë°°í¬ì— ì‚¬ìš©í•  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"\nâš ï¸ ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•˜ì§€ë§Œ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.")
        
        return 0 if report['overall_success'] else 1
        
    finally:
        verifier.cleanup()


if __name__ == '__main__':
    sys.exit(main())