#!/usr/bin/env python3
"""
Universal Port Manager í†µí•© í…ŒìŠ¤íŠ¸
================================

ì‹¤ì œ í™˜ê²½ì—ì„œ í¬íŠ¸ ì¶©ëŒ íšŒí”¼ ë° ì „ì²´ ì›Œí¬í”Œë¡œìš° ê²€ì¦
ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì™€ ì—£ì§€ ì¼€ì´ìŠ¤ë¥¼ í¬í•¨í•œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import os
import sys
import json
import time
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntegrationTestSuite:
    """
    í¬íŠ¸ ë§¤ë‹ˆì € í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
    
    í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
    1. ì˜ì¡´ì„±ë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    2. í¬íŠ¸ ì¶©ëŒ íšŒí”¼ í…ŒìŠ¤íŠ¸
    3. ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ë™ì‹œ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    4. Docker í†µí•© í…ŒìŠ¤íŠ¸
    5. CLI ëª…ë ¹ì–´ ì „ì²´ í…ŒìŠ¤íŠ¸
    6. ì‹¤ì œ í¬íŠ¸ ì‚¬ìš© í™˜ê²½ í…ŒìŠ¤íŠ¸
    """
    
    def __init__(self, test_dir: Optional[Path] = None):
        """í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì´ˆê¸°í™”"""
        self.test_dir = test_dir or Path(tempfile.mkdtemp(prefix='upm_test_'))
        self.test_results = []
        self.current_ports = self._get_system_ports()
        self.test_projects = []
        
        logger.info(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {self.test_dir}")
        logger.info(f"í˜„ì¬ ì‹œìŠ¤í…œ í¬íŠ¸ ì‚¬ìš©ëŸ‰: {len(self.current_ports)}ê°œ")
    
    def _get_system_ports(self) -> List[int]:
        """í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ ëª©ë¡"""
        used_ports = []
        
        # netstatì„ ì‚¬ìš©í•˜ì—¬ í¬íŠ¸ í™•ì¸
        try:
            result = subprocess.run(['netstat', '-tuln'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    if ':' in line and ('LISTEN' in line or 'UDP' in line):
                        try:
                            port_part = line.split()[3]
                            port = int(port_part.split(':')[-1])
                            used_ports.append(port)
                        except (ValueError, IndexError):
                            continue
        except (subprocess.TimeoutExpired, FileNotFoundError):
            # ss ëª…ë ¹ì–´ë¡œ ëŒ€ì²´ ì‹œë„
            try:
                result = subprocess.run(['ss', '-tuln'], 
                                      capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        if ':' in line and 'LISTEN' in line:
                            try:
                                port_part = line.split()[4]
                                port = int(port_part.split(':')[-1])
                                used_ports.append(port)
                            except (ValueError, IndexError):
                                continue
            except (subprocess.TimeoutExpired, FileNotFoundError):
                logger.warning("í¬íŠ¸ ìŠ¤ìº” ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ")
        
        return sorted(list(set(used_ports)))
    
    def run_all_tests(self) -> Dict:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ Universal Port Manager í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        logger.info("=" * 60)
        
        test_methods = [
            self.test_dependency_scenarios,
            self.test_port_conflict_avoidance,
            self.test_multi_project_isolation,
            self.test_cli_commands,
            self.test_docker_integration,
            self.test_real_world_scenarios,
            self.test_edge_cases,
            self.test_performance_stress
        ]
        
        for test_method in test_methods:
            try:
                logger.info(f"\nğŸ“‹ ì‹¤í–‰ ì¤‘: {test_method.__name__}")
                result = test_method()
                self.test_results.append(result)
                
                if result['success']:
                    logger.info(f"âœ… {test_method.__name__} ì„±ê³µ")
                else:
                    logger.error(f"âŒ {test_method.__name__} ì‹¤íŒ¨: {result.get('error', 'Unknown')}")
                    
            except Exception as e:
                error_result = {
                    'test_name': test_method.__name__,
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
                self.test_results.append(error_result)
                logger.error(f"ğŸ’¥ {test_method.__name__} ì˜ˆì™¸ ë°œìƒ: {e}")
        
        return self._generate_final_report()
    
    def test_dependency_scenarios(self) -> Dict:
        """ì˜ì¡´ì„± ì‹œë‚˜ë¦¬ì˜¤ë³„ í…ŒìŠ¤íŠ¸"""
        test_name = "dependency_scenarios"
        logger.info("ğŸ” ì˜ì¡´ì„± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
        
        scenarios = [
            {
                'name': 'minimal_only',
                'deps': ['click'],
                'expected_features': ['basic_scan', 'port_allocation', 'cli']
            },
            {
                'name': 'with_psutil',
                'deps': ['click', 'psutil'],
                'expected_features': ['advanced_scan', 'process_info']
            },
            {
                'name': 'with_yaml',
                'deps': ['click', 'PyYAML'],
                'expected_features': ['docker_compose_generation']
            },
            {
                'name': 'full_features',
                'deps': ['click', 'psutil', 'PyYAML', 'requests'],
                'expected_features': ['all_features']
            }
        ]
        
        results = {}
        
        for scenario in scenarios:
            logger.info(f"  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {scenario['name']}")
            
            # ê°€ìƒ í™˜ê²½ì—ì„œ ì˜ì¡´ì„± ì²´í¬ ì‹œë®¬ë ˆì´ì…˜
            try:
                # CLI doctor ëª…ë ¹ì–´ë¡œ ì˜ì¡´ì„± ìƒíƒœ í™•ì¸
                result = self._run_upm_command(['doctor', '--group', 'full'])
                
                if result['success']:
                    # ì¶œë ¥ì—ì„œ ì˜ì¡´ì„± ìƒíƒœ íŒŒì‹±
                    dependency_status = self._parse_dependency_output(result['output'])
                    results[scenario['name']] = {
                        'status': 'success',
                        'dependencies': dependency_status,
                        'features_available': len(dependency_status.get('available', []))
                    }
                else:
                    results[scenario['name']] = {
                        'status': 'failed',
                        'error': result.get('error')
                    }
                    
            except Exception as e:
                results[scenario['name']] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        # ê²°ê³¼ í‰ê°€
        success_count = sum(1 for r in results.values() if r['status'] == 'success')
        total_count = len(scenarios)
        
        return {
            'test_name': test_name,
            'success': success_count >= total_count * 0.7,  # 70% ì´ìƒ ì„±ê³µ
            'results': results,
            'summary': f"{success_count}/{total_count} ì‹œë‚˜ë¦¬ì˜¤ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_port_conflict_avoidance(self) -> Dict:
        """í¬íŠ¸ ì¶©ëŒ íšŒí”¼ í…ŒìŠ¤íŠ¸"""
        test_name = "port_conflict_avoidance"
        logger.info("ğŸ” í¬íŠ¸ ì¶©ëŒ íšŒí”¼ í…ŒìŠ¤íŠ¸")
        
        conflict_tests = []
        
        # 1. í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ íšŒí”¼ í…ŒìŠ¤íŠ¸
        logger.info("  í˜„ì¬ ì‚¬ìš© í¬íŠ¸ íšŒí”¼ í…ŒìŠ¤íŠ¸")
        try:
            # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ë¥¼ ì„ í˜¸ í¬íŠ¸ë¡œ ì§€ì •
            if self.current_ports:
                occupied_port = self.current_ports[0]
                preferred_ports = f'{{"frontend":{occupied_port},"backend":{occupied_port+1}}}'
                
                result = self._run_upm_command([
                    'allocate', 'frontend', 'backend',
                    '--preferred-ports', preferred_ports,
                    '--dry-run'
                ])
                
                if result['success']:
                    allocated_ports = self._parse_allocation_output(result['output'])
                    # í• ë‹¹ëœ í¬íŠ¸ê°€ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ì™€ ë‹¤ë¥¸ì§€ í™•ì¸
                    conflict_avoided = all(
                        port not in self.current_ports 
                        for port in allocated_ports.values()
                    )
                    
                    conflict_tests.append({
                        'name': 'avoid_occupied_ports',
                        'success': conflict_avoided,
                        'details': {
                            'occupied_port': occupied_port,
                            'allocated_ports': allocated_ports,
                            'conflict_avoided': conflict_avoided
                        }
                    })
        except Exception as e:
            conflict_tests.append({
                'name': 'avoid_occupied_ports',
                'success': False,
                'error': str(e)
            })
        
        # 2. ì—°ì† í¬íŠ¸ í• ë‹¹ í…ŒìŠ¤íŠ¸
        logger.info("  ì—°ì† í¬íŠ¸ í• ë‹¹ í…ŒìŠ¤íŠ¸")
        try:
            result = self._run_upm_command([
                'allocate', 'frontend', 'backend', 'database', 'redis',
                '--dry-run'
            ])
            
            if result['success']:
                allocated_ports = self._parse_allocation_output(result['output'])
                
                # í¬íŠ¸ê°€ ëª¨ë‘ ë‹¤ë¥¸ì§€ í™•ì¸
                unique_ports = len(set(allocated_ports.values()))
                all_unique = unique_ports == len(allocated_ports)
                
                conflict_tests.append({
                    'name': 'unique_port_allocation',
                    'success': all_unique,
                    'details': {
                        'allocated_ports': allocated_ports,
                        'unique_count': unique_ports,
                        'total_count': len(allocated_ports)
                    }
                })
        except Exception as e:
            conflict_tests.append({
                'name': 'unique_port_allocation',
                'success': False,
                'error': str(e)
            })
        
        # 3. í¬íŠ¸ ë²”ìœ„ í…ŒìŠ¤íŠ¸
        logger.info("  í¬íŠ¸ ë²”ìœ„ ì í•©ì„± í…ŒìŠ¤íŠ¸")
        try:
            result = self._run_upm_command(['allocate', 'frontend', 'backend', '--dry-run'])
            
            if result['success']:
                allocated_ports = self._parse_allocation_output(result['output'])
                
                # ì ì ˆí•œ í¬íŠ¸ ë²”ìœ„ì¸ì§€ í™•ì¸ (1024-65535)
                valid_range = all(
                    1024 <= port <= 65535 
                    for port in allocated_ports.values()
                )
                
                conflict_tests.append({
                    'name': 'valid_port_range',
                    'success': valid_range,
                    'details': {
                        'allocated_ports': allocated_ports,
                        'all_in_valid_range': valid_range
                    }
                })
        except Exception as e:
            conflict_tests.append({
                'name': 'valid_port_range',
                'success': False,
                'error': str(e)
            })
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for test in conflict_tests if test['success'])
        total_count = len(conflict_tests)
        
        return {
            'test_name': test_name,
            'success': success_count == total_count,
            'results': conflict_tests,
            'summary': f"{success_count}/{total_count} ì¶©ëŒ íšŒí”¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_multi_project_isolation(self) -> Dict:
        """ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ê²©ë¦¬ í…ŒìŠ¤íŠ¸"""
        test_name = "multi_project_isolation"
        logger.info("ğŸ” ë‹¤ì¤‘ í”„ë¡œì íŠ¸ ê²©ë¦¬ í…ŒìŠ¤íŠ¸")
        
        # í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ ìƒì„±
        projects = ['project-a', 'project-b', 'project-c']
        project_results = {}
        
        for project_name in projects:
            logger.info(f"  í”„ë¡œì íŠ¸ í…ŒìŠ¤íŠ¸: {project_name}")
            
            project_dir = self.test_dir / project_name
            project_dir.mkdir(exist_ok=True)
            
            try:
                # ê° í”„ë¡œì íŠ¸ì—ì„œ í¬íŠ¸ í• ë‹¹
                result = self._run_upm_command([
                    '--project', project_name,
                    'allocate', 'frontend', 'backend'
                ], cwd=project_dir)
                
                if result['success']:
                    allocated_ports = self._parse_allocation_output(result['output'])
                    project_results[project_name] = {
                        'status': 'success',
                        'ports': allocated_ports,
                        'directory': str(project_dir)
                    }
                    self.test_projects.append((project_name, allocated_ports))
                else:
                    project_results[project_name] = {
                        'status': 'failed',
                        'error': result.get('error')
                    }
                    
            except Exception as e:
                project_results[project_name] = {
                    'status': 'error',
                    'error': str(e)
                }
        
        # í”„ë¡œì íŠ¸ ê°„ í¬íŠ¸ ì¶©ëŒ í™•ì¸
        all_ports = []
        for project_name, project_result in project_results.items():
            if project_result['status'] == 'success':
                all_ports.extend(project_result['ports'].values())
        
        # ëª¨ë“  í¬íŠ¸ê°€ ìœ ë‹ˆí¬í•œì§€ í™•ì¸
        unique_ports = len(set(all_ports))
        no_conflicts = unique_ports == len(all_ports)
        
        # ì„±ê³µí•œ í”„ë¡œì íŠ¸ ìˆ˜
        success_projects = sum(
            1 for result in project_results.values() 
            if result['status'] == 'success'
        )
        
        return {
            'test_name': test_name,
            'success': no_conflicts and success_projects >= 2,
            'results': {
                'project_results': project_results,
                'total_ports': len(all_ports),
                'unique_ports': unique_ports,
                'no_conflicts': no_conflicts,
                'success_projects': success_projects
            },
            'summary': f"{success_projects}/{len(projects)} í”„ë¡œì íŠ¸ ì„±ê³µ, ì¶©ëŒ ì—†ìŒ: {no_conflicts}",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_cli_commands(self) -> Dict:
        """CLI ëª…ë ¹ì–´ ì „ì²´ í…ŒìŠ¤íŠ¸"""
        test_name = "cli_commands"
        logger.info("ğŸ” CLI ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸")
        
        commands_to_test = [
            {
                'name': 'doctor',
                'cmd': ['doctor'],
                'expect_success': True
            },
            {
                'name': 'scan',
                'cmd': ['scan', '--range', '3000-3010'],
                'expect_success': True
            },
            {
                'name': 'allocate',
                'cmd': ['allocate', 'frontend', 'backend', '--dry-run'],
                'expect_success': True
            },
            {
                'name': 'status',
                'cmd': ['status'],
                'expect_success': True  # í• ë‹¹ëœ í¬íŠ¸ê°€ ì—†ì–´ë„ ì„±ê³µí•´ì•¼ í•¨
            },
            {
                'name': 'doctor_with_report',
                'cmd': ['doctor', '--report'],
                'expect_success': True
            }
        ]
        
        command_results = {}
        
        for cmd_test in commands_to_test:
            logger.info(f"  CLI ëª…ë ¹ì–´: {' '.join(cmd_test['cmd'])}")
            
            try:
                result = self._run_upm_command(cmd_test['cmd'])
                
                command_results[cmd_test['name']] = {
                    'success': result['success'] == cmd_test['expect_success'],
                    'output_length': len(result.get('output', '')),
                    'has_output': bool(result.get('output', '').strip()),
                    'execution_time': result.get('execution_time', 0)
                }
                
            except Exception as e:
                command_results[cmd_test['name']] = {
                    'success': False,
                    'error': str(e)
                }
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for result in command_results.values() if result['success'])
        total_count = len(commands_to_test)
        
        return {
            'test_name': test_name,
            'success': success_count >= total_count * 0.8,  # 80% ì´ìƒ ì„±ê³µ
            'results': command_results,
            'summary': f"{success_count}/{total_count} CLI ëª…ë ¹ì–´ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_docker_integration(self) -> Dict:
        """Docker í†µí•© í…ŒìŠ¤íŠ¸"""
        test_name = "docker_integration"
        logger.info("ğŸ” Docker í†µí•© í…ŒìŠ¤íŠ¸")
        
        docker_tests = []
        
        # Docker ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        docker_available = self._check_docker_availability()
        
        if not docker_available:
            return {
                'test_name': test_name,
                'success': True,  # Dockerê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                'results': {'docker_available': False},
                'summary': "Docker ì—†ìŒ - í…ŒìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸°",
                'timestamp': datetime.now().isoformat()
            }
        
        # 1. Docker Compose íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸
        logger.info("  Docker Compose ìƒì„± í…ŒìŠ¤íŠ¸")
        try:
            # í¬íŠ¸ í• ë‹¹ í›„ ì„¤ì • íŒŒì¼ ìƒì„±
            project_dir = self.test_dir / 'docker-test'
            project_dir.mkdir(exist_ok=True)
            
            alloc_result = self._run_upm_command([
                'allocate', 'frontend', 'backend', 'mongodb'
            ], cwd=project_dir)
            
            if alloc_result['success']:
                gen_result = self._run_upm_command(['generate'], cwd=project_dir)
                
                if gen_result['success']:
                    # Docker Compose íŒŒì¼ í™•ì¸
                    compose_file = project_dir / 'docker-compose.yml'
                    compose_exists = compose_file.exists()
                    
                    docker_tests.append({
                        'name': 'compose_file_generation',
                        'success': compose_exists,
                        'details': {
                            'file_exists': compose_exists,
                            'file_size': compose_file.stat().st_size if compose_exists else 0
                        }
                    })
                else:
                    docker_tests.append({
                        'name': 'compose_file_generation',
                        'success': False,
                        'error': 'generate ëª…ë ¹ ì‹¤íŒ¨'
                    })
            else:
                docker_tests.append({
                    'name': 'compose_file_generation',
                    'success': False,
                    'error': 'allocate ëª…ë ¹ ì‹¤íŒ¨'
                })
                
        except Exception as e:
            docker_tests.append({
                'name': 'compose_file_generation',
                'success': False,
                'error': str(e)
            })
        
        # 2. í™˜ê²½ íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸
        logger.info("  í™˜ê²½ íŒŒì¼ ìƒì„± í…ŒìŠ¤íŠ¸")
        try:
            project_dir = self.test_dir / 'env-test'
            project_dir.mkdir(exist_ok=True)
            
            # í¬íŠ¸ í• ë‹¹ ë° í™˜ê²½ íŒŒì¼ ìƒì„±
            result = self._run_upm_command([
                'allocate', 'frontend', 'backend'
            ], cwd=project_dir)
            
            if result['success']:
                gen_result = self._run_upm_command([
                    'generate', '--formats', 'docker', 'bash', 'json'
                ], cwd=project_dir)
                
                if gen_result['success']:
                    env_files = ['.env', 'set_ports.sh', 'ports.json']
                    files_exist = [
                        (project_dir / file).exists() 
                        for file in env_files
                    ]
                    
                    docker_tests.append({
                        'name': 'env_file_generation',
                        'success': all(files_exist),
                        'details': {
                            'files_created': sum(files_exist),
                            'total_files': len(env_files),
                            'file_status': dict(zip(env_files, files_exist))
                        }
                    })
                else:
                    docker_tests.append({
                        'name': 'env_file_generation',
                        'success': False,
                        'error': 'generate ëª…ë ¹ ì‹¤íŒ¨'
                    })
            else:
                docker_tests.append({
                    'name': 'env_file_generation',
                    'success': False,
                    'error': 'allocate ëª…ë ¹ ì‹¤íŒ¨'
                })
                
        except Exception as e:
            docker_tests.append({
                'name': 'env_file_generation',
                'success': False,
                'error': str(e)
            })
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for test in docker_tests if test['success'])
        total_count = len(docker_tests)
        
        return {
            'test_name': test_name,
            'success': success_count == total_count,
            'results': {
                'docker_available': docker_available,
                'tests': docker_tests
            },
            'summary': f"{success_count}/{total_count} Docker í…ŒìŠ¤íŠ¸ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_real_world_scenarios(self) -> Dict:
        """ì‹¤ì œ í™˜ê²½ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        test_name = "real_world_scenarios"
        logger.info("ğŸ” ì‹¤ì œ í™˜ê²½ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸")
        
        scenarios = []
        
        # 1. ë†’ì€ í¬íŠ¸ ì‚¬ìš©ë¥  í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
        logger.info("  ë†’ì€ í¬íŠ¸ ì‚¬ìš©ë¥  ì‹œë‚˜ë¦¬ì˜¤")
        try:
            # ë§ì€ ì„œë¹„ìŠ¤ ë™ì‹œ í• ë‹¹ ìš”ì²­
            services = [
                'frontend', 'backend', 'database', 'redis', 'nginx',
                'monitoring', 'elasticsearch', 'kibana', 'prometheus'
            ]
            
            result = self._run_upm_command(['allocate'] + services + ['--dry-run'])
            
            if result['success']:
                allocated_ports = self._parse_allocation_output(result['output'])
                all_allocated = len(allocated_ports) == len(services)
                
                scenarios.append({
                    'name': 'high_port_usage',
                    'success': all_allocated,
                    'details': {
                        'requested_services': len(services),
                        'allocated_services': len(allocated_ports),
                        'all_allocated': all_allocated
                    }
                })
            else:
                scenarios.append({
                    'name': 'high_port_usage',
                    'success': False,
                    'error': result.get('error')
                })
                
        except Exception as e:
            scenarios.append({
                'name': 'high_port_usage',
                'success': False,
                'error': str(e)
            })
        
        # 2. ì„ í˜¸ í¬íŠ¸ê°€ ëª¨ë‘ ì‚¬ìš© ì¤‘ì¸ ì‹œë‚˜ë¦¬ì˜¤
        logger.info("  ì„ í˜¸ í¬íŠ¸ ì¶©ëŒ ì‹œë‚˜ë¦¬ì˜¤")
        try:
            if self.current_ports and len(self.current_ports) >= 2:
                # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ë“¤ì„ ì„ í˜¸ í¬íŠ¸ë¡œ ì§€ì •
                occupied_ports = self.current_ports[:2]
                preferred_ports = f'{{"frontend":{occupied_ports[0]},"backend":{occupied_ports[1]}}}'
                
                result = self._run_upm_command([
                    'allocate', 'frontend', 'backend',
                    '--preferred-ports', preferred_ports,
                    '--dry-run'
                ])
                
                if result['success']:
                    allocated_ports = self._parse_allocation_output(result['output'])
                    avoided_conflicts = all(
                        port not in occupied_ports 
                        for port in allocated_ports.values()
                    )
                    
                    scenarios.append({
                        'name': 'preferred_port_conflicts',
                        'success': avoided_conflicts,
                        'details': {
                            'occupied_ports': occupied_ports,
                            'allocated_ports': allocated_ports,
                            'conflicts_avoided': avoided_conflicts
                        }
                    })
                else:
                    scenarios.append({
                        'name': 'preferred_port_conflicts',
                        'success': False,
                        'error': result.get('error')
                    })
            else:
                scenarios.append({
                    'name': 'preferred_port_conflicts',
                    'success': True,  # ì¶©ëŒí•  í¬íŠ¸ê°€ ì—†ìœ¼ë©´ ì„±ê³µ
                    'details': {'insufficient_occupied_ports': True}
                })
                
        except Exception as e:
            scenarios.append({
                'name': 'preferred_port_conflicts',
                'success': False,
                'error': str(e)
            })
        
        # 3. ì—°ì† í¬íŠ¸ í• ë‹¹/í•´ì œ ì‹œë‚˜ë¦¬ì˜¤
        logger.info("  ì—°ì† ì‘ì—… ì‹œë‚˜ë¦¬ì˜¤")
        try:
            operations_success = []
            
            # í• ë‹¹ -> ìƒíƒœ í™•ì¸ -> ì •ë¦¬ -> ì¬í• ë‹¹
            operations = [
                (['allocate', 'frontend', 'backend'], 'allocate'),
                (['status'], 'status'),
                (['cleanup'], 'cleanup'),
                (['allocate', 'database', 'redis'], 're_allocate')
            ]
            
            for cmd, op_name in operations:
                op_result = self._run_upm_command(cmd)
                operations_success.append(op_result['success'])
                
                if not op_result['success']:
                    break
            
            all_operations_success = all(operations_success)
            
            scenarios.append({
                'name': 'continuous_operations',
                'success': all_operations_success,
                'details': {
                    'operations_tested': len(operations),
                    'operations_success': operations_success,
                    'all_success': all_operations_success
                }
            })
            
        except Exception as e:
            scenarios.append({
                'name': 'continuous_operations',
                'success': False,
                'error': str(e)
            })
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for scenario in scenarios if scenario['success'])
        total_count = len(scenarios)
        
        return {
            'test_name': test_name,
            'success': success_count >= total_count * 0.8,  # 80% ì´ìƒ ì„±ê³µ
            'results': scenarios,
            'summary': f"{success_count}/{total_count} ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_edge_cases(self) -> Dict:
        """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        test_name = "edge_cases"
        logger.info("ğŸ” ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
        
        edge_cases = []
        
        # 1. ì˜ëª»ëœ í¬íŠ¸ ë²”ìœ„
        logger.info("  ì˜ëª»ëœ í¬íŠ¸ ë²”ìœ„ í…ŒìŠ¤íŠ¸")
        try:
            result = self._run_upm_command(['scan', '--range', 'invalid-range'])
            
            # ì‹¤íŒ¨í•´ì•¼ ì •ìƒ (ì˜ëª»ëœ ì…ë ¥ì´ë¯€ë¡œ)
            edge_cases.append({
                'name': 'invalid_port_range',
                'success': not result['success'],
                'details': {'correctly_rejected': not result['success']}
            })
            
        except Exception as e:
            edge_cases.append({
                'name': 'invalid_port_range',
                'success': True,  # ì˜ˆì™¸ ë°œìƒë„ ì •ìƒì ì¸ ì²˜ë¦¬
                'details': {'exception_handled': True}
            })
        
        # 2. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ íƒ€ì…
        logger.info("  ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ íƒ€ì… í…ŒìŠ¤íŠ¸")
        try:
            result = self._run_upm_command([
                'allocate', 'nonexistent_service_type', '--dry-run'
            ])
            
            # ì‹¤íŒ¨í•˜ê±°ë‚˜ ê¸°ë³¸ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
            edge_cases.append({
                'name': 'nonexistent_service',
                'success': True,  # ì–´ë–¤ ê²°ê³¼ë“  í¬ë˜ì‹œí•˜ì§€ ì•Šìœ¼ë©´ ì„±ê³µ
                'details': {
                    'handled_gracefully': True,
                    'command_success': result['success']
                }
            })
            
        except Exception as e:
            edge_cases.append({
                'name': 'nonexistent_service',
                'success': False,
                'error': str(e)
            })
        
        # 3. ì˜ëª»ëœ JSON í˜•ì‹
        logger.info("  ì˜ëª»ëœ JSON í˜•ì‹ í…ŒìŠ¤íŠ¸")
        try:
            result = self._run_upm_command([
                'allocate', 'frontend', 'backend',
                '--preferred-ports', '{invalid_json}',
                '--dry-run'
            ])
            
            # ì‹¤íŒ¨í•´ì•¼ ì •ìƒ
            edge_cases.append({
                'name': 'invalid_json',
                'success': not result['success'],
                'details': {'correctly_rejected': not result['success']}
            })
            
        except Exception as e:
            edge_cases.append({
                'name': 'invalid_json',
                'success': True,  # ì˜ˆì™¸ ì²˜ë¦¬ë„ ì •ìƒ
                'details': {'exception_handled': True}
            })
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for case in edge_cases if case['success'])
        total_count = len(edge_cases)
        
        return {
            'test_name': test_name,
            'success': success_count == total_count,
            'results': edge_cases,
            'summary': f"{success_count}/{total_count} ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬ ì„±ê³µ",
            'timestamp': datetime.now().isoformat()
        }
    
    def test_performance_stress(self) -> Dict:
        """ì„±ëŠ¥ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        test_name = "performance_stress"
        logger.info("ğŸ” ì„±ëŠ¥ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸")
        
        performance_tests = []
        
        # 1. ëŒ€ìš©ëŸ‰ í¬íŠ¸ ìŠ¤ìº” ì„±ëŠ¥
        logger.info("  ëŒ€ìš©ëŸ‰ í¬íŠ¸ ìŠ¤ìº” ì„±ëŠ¥")
        try:
            start_time = time.time()
            result = self._run_upm_command(['scan', '--range', '3000-4000'])
            end_time = time.time()
            
            execution_time = end_time - start_time
            acceptable_time = 30.0  # 30ì´ˆ ì´ë‚´
            
            performance_tests.append({
                'name': 'large_port_scan',
                'success': result['success'] and execution_time < acceptable_time,
                'details': {
                    'execution_time': execution_time,
                    'acceptable_time': acceptable_time,
                    'within_limit': execution_time < acceptable_time
                }
            })
            
        except Exception as e:
            performance_tests.append({
                'name': 'large_port_scan',
                'success': False,
                'error': str(e)
            })
        
        # 2. ë‹¤ì¤‘ ì„œë¹„ìŠ¤ í• ë‹¹ ì„±ëŠ¥
        logger.info("  ë‹¤ì¤‘ ì„œë¹„ìŠ¤ í• ë‹¹ ì„±ëŠ¥")
        try:
            services = ['frontend', 'backend', 'database', 'redis', 'nginx'] * 3  # 15ê°œ ì„œë¹„ìŠ¤
            
            start_time = time.time()
            result = self._run_upm_command(['allocate'] + services + ['--dry-run'])
            end_time = time.time()
            
            execution_time = end_time - start_time
            acceptable_time = 10.0  # 10ì´ˆ ì´ë‚´
            
            performance_tests.append({
                'name': 'multi_service_allocation',
                'success': result['success'] and execution_time < acceptable_time,
                'details': {
                    'services_count': len(services),
                    'execution_time': execution_time,
                    'acceptable_time': acceptable_time,
                    'within_limit': execution_time < acceptable_time
                }
            })
            
        except Exception as e:
            performance_tests.append({
                'name': 'multi_service_allocation',
                'success': False,
                'error': str(e)
            })
        
        # 3. ë°˜ë³µ ì‘ì—… ì„±ëŠ¥
        logger.info("  ë°˜ë³µ ì‘ì—… ì„±ëŠ¥")
        try:
            iterations = 5
            total_time = 0
            success_count = 0
            
            for i in range(iterations):
                start_time = time.time()
                result = self._run_upm_command(['doctor'])
                end_time = time.time()
                
                total_time += (end_time - start_time)
                if result['success']:
                    success_count += 1
            
            avg_time = total_time / iterations
            acceptable_avg_time = 5.0  # í‰ê·  5ì´ˆ ì´ë‚´
            
            performance_tests.append({
                'name': 'repeated_operations',
                'success': success_count == iterations and avg_time < acceptable_avg_time,
                'details': {
                    'iterations': iterations,
                    'success_count': success_count,
                    'total_time': total_time,
                    'avg_time': avg_time,
                    'acceptable_avg_time': acceptable_avg_time
                }
            })
            
        except Exception as e:
            performance_tests.append({
                'name': 'repeated_operations',
                'success': False,
                'error': str(e)
            })
        
        # ê²°ê³¼ ì¢…í•©
        success_count = sum(1 for test in performance_tests if test['success'])
        total_count = len(performance_tests)
        
        return {
            'test_name': test_name,
            'success': success_count >= total_count * 0.7,  # 70% ì´ìƒ ì„±ê³µ
            'results': performance_tests,
            'summary': f"{success_count}/{total_count} ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼",
            'timestamp': datetime.now().isoformat()
        }
    
    def _run_upm_command(self, args: List[str], cwd: Optional[Path] = None) -> Dict:
        """UPM ëª…ë ¹ì–´ ì‹¤í–‰"""
        cmd = [sys.executable, '-m', 'universal_port_manager'] + args
        
        try:
            start_time = time.time()
            result = subprocess.run(
                cmd,
                cwd=cwd or self.test_dir,
                capture_output=True,
                text=True,
                timeout=60
            )
            end_time = time.time()
            
            return {
                'success': result.returncode == 0,
                'output': result.stdout,
                'error': result.stderr,
                'execution_time': end_time - start_time,
                'returncode': result.returncode
            }
            
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': 'Command timeout',
                'execution_time': 60.0
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'execution_time': 0
            }
    
    def _parse_dependency_output(self, output: str) -> Dict:
        """ì˜ì¡´ì„± ì¶œë ¥ íŒŒì‹±"""
        # ê°„ë‹¨í•œ íŒŒì‹± - ì‹¤ì œë¡œëŠ” ë” ì •êµí•˜ê²Œ êµ¬í˜„
        available = []
        missing = []
        
        for line in output.split('\n'):
            if 'âœ…' in line:
                available.append(line.strip())
            elif 'âŒ' in line:
                missing.append(line.strip())
        
        return {
            'available': available,
            'missing': missing
        }
    
    def _parse_allocation_output(self, output: str) -> Dict[str, int]:
        """í¬íŠ¸ í• ë‹¹ ì¶œë ¥ íŒŒì‹±"""
        allocated_ports = {}
        
        for line in output.split('\n'):
            if 'ğŸ”Œ' in line and ':' in line:
                try:
                    # ì˜ˆ: "  ğŸ”Œ frontend        : 3001 (frontend)"
                    parts = line.strip().split(':')
                    if len(parts) >= 2:
                        service_name = parts[0].replace('ğŸ”Œ', '').strip()
                        port_part = parts[1].strip().split()[0]
                        port = int(port_part)
                        allocated_ports[service_name] = port
                except (ValueError, IndexError):
                    continue
        
        return allocated_ports
    
    def _check_docker_availability(self) -> bool:
        """Docker ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            result = subprocess.run(
                ['docker', '--version'],
                capture_output=True,
                timeout=10
            )
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError):
            return False
    
    def _generate_final_report(self) -> Dict:
        """ìµœì¢… í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        total_tests = len(self.test_results)
        successful_tests = sum(1 for result in self.test_results if result['success'])
        
        overall_success = successful_tests >= total_tests * 0.8  # 80% ì´ìƒ ì„±ê³µ
        
        report = {
            'overall_success': overall_success,
            'summary': {
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': total_tests - successful_tests,
                'success_rate': (successful_tests / total_tests * 100) if total_tests > 0 else 0
            },
            'test_results': self.test_results,
            'environment': {
                'current_ports_count': len(self.current_ports),
                'test_directory': str(self.test_dir),
                'projects_created': len(self.test_projects)
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # ë³´ê³ ì„œ íŒŒì¼ ì €ì¥
        report_file = Path.cwd() / f'integration_test_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š ìµœì¢… ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        return report
    
    def cleanup(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        try:
            if self.test_dir.exists():
                import shutil
                shutil.rmtree(self.test_dir)
                logger.info(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬: {self.test_dir}")
        except Exception as e:
            logger.warning(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


def main():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Universal Port Manager í†µí•© í…ŒìŠ¤íŠ¸')
    parser.add_argument('--test-dir', type=Path, help='í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬')
    parser.add_argument('--cleanup', action='store_true', help='í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬')
    parser.add_argument('--verbose', '-v', action='store_true', help='ìƒì„¸ ë¡œê·¸')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_suite = IntegrationTestSuite(args.test_dir)
    
    try:
        report = test_suite.run_all_tests()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 60)
        print("ğŸ¯ UNIVERSAL PORT MANAGER í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼")
        print("=" * 60)
        
        if report['overall_success']:
            print("âœ… ì „ì²´ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        else:
            print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        
        summary = report['summary']
        print(f"\nğŸ“Š ìš”ì•½:")
        print(f"  ì „ì²´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}ê°œ")
        print(f"  ì„±ê³µ: {summary['successful_tests']}ê°œ")
        print(f"  ì‹¤íŒ¨: {summary['failed_tests']}ê°œ") 
        print(f"  ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ìƒì„¸
        failed_tests = [r for r in report['test_results'] if not r['success']]
        if failed_tests:
            print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
            for test in failed_tests:
                print(f"  - {test['test_name']}: {test.get('error', 'Unknown error')}")
        
        return 0 if report['overall_success'] else 1
        
    finally:
        if args.cleanup:
            test_suite.cleanup()


if __name__ == '__main__':
    sys.exit(main())