#!/usr/bin/env python3
"""
ğŸ“Š AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ëª¨ë‹ˆí„°ë§ ë° í”„ë¡œíŒŒì¼ë§ ë„êµ¬
ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§, APM, ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ
"""

import asyncio
import time
import json
import psutil
import logging
import threading
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import statistics
from collections import deque, defaultdict
import subprocess
import os
import socket

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ ìœ í˜•"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"

class AlertLevel(Enum):
    """ì•Œë¦¼ ë ˆë²¨"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class Metric:
    """ë©”íŠ¸ë¦­ ë°ì´í„°"""
    name: str
    value: float
    timestamp: datetime
    tags: Dict[str, str]
    metric_type: MetricType

@dataclass
class Alert:
    """ì•Œë¦¼ ë°ì´í„°"""
    id: str
    level: AlertLevel
    title: str
    message: str
    timestamp: datetime
    metric_name: str
    current_value: float
    threshold_value: float
    resolved: bool = False

@dataclass
class SystemHealth:
    """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ"""
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_io: Dict[str, float]
    process_count: int
    uptime_seconds: float
    load_average: List[float]

class MetricsCollector:
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, collection_interval: int = 10):
        self.collection_interval = collection_interval
        self.metrics: deque = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ ë©”íŠ¸ë¦­
        self.custom_metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        self.is_collecting = False
        self.logger = logging.getLogger(__name__)
        
        # ì‹œìŠ¤í…œ ê¸°ì¤€ ë©”íŠ¸ë¦­
        self.baseline_metrics = {
            'cpu_usage': 0.0,
            'memory_usage': 0.0,
            'response_time': 0.0,
            'throughput': 0.0
        }
        
    def start_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘"""
        self.is_collecting = True
        self.logger.info("ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘")
        
        # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜ì§‘
        collection_thread = threading.Thread(target=self._collect_system_metrics)
        collection_thread.daemon = True
        collection_thread.start()
        
    def stop_collection(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€"""
        self.is_collecting = False
        self.logger.info("ğŸ›‘ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì¤‘ì§€")
        
    def _collect_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        while self.is_collecting:
            try:
                timestamp = datetime.now()
                
                # CPU ì‚¬ìš©ë¥ 
                cpu_usage = psutil.cpu_percent(interval=1)
                self._add_metric("system.cpu.usage", cpu_usage, timestamp, {"unit": "percent"})
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                memory = psutil.virtual_memory()
                self._add_metric("system.memory.usage", memory.percent, timestamp, {"unit": "percent"})
                self._add_metric("system.memory.available", memory.available / (1024**3), timestamp, {"unit": "GB"})
                
                # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
                disk = psutil.disk_usage('/')
                disk_usage = (disk.used / disk.total) * 100
                self._add_metric("system.disk.usage", disk_usage, timestamp, {"unit": "percent"})
                
                # ë„¤íŠ¸ì›Œí¬ I/O
                network = psutil.net_io_counters()
                self._add_metric("system.network.bytes_sent", network.bytes_sent, timestamp, {"unit": "bytes"})
                self._add_metric("system.network.bytes_recv", network.bytes_recv, timestamp, {"unit": "bytes"})
                
                # í”„ë¡œì„¸ìŠ¤ ìˆ˜
                process_count = len(psutil.pids())
                self._add_metric("system.process.count", process_count, timestamp, {"unit": "count"})
                
                # ë¡œë“œ í‰ê·  (Unix ì‹œìŠ¤í…œ)
                if hasattr(os, 'getloadavg'):
                    load_avg = os.getloadavg()
                    self._add_metric("system.load.1min", load_avg[0], timestamp, {"unit": "load"})
                    self._add_metric("system.load.5min", load_avg[1], timestamp, {"unit": "load"})
                    self._add_metric("system.load.15min", load_avg[2], timestamp, {"unit": "load"})
                
            except Exception as e:
                self.logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                
            time.sleep(self.collection_interval)
            
    def _add_metric(self, name: str, value: float, timestamp: datetime, tags: Dict[str, str]):
        """ë©”íŠ¸ë¦­ ì¶”ê°€"""
        metric = Metric(
            name=name,
            value=value,
            timestamp=timestamp,
            tags=tags,
            metric_type=MetricType.GAUGE
        )
        self.metrics.append(metric)
        
    def record_custom_metric(self, name: str, value: float, tags: Dict[str, str] = None):
        """ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        tags = tags or {}
        timestamp = datetime.now()
        
        metric = Metric(
            name=name,
            value=value,
            timestamp=timestamp,
            tags=tags,
            metric_type=MetricType.GAUGE
        )
        
        self.custom_metrics[name].append(metric)
        
    def get_latest_metrics(self, metric_name: str = None, limit: int = 10) -> List[Metric]:
        """ìµœì‹  ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        if metric_name:
            return list(self.custom_metrics.get(metric_name, deque()))[-limit:]
        else:
            return list(self.metrics)[-limit:]
            
    def get_metric_summary(self, metric_name: str, duration_minutes: int = 60) -> Dict[str, float]:
        """ë©”íŠ¸ë¦­ ìš”ì•½ í†µê³„"""
        cutoff_time = datetime.now() - timedelta(minutes=duration_minutes)
        
        # í•´ë‹¹ ë©”íŠ¸ë¦­ í•„í„°ë§
        filtered_metrics = [
            m for m in self.metrics 
            if m.name == metric_name and m.timestamp >= cutoff_time
        ]
        
        if not filtered_metrics:
            return {}
            
        values = [m.value for m in filtered_metrics]
        
        return {
            'count': len(values),
            'min': min(values),
            'max': max(values),
            'mean': statistics.mean(values),
            'median': statistics.median(values),
            'std_dev': statistics.stdev(values) if len(values) > 1 else 0,
            'latest': values[-1] if values else 0
        }

class ApplicationProfiler:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œíŒŒì¼ëŸ¬"""
    
    def __init__(self):
        self.request_times: deque = deque(maxlen=1000)
        self.endpoint_stats: Dict[str, List[float]] = defaultdict(list)
        self.database_query_times: deque = deque(maxlen=500)
        self.error_counts: Dict[str, int] = defaultdict(int)
        self.logger = logging.getLogger(__name__)
        
    def profile_request(self, endpoint: str, execution_time: float, status_code: int):
        """ìš”ì²­ í”„ë¡œíŒŒì¼ë§"""
        timestamp = datetime.now()
        
        # ì „ì²´ ìš”ì²­ ì‹œê°„ ê¸°ë¡
        self.request_times.append({
            'endpoint': endpoint,
            'time': execution_time,
            'status_code': status_code,
            'timestamp': timestamp
        })
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ í†µê³„
        self.endpoint_stats[endpoint].append(execution_time)
        
        # ì—ëŸ¬ ì¹´ìš´íŠ¸
        if status_code >= 400:
            self.error_counts[f"{endpoint}_{status_code}"] += 1
            
    def profile_database_query(self, query_type: str, execution_time: float):
        """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ í”„ë¡œíŒŒì¼ë§"""
        self.database_query_times.append({
            'query_type': query_type,
            'time': execution_time,
            'timestamp': datetime.now()
        })
        
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.request_times:
            return {"message": "ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
        # ìµœê·¼ ìš”ì²­ë“¤ ë¶„ì„
        recent_requests = list(self.request_times)[-100:]  # ìµœê·¼ 100ê°œ
        request_times = [r['time'] for r in recent_requests]
        
        # ì‘ë‹µì‹œê°„ í†µê³„
        response_time_stats = {
            'avg_response_time': statistics.mean(request_times),
            'p50_response_time': statistics.median(request_times),
            'p95_response_time': sorted(request_times)[int(len(request_times) * 0.95)] if request_times else 0,
            'p99_response_time': sorted(request_times)[int(len(request_times) * 0.99)] if request_times else 0,
            'max_response_time': max(request_times),
            'min_response_time': min(request_times)
        }
        
        # ì—”ë“œí¬ì¸íŠ¸ë³„ ì„±ëŠ¥
        endpoint_performance = {}
        for endpoint, times in self.endpoint_stats.items():
            if times:
                endpoint_performance[endpoint] = {
                    'avg_time': statistics.mean(times[-50:]),  # ìµœê·¼ 50ê°œ
                    'request_count': len(times),
                    'max_time': max(times[-50:]),
                    'min_time': min(times[-50:])
                }
                
        # ì—ëŸ¬ìœ¨ ê³„ì‚°
        total_requests = len(recent_requests)
        error_requests = len([r for r in recent_requests if r['status_code'] >= 400])
        error_rate = (error_requests / total_requests * 100) if total_requests > 0 else 0
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥
        db_performance = {}
        if self.database_query_times:
            recent_db_queries = list(self.database_query_times)[-100:]
            db_times = [q['time'] for q in recent_db_queries]
            db_performance = {
                'avg_query_time': statistics.mean(db_times),
                'query_count': len(db_times),
                'max_query_time': max(db_times),
                'slow_queries': len([t for t in db_times if t > 1.0])  # 1ì´ˆ ì´ìƒ
            }
            
        return {
            'response_time_stats': response_time_stats,
            'endpoint_performance': endpoint_performance,
            'error_rate': error_rate,
            'database_performance': db_performance,
            'total_requests': total_requests,
            'analysis_period': f"ìµœê·¼ {len(recent_requests)}ê°œ ìš”ì²­"
        }
        
    def get_slow_endpoints(self, threshold_seconds: float = 2.0) -> List[Dict[str, Any]]:
        """ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ ì‹ë³„"""
        slow_endpoints = []
        
        for endpoint, times in self.endpoint_stats.items():
            if times:
                avg_time = statistics.mean(times[-20:])  # ìµœê·¼ 20ê°œ í‰ê· 
                if avg_time > threshold_seconds:
                    slow_endpoints.append({
                        'endpoint': endpoint,
                        'avg_response_time': avg_time,
                        'max_response_time': max(times[-20:]),
                        'request_count': len(times[-20:])
                    })
                    
        return sorted(slow_endpoints, key=lambda x: x['avg_response_time'], reverse=True)

class AlertManager:
    """ì•Œë¦¼ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.alert_rules: List[Dict[str, Any]] = []
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: deque = deque(maxlen=1000)
        self.notification_callbacks: List[Callable] = []
        self.logger = logging.getLogger(__name__)
        
        # ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •
        self._setup_default_rules()
        
    def _setup_default_rules(self):
        """ê¸°ë³¸ ì•Œë¦¼ ê·œì¹™ ì„¤ì •"""
        self.alert_rules = [
            {
                'name': 'high_cpu_usage',
                'metric': 'system.cpu.usage',
                'threshold': 80.0,
                'operator': '>',
                'level': AlertLevel.WARNING,
                'duration_minutes': 5
            },
            {
                'name': 'high_memory_usage',
                'metric': 'system.memory.usage',
                'threshold': 85.0,
                'operator': '>',
                'level': AlertLevel.WARNING,
                'duration_minutes': 3
            },
            {
                'name': 'disk_space_low',
                'metric': 'system.disk.usage',
                'threshold': 90.0,
                'operator': '>',
                'level': AlertLevel.ERROR,
                'duration_minutes': 1
            },
            {
                'name': 'high_response_time',
                'metric': 'app.response_time',
                'threshold': 5.0,
                'operator': '>',
                'level': AlertLevel.WARNING,
                'duration_minutes': 2
            },
            {
                'name': 'high_error_rate',
                'metric': 'app.error_rate',
                'threshold': 5.0,
                'operator': '>',
                'level': AlertLevel.ERROR,
                'duration_minutes': 1
            }
        ]
        
    def add_alert_rule(self, name: str, metric: str, threshold: float, 
                      operator: str, level: AlertLevel, duration_minutes: int = 5):
        """ì•Œë¦¼ ê·œì¹™ ì¶”ê°€"""
        rule = {
            'name': name,
            'metric': metric,
            'threshold': threshold,
            'operator': operator,
            'level': level,
            'duration_minutes': duration_minutes
        }
        self.alert_rules.append(rule)
        
    def check_alerts(self, metrics: List[Metric]):
        """ì•Œë¦¼ ê·œì¹™ í™•ì¸"""
        for rule in self.alert_rules:
            metric_name = rule['metric']
            threshold = rule['threshold']
            operator = rule['operator']
            
            # í•´ë‹¹ ë©”íŠ¸ë¦­ ì°¾ê¸°
            relevant_metrics = [m for m in metrics if m.name == metric_name]
            
            if not relevant_metrics:
                continue
                
            latest_metric = relevant_metrics[-1]
            current_value = latest_metric.value
            
            # ì„ê³„ê°’ í™•ì¸
            alert_triggered = False
            if operator == '>' and current_value > threshold:
                alert_triggered = True
            elif operator == '<' and current_value < threshold:
                alert_triggered = True
            elif operator == '=' and current_value == threshold:
                alert_triggered = True
                
            if alert_triggered:
                self._trigger_alert(rule, current_value)
            else:
                self._resolve_alert(rule['name'])
                
    def _trigger_alert(self, rule: Dict[str, Any], current_value: float):
        """ì•Œë¦¼ ë°œìƒ"""
        alert_id = rule['name']
        
        # ì´ë¯¸ í™œì„±í™”ëœ ì•Œë¦¼ì¸ì§€ í™•ì¸
        if alert_id in self.active_alerts:
            return
            
        alert = Alert(
            id=alert_id,
            level=rule['level'],
            title=f"{rule['name'].replace('_', ' ').title()}",
            message=f"{rule['metric']} ê°’ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. í˜„ì¬: {current_value:.2f}, ì„ê³„ê°’: {rule['threshold']:.2f}",
            timestamp=datetime.now(),
            metric_name=rule['metric'],
            current_value=current_value,
            threshold_value=rule['threshold']
        )
        
        self.active_alerts[alert_id] = alert
        self.alert_history.append(alert)
        
        # ì•Œë¦¼ ì „ì†¡
        self._send_notification(alert)
        
        self.logger.warning(f"ğŸš¨ ì•Œë¦¼ ë°œìƒ: {alert.title} - {alert.message}")
        
    def _resolve_alert(self, alert_id: str):
        """ì•Œë¦¼ í•´ê²°"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolved = True
            del self.active_alerts[alert_id]
            
            self.logger.info(f"âœ… ì•Œë¦¼ í•´ê²°: {alert.title}")
            
    def _send_notification(self, alert: Alert):
        """ì•Œë¦¼ ì „ì†¡"""
        for callback in self.notification_callbacks:
            try:
                callback(alert)
            except Exception as e:
                self.logger.error(f"ì•Œë¦¼ ì½œë°± ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                
    def add_notification_callback(self, callback: Callable):
        """ì•Œë¦¼ ì½œë°± ì¶”ê°€"""
        self.notification_callbacks.append(callback)
        
    def get_active_alerts(self) -> List[Alert]:
        """í™œì„± ì•Œë¦¼ ì¡°íšŒ"""
        return list(self.active_alerts.values())
        
    def get_alert_history(self, limit: int = 50) -> List[Alert]:
        """ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return list(self.alert_history)[-limit:]

class PerformanceMonitor:
    """í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.profiler = ApplicationProfiler()
        self.alert_manager = AlertManager()
        self.logger = logging.getLogger(__name__)
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì •
        self.monitoring_active = False
        self.dashboard_data = {}
        
        # ì•Œë¦¼ ì½œë°± ì„¤ì •
        self.alert_manager.add_notification_callback(self._handle_alert)
        
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.metrics_collector.start_collection()
        
        # ì•Œë¦¼ ì²´í¬ ìŠ¤ë ˆë“œ ì‹œì‘
        alert_thread = threading.Thread(target=self._alert_check_loop)
        alert_thread.daemon = True
        alert_thread.start()
        
        self.logger.info("ğŸ” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        self.metrics_collector.stop_collection()
        self.logger.info("ğŸ›‘ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
        
    def _alert_check_loop(self):
        """ì•Œë¦¼ ì²´í¬ ë£¨í”„"""
        while self.monitoring_active:
            try:
                # ìµœê·¼ ë©”íŠ¸ë¦­ìœ¼ë¡œ ì•Œë¦¼ í™•ì¸
                recent_metrics = self.metrics_collector.get_latest_metrics(limit=50)
                self.alert_manager.check_alerts(recent_metrics)
                
                # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸
                self._update_dashboard_data()
                
            except Exception as e:
                self.logger.error(f"ì•Œë¦¼ ì²´í¬ ì‹¤íŒ¨: {e}")
                
            time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
            
    def _handle_alert(self, alert: Alert):
        """ì•Œë¦¼ ì²˜ë¦¬"""
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì´ë©”ì¼, ìŠ¬ë™, ì›¹í›… ë“±ìœ¼ë¡œ ì „ì†¡
        print(f"ğŸš¨ ì•Œë¦¼: [{alert.level.value.upper()}] {alert.title}")
        print(f"   ë©”ì‹œì§€: {alert.message}")
        print(f"   ì‹œê°„: {alert.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        
    def _update_dashboard_data(self):
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        # ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ
        system_health = self._get_system_health()
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥
        app_performance = self.profiler.get_performance_report()
        
        # ì•Œë¦¼ ìƒíƒœ
        active_alerts = self.alert_manager.get_active_alerts()
        
        self.dashboard_data = {
            'timestamp': datetime.now().isoformat(),
            'system_health': asdict(system_health),
            'application_performance': app_performance,
            'active_alerts_count': len(active_alerts),
            'alert_levels': {
                'critical': len([a for a in active_alerts if a.level == AlertLevel.CRITICAL]),
                'error': len([a for a in active_alerts if a.level == AlertLevel.ERROR]),
                'warning': len([a for a in active_alerts if a.level == AlertLevel.WARNING])
            }
        }
        
    def _get_system_health(self) -> SystemHealth:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì¡°íšŒ"""
        # CPU
        cpu_usage = psutil.cpu_percent()
        
        # ë©”ëª¨ë¦¬
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        
        # ë””ìŠ¤í¬
        disk = psutil.disk_usage('/')
        disk_usage = (disk.used / disk.total) * 100
        
        # ë„¤íŠ¸ì›Œí¬
        network = psutil.net_io_counters()
        network_io = {
            'bytes_sent_mb': network.bytes_sent / (1024**2),
            'bytes_recv_mb': network.bytes_recv / (1024**2)
        }
        
        # í”„ë¡œì„¸ìŠ¤
        process_count = len(psutil.pids())
        
        # ì—…íƒ€ì„
        boot_time = psutil.boot_time()
        uptime_seconds = time.time() - boot_time
        
        # ë¡œë“œ í‰ê· 
        load_average = list(os.getloadavg()) if hasattr(os, 'getloadavg') else [0.0, 0.0, 0.0]
        
        return SystemHealth(
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            disk_usage=disk_usage,
            network_io=network_io,
            process_count=process_count,
            uptime_seconds=uptime_seconds,
            load_average=load_average
        )
        
    def record_request(self, endpoint: str, execution_time: float, status_code: int = 200):
        """ìš”ì²­ ê¸°ë¡"""
        self.profiler.profile_request(endpoint, execution_time, status_code)
        
        # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡
        self.metrics_collector.record_custom_metric(
            "app.response_time", 
            execution_time,
            {"endpoint": endpoint, "status": str(status_code)}
        )
        
    def record_database_query(self, query_type: str, execution_time: float):
        """ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ê¸°ë¡"""
        self.profiler.profile_database_query(query_type, execution_time)
        
        self.metrics_collector.record_custom_metric(
            "db.query_time",
            execution_time,
            {"query_type": query_type}
        )
        
    def get_dashboard_data(self) -> Dict[str, Any]:
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
        return self.dashboard_data
        
    def get_health_status(self) -> Dict[str, str]:
        """ì „ì²´ ê±´ê°• ìƒíƒœ"""
        active_alerts = self.alert_manager.get_active_alerts()
        
        if any(a.level == AlertLevel.CRITICAL for a in active_alerts):
            return {"status": "critical", "message": "ì¹˜ëª…ì ì¸ ë¬¸ì œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤"}
        elif any(a.level == AlertLevel.ERROR for a in active_alerts):
            return {"status": "error", "message": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
        elif any(a.level == AlertLevel.WARNING for a in active_alerts):
            return {"status": "warning", "message": "ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"}
        else:
            return {"status": "healthy", "message": "ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤"}
            
    def generate_performance_report(self) -> str:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        system_health = self._get_system_health()
        
        # ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥
        app_performance = self.profiler.get_performance_report()
        
        # ëŠë¦° ì—”ë“œí¬ì¸íŠ¸
        slow_endpoints = self.profiler.get_slow_endpoints()
        
        # ì•Œë¦¼ íˆìŠ¤í† ë¦¬
        alert_history = self.alert_manager.get_alert_history(limit=20)
        
        report = f"""
ğŸ“Š AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¦¬í¬íŠ¸
{'='*60}
ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ–¥ï¸ ì‹œìŠ¤í…œ ìƒíƒœ:
- CPU ì‚¬ìš©ë¥ : {system_health.cpu_usage:.1f}%
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {system_health.memory_usage:.1f}%
- ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : {system_health.disk_usage:.1f}%
- í”„ë¡œì„¸ìŠ¤ ìˆ˜: {system_health.process_count}ê°œ
- ì—…íƒ€ì„: {system_health.uptime_seconds/3600:.1f}ì‹œê°„

ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥:
- í‰ê·  ì‘ë‹µì‹œê°„: {app_performance.get('response_time_stats', {}).get('avg_response_time', 0):.3f}ì´ˆ
- P95 ì‘ë‹µì‹œê°„: {app_performance.get('response_time_stats', {}).get('p95_response_time', 0):.3f}ì´ˆ
- ì—ëŸ¬ìœ¨: {app_performance.get('error_rate', 0):.2f}%
- ì´ ìš”ì²­ ìˆ˜: {app_performance.get('total_requests', 0)}ê°œ

ğŸŒ ëŠë¦° ì—”ë“œí¬ì¸íŠ¸ (ìƒìœ„ 5ê°œ):
"""
        
        for i, endpoint in enumerate(slow_endpoints[:5], 1):
            report += f"  {i}. {endpoint['endpoint']}: {endpoint['avg_response_time']:.3f}ì´ˆ\n"
            
        report += f"\nğŸš¨ ìµœê·¼ ì•Œë¦¼ ({len(alert_history)}ê°œ):\n"
        for alert in alert_history[-10:]:
            status = "í•´ê²°ë¨" if alert.resolved else "í™œì„±"
            report += f"  - [{alert.level.value.upper()}] {alert.title} ({status})\n"
            
        # íŒŒì¼ë¡œ ì €ì¥
        report_file = f"performance_monitoring_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
            
        self.logger.info(f"ğŸ“‹ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        return report

async def main():
    """ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë°ëª¨"""
    monitor = PerformanceMonitor()
    
    try:
        print("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 50)
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        monitor.start_monitoring()
        
        # ëª¨ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ í™œë™
        endpoints = ['/api/models', '/api/evaluations', '/api/users', '/api/reports']
        
        for i in range(20):
            # ëœë¤ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
            import random
            endpoint = random.choice(endpoints)
            response_time = random.uniform(0.1, 3.0)
            status_code = random.choice([200, 200, 200, 404, 500])  # ëŒ€ë¶€ë¶„ ì„±ê³µ
            
            monitor.record_request(endpoint, response_time, status_code)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œë®¬ë ˆì´ì…˜
            query_type = random.choice(['SELECT', 'INSERT', 'UPDATE', 'DELETE'])
            query_time = random.uniform(0.01, 1.5)
            monitor.record_database_query(query_type, query_time)
            
            await asyncio.sleep(0.5)
            
        # ì ì‹œ ëŒ€ê¸°í•˜ì—¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        await asyncio.sleep(10)
        
        # ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¶œë ¥
        dashboard_data = monitor.get_dashboard_data()
        print("\nğŸ“Š ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ë°ì´í„°:")
        print(json.dumps(dashboard_data, indent=2, ensure_ascii=False, default=str))
        
        # ê±´ê°• ìƒíƒœ í™•ì¸
        health_status = monitor.get_health_status()
        print(f"\nğŸ¥ ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ: {health_status['status']} - {health_status['message']}")
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
        report = monitor.generate_performance_report()
        print("\nğŸ“‹ ì„±ëŠ¥ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤")
        
    except Exception as e:
        print(f"âŒ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")
        
    finally:
        monitor.stop_monitoring()
        print("ğŸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())