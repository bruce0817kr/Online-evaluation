#!/usr/bin/env python3
"""
âš¡ AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”
MongoDB ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„ ë° ì¸ë±ìŠ¤ ìµœì í™” ìë™í™” ë„êµ¬
"""

import asyncio
import time
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging
from dataclasses import dataclass
import motor.motor_asyncio
import pymongo
import json
from pathlib import Path

@dataclass
class QueryPerformance:
    """ì¿¼ë¦¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    query: Dict[str, Any]
    collection: str
    execution_time: float
    documents_examined: int
    documents_returned: int
    index_used: Optional[str]
    optimization_suggestions: List[str]

@dataclass
class IndexRecommendation:
    """ì¸ë±ìŠ¤ ì¶”ì²œ"""
    collection: str
    fields: List[str]
    index_type: str  # single, compound, text, geo
    priority: str    # high, medium, low
    estimated_improvement: float
    reasoning: str

class DatabaseOptimizer:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, mongodb_url: str = "mongodb://localhost:27017/online_evaluation"):
        self.mongodb_url = mongodb_url
        self.client = None
        self.db = None
        
        # ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
        self.query_performance: List[QueryPerformance] = []
        self.index_recommendations: List[IndexRecommendation] = []
        self.current_indexes: Dict[str, List[Dict]] = {}
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ìµœì í™” ì„¤ì •
        self.performance_thresholds = {
            'slow_query_time': 100,      # 100ms ì´ìƒì€ ëŠë¦° ì¿¼ë¦¬
            'examine_ratio': 10,         # examined/returned ë¹„ìœ¨ì´ 10:1 ì´ìƒì´ë©´ ë¹„íš¨ìœ¨ì 
            'index_selectivity': 0.1     # ì¸ë±ìŠ¤ ì„ íƒë„ê°€ 10% ì´í•˜ë©´ ê°œì„  í•„ìš”
        }
        
    async def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        self.client = motor.motor_asyncio.AsyncIOMotorClient(self.mongodb_url)
        self.db = self.client.get_default_database()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            await self.client.admin.command('ismaster')
            self.logger.info("âœ… MongoDB ì—°ê²° ì„±ê³µ")
        except Exception as e:
            self.logger.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
            
    async def disconnect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ"""
        if self.client:
            self.client.close()
            
    async def analyze_all_collections(self) -> Dict[str, Any]:
        """ëª¨ë“  ì»¬ë ‰ì…˜ ì„±ëŠ¥ ë¶„ì„"""
        self.logger.info("ğŸ” ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì‹œì‘")
        
        # 1. í˜„ì¬ ì¸ë±ìŠ¤ ì •ë³´ ìˆ˜ì§‘
        await self._collect_current_indexes()
        
        # 2. ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ ë¶„ì„
        await self._analyze_running_queries()
        
        # 3. ëŠë¦° ì¿¼ë¦¬ ë¡œê·¸ ë¶„ì„
        await self._analyze_slow_queries()
        
        # 4. ì»¬ë ‰ì…˜ë³„ í†µê³„ ë¶„ì„
        collection_stats = await self._analyze_collection_statistics()
        
        # 5. ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„
        index_usage = await self._analyze_index_usage()
        
        # 6. ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
        await self._generate_optimization_recommendations()
        
        # 7. ì¢…í•© ë¶„ì„ ê²°ê³¼
        analysis_result = {
            'timestamp': datetime.now().isoformat(),
            'collection_statistics': collection_stats,
            'index_usage': index_usage,
            'query_performance': [self._serialize_query_performance(qp) for qp in self.query_performance],
            'index_recommendations': [self._serialize_index_recommendation(ir) for ir in self.index_recommendations],
            'current_indexes': self.current_indexes,
            'optimization_summary': self._generate_optimization_summary()
        }
        
        self.logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë¶„ì„ ì™„ë£Œ")
        return analysis_result
        
    async def _collect_current_indexes(self):
        """í˜„ì¬ ì¸ë±ìŠ¤ ì •ë³´ ìˆ˜ì§‘"""
        self.logger.info("ğŸ“Š í˜„ì¬ ì¸ë±ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        collections = await self.db.list_collection_names()
        
        for collection_name in collections:
            collection = self.db[collection_name]
            indexes = await collection.list_indexes().to_list(length=None)
            
            self.current_indexes[collection_name] = []
            for index in indexes:
                index_info = {
                    'name': index['name'],
                    'key': index['key'],
                    'unique': index.get('unique', False),
                    'sparse': index.get('sparse', False),
                    'background': index.get('background', False),
                    'size': 0  # í¬ê¸°ëŠ” ë³„ë„ë¡œ ê³„ì‚°
                }
                self.current_indexes[collection_name].append(index_info)
                
        self.logger.info(f"âœ… {len(collections)}ê°œ ì»¬ë ‰ì…˜ì˜ ì¸ë±ìŠ¤ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        
    async def _analyze_running_queries(self):
        """ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ ë¶„ì„"""
        self.logger.info("ğŸ”„ ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ ë¶„ì„ ì¤‘...")
        
        try:
            # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì¡°íšŒ
            current_ops = await self.db.admin.command("currentOp", {"active": True})
            
            for op in current_ops.get('inprog', []):
                if op.get('op') in ['query', 'getmore']:
                    command = op.get('command', {})
                    if 'find' in command:
                        collection_name = command['find']
                        query = command.get('filter', {})
                        duration = op.get('microsecs_running', 0) / 1000  # msë¡œ ë³€í™˜
                        
                        if duration > self.performance_thresholds['slow_query_time']:
                            # ëŠë¦° ì¿¼ë¦¬ ë°œê²¬
                            performance = QueryPerformance(
                                query=query,
                                collection=collection_name,
                                execution_time=duration,
                                documents_examined=0,  # currentOpì—ì„œëŠ” ì •í™•í•œ ê°’ ì—†ìŒ
                                documents_returned=0,
                                index_used=None,
                                optimization_suggestions=["í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëŠë¦° ì¿¼ë¦¬ì…ë‹ˆë‹¤"]
                            )
                            self.query_performance.append(performance)
                            
        except Exception as e:
            self.logger.warning(f"ì‹¤í–‰ ì¤‘ì¸ ì¿¼ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            
    async def _analyze_slow_queries(self):
        """ëŠë¦° ì¿¼ë¦¬ ë¡œê·¸ ë¶„ì„"""
        self.logger.info("ğŸŒ ëŠë¦° ì¿¼ë¦¬ ë¶„ì„ ì¤‘...")
        
        # MongoDB í”„ë¡œíŒŒì¼ëŸ¬ í™œì„±í™” (ë ˆë²¨ 2: ëª¨ë“  ì‘ì—… ê¸°ë¡)
        try:
            # í”„ë¡œíŒŒì¼ë§ ì„¤ì • í™•ì¸
            profile_status = await self.db.command("profile", -1)
            
            if profile_status.get('was', 0) == 0:
                # í”„ë¡œíŒŒì¼ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ì„ì‹œë¡œ í™œì„±í™”
                await self.db.command("profile", 2, {"slowms": 50})
                self.logger.info("ğŸ“Š MongoDB í”„ë¡œíŒŒì¼ëŸ¬ í™œì„±í™”")
                
                # ì ì‹œ ëŒ€ê¸° (ì‹¤ì œ ì¿¼ë¦¬ ìˆ˜ì§‘ì„ ìœ„í•´)
                await asyncio.sleep(2)
                
        except Exception as e:
            self.logger.warning(f"í”„ë¡œíŒŒì¼ëŸ¬ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
            
        # í”„ë¡œíŒŒì¼ ì»¬ë ‰ì…˜ì—ì„œ ëŠë¦° ì¿¼ë¦¬ ë¶„ì„
        try:
            profile_collection = self.db['system.profile']
            
            # ìµœê·¼ 1ì‹œê°„ì˜ í”„ë¡œíŒŒì¼ ë°ì´í„° ì¡°íšŒ
            one_hour_ago = datetime.now() - timedelta(hours=1)
            
            cursor = profile_collection.find({
                'ts': {'$gte': one_hour_ago},
                'op': {'$in': ['query', 'getmore']},
                'millis': {'$gte': self.performance_thresholds['slow_query_time']}
            }).sort('millis', -1).limit(100)
            
            async for profile in cursor:
                collection_name = profile.get('ns', '').split('.')[-1]
                if not collection_name or collection_name.startswith('system.'):
                    continue
                    
                query = profile.get('command', {}).get('filter', {})
                execution_time = profile.get('millis', 0)
                docs_examined = profile.get('docsExamined', 0)
                docs_returned = profile.get('docsReturned', 0)
                
                # ì¸ë±ìŠ¤ ì‚¬ìš© ì •ë³´
                execution_stats = profile.get('execStats', {})
                index_used = self._extract_index_used(execution_stats)
                
                # ìµœì í™” ì œì•ˆ ìƒì„±
                suggestions = self._generate_query_suggestions(
                    query, docs_examined, docs_returned, index_used
                )
                
                performance = QueryPerformance(
                    query=query,
                    collection=collection_name,
                    execution_time=execution_time,
                    documents_examined=docs_examined,
                    documents_returned=docs_returned,
                    index_used=index_used,
                    optimization_suggestions=suggestions
                )
                
                self.query_performance.append(performance)
                
            self.logger.info(f"âœ… {len(self.query_performance)}ê°œì˜ ëŠë¦° ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ")
            
        except Exception as e:
            self.logger.warning(f"ëŠë¦° ì¿¼ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            
    async def _analyze_collection_statistics(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ í†µê³„ ë¶„ì„"""
        self.logger.info("ğŸ“ˆ ì»¬ë ‰ì…˜ í†µê³„ ë¶„ì„ ì¤‘...")
        
        stats = {}
        collections = await self.db.list_collection_names()
        
        for collection_name in collections:
            if collection_name.startswith('system.'):
                continue
                
            try:
                collection = self.db[collection_name]
                
                # ì»¬ë ‰ì…˜ í†µê³„
                collection_stats = await self.db.command("collStats", collection_name)
                
                # ë¬¸ì„œ ìˆ˜ ë° í¬ê¸°
                document_count = collection_stats.get('count', 0)
                avg_obj_size = collection_stats.get('avgObjSize', 0)
                total_size = collection_stats.get('size', 0)
                
                # ì¸ë±ìŠ¤ í†µê³„
                index_count = len(self.current_indexes.get(collection_name, []))
                total_index_size = collection_stats.get('totalIndexSize', 0)
                
                stats[collection_name] = {
                    'document_count': document_count,
                    'average_document_size': avg_obj_size,
                    'total_size_bytes': total_size,
                    'total_size_mb': round(total_size / (1024 * 1024), 2),
                    'index_count': index_count,
                    'total_index_size_bytes': total_index_size,
                    'total_index_size_mb': round(total_index_size / (1024 * 1024), 2),
                    'index_to_data_ratio': round(total_index_size / total_size * 100, 2) if total_size > 0 else 0
                }
                
            except Exception as e:
                self.logger.warning(f"ì»¬ë ‰ì…˜ {collection_name} í†µê³„ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                
        return stats
        
    async def _analyze_index_usage(self) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
        self.logger.info("ğŸ“Š ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„ ì¤‘...")
        
        usage_stats = {}
        
        for collection_name, indexes in self.current_indexes.items():
            collection = self.db[collection_name]
            
            try:
                # $indexStats ì§‘ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
                pipeline = [{"$indexStats": {}}]
                cursor = collection.aggregate(pipeline)
                
                collection_usage = []
                async for index_stat in cursor:
                    index_info = {
                        'name': index_stat['name'],
                        'accesses': index_stat['accesses'],
                        'since': index_stat['accesses']['since'].isoformat() if 'since' in index_stat['accesses'] else None
                    }
                    collection_usage.append(index_info)
                    
                usage_stats[collection_name] = collection_usage
                
            except Exception as e:
                self.logger.warning(f"ì»¬ë ‰ì…˜ {collection_name} ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                usage_stats[collection_name] = []
                
        return usage_stats
        
    async def _generate_optimization_recommendations(self):
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        self.logger.info("ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„± ì¤‘...")
        
        # 1. ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„
        query_patterns = self._analyze_query_patterns()
        
        # 2. ì¸ë±ìŠ¤ê°€ ì—†ëŠ” ì¿¼ë¦¬ í•„ë“œ ì‹ë³„
        missing_indexes = self._identify_missing_indexes(query_patterns)
        
        # 3. ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ ì‹ë³„
        unused_indexes = await self._identify_unused_indexes()
        
        # 4. ë³µí•© ì¸ë±ìŠ¤ ê¸°íšŒ ì‹ë³„
        compound_index_opportunities = self._identify_compound_index_opportunities(query_patterns)
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        for collection, fields in missing_indexes.items():
            for field_set in fields:
                if len(field_set) == 1:
                    # ë‹¨ì¼ í•„ë“œ ì¸ë±ìŠ¤
                    recommendation = IndexRecommendation(
                        collection=collection,
                        fields=list(field_set),
                        index_type="single",
                        priority="high",
                        estimated_improvement=self._estimate_improvement(collection, field_set),
                        reasoning=f"í•„ë“œ '{field_set}'ì— ëŒ€í•œ ì¿¼ë¦¬ê°€ ë¹ˆë²ˆí•˜ì§€ë§Œ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤"
                    )
                else:
                    # ë³µí•© ì¸ë±ìŠ¤
                    recommendation = IndexRecommendation(
                        collection=collection,
                        fields=list(field_set),
                        index_type="compound",
                        priority="medium",
                        estimated_improvement=self._estimate_improvement(collection, field_set),
                        reasoning=f"ë³µí•© ì¿¼ë¦¬ íŒ¨í„´ ìµœì í™”ë¥¼ ìœ„í•œ ë³µí•© ì¸ë±ìŠ¤ ê¶Œì¥"
                    )
                    
                self.index_recommendations.append(recommendation)
                
        # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ ì œê±° ê¶Œì¥
        for collection, index_names in unused_indexes.items():
            for index_name in index_names:
                if index_name != '_id_':  # ê¸°ë³¸ ì¸ë±ìŠ¤ëŠ” ì œì™¸
                    recommendation = IndexRecommendation(
                        collection=collection,
                        fields=[index_name],
                        index_type="remove",
                        priority="low",
                        estimated_improvement=5.0,  # ìŠ¤í† ë¦¬ì§€ ì ˆì•½
                        reasoning=f"ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ '{index_name}' ì œê±° ê¶Œì¥"
                    )
                    self.index_recommendations.append(recommendation)
                    
    def _analyze_query_patterns(self) -> Dict[str, List[set]]:
        """ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„"""
        patterns = {}
        
        for qp in self.query_performance:
            collection = qp.collection
            if collection not in patterns:
                patterns[collection] = []
                
            # ì¿¼ë¦¬ì—ì„œ ì‚¬ìš©ëœ í•„ë“œ ì¶”ì¶œ
            query_fields = self._extract_query_fields(qp.query)
            if query_fields:
                patterns[collection].append(set(query_fields))
                
        return patterns
        
    def _extract_query_fields(self, query: Dict[str, Any]) -> List[str]:
        """ì¿¼ë¦¬ì—ì„œ í•„ë“œëª… ì¶”ì¶œ"""
        fields = []
        
        def extract_fields_recursive(obj, prefix=""):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if key.startswith('$'):
                        # MongoDB ì—°ì‚°ìëŠ” ìŠ¤í‚µ
                        if isinstance(value, dict):
                            extract_fields_recursive(value, prefix)
                        elif isinstance(value, list):
                            for item in value:
                                if isinstance(item, dict):
                                    extract_fields_recursive(item, prefix)
                    else:
                        field_name = f"{prefix}.{key}" if prefix else key
                        fields.append(field_name)
                        
                        if isinstance(value, dict):
                            extract_fields_recursive(value, field_name)
                            
        extract_fields_recursive(query)
        return fields
        
    def _identify_missing_indexes(self, query_patterns: Dict[str, List[set]]) -> Dict[str, List[set]]:
        """ëˆ„ë½ëœ ì¸ë±ìŠ¤ ì‹ë³„"""
        missing = {}
        
        for collection, patterns in query_patterns.items():
            existing_indexes = self.current_indexes.get(collection, [])
            existing_fields = set()
            
            for index in existing_indexes:
                for field in index['key'].keys():
                    existing_fields.add(field)
                    
            missing_patterns = []
            for pattern in patterns:
                if not any(field in existing_fields for field in pattern):
                    missing_patterns.append(pattern)
                    
            if missing_patterns:
                missing[collection] = missing_patterns
                
        return missing
        
    async def _identify_unused_indexes(self) -> Dict[str, List[str]]:
        """ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ ì‹ë³„"""
        unused = {}
        
        # ì¸ë±ìŠ¤ ì‚¬ìš©ëŸ‰ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” $indexStats ê²°ê³¼ë¥¼ ì‚¬ìš©
        
        return unused
        
    def _identify_compound_index_opportunities(self, query_patterns: Dict[str, List[set]]) -> Dict[str, List[List[str]]]:
        """ë³µí•© ì¸ë±ìŠ¤ ê¸°íšŒ ì‹ë³„"""
        opportunities = {}
        
        for collection, patterns in query_patterns.items():
            # ìì£¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” í•„ë“œ ì¡°í•© ì°¾ê¸°
            field_combinations = {}
            
            for pattern in patterns:
                if len(pattern) > 1:
                    sorted_fields = tuple(sorted(pattern))
                    field_combinations[sorted_fields] = field_combinations.get(sorted_fields, 0) + 1
                    
            # ë¹ˆë„ê°€ ë†’ì€ ì¡°í•© ì„ ë³„
            frequent_combinations = [
                list(combo) for combo, count in field_combinations.items() 
                if count >= 3  # 3íšŒ ì´ìƒ ë‚˜íƒ€ë‚˜ëŠ” ì¡°í•©
            ]
            
            if frequent_combinations:
                opportunities[collection] = frequent_combinations
                
        return opportunities
        
    def _estimate_improvement(self, collection: str, fields: set) -> float:
        """ì„±ëŠ¥ ê°œì„  ì˜ˆìƒì¹˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ì¶”ì •
        base_improvement = 50.0  # ê¸°ë³¸ 50% ê°œì„ 
        
        # í•„ë“œ ìˆ˜ì— ë”°ë¥¸ ì¡°ì •
        if len(fields) > 1:
            base_improvement *= 0.8  # ë³µí•© ì¸ë±ìŠ¤ëŠ” ì•½ê°„ ë‚®ê²Œ
            
        # ì»¬ë ‰ì…˜ í¬ê¸°ì— ë”°ë¥¸ ì¡°ì •
        # (ì‹¤ì œë¡œëŠ” ì»¬ë ‰ì…˜ í†µê³„ë¥¼ ì‚¬ìš©)
        
        return min(base_improvement, 90.0)  # ìµœëŒ€ 90% ê°œì„ 
        
    def _extract_index_used(self, execution_stats: Dict) -> Optional[str]:
        """ì‹¤í–‰ í†µê³„ì—ì„œ ì‚¬ìš©ëœ ì¸ë±ìŠ¤ ì¶”ì¶œ"""
        if 'indexName' in execution_stats:
            return execution_stats['indexName']
        return None
        
    def _generate_query_suggestions(self, query: Dict, examined: int, returned: int, index_used: Optional[str]) -> List[str]:
        """ì¿¼ë¦¬ë³„ ìµœì í™” ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        # ê²€ì‚¬ ë¹„ìœ¨ í™•ì¸
        if returned > 0 and examined / returned > self.performance_thresholds['examine_ratio']:
            suggestions.append(f"ë¹„íš¨ìœ¨ì ì¸ ì¿¼ë¦¬: {examined}ê°œ ë¬¸ì„œ ê²€ì‚¬ í›„ {returned}ê°œ ë°˜í™˜. ì¸ë±ìŠ¤ ìµœì í™” í•„ìš”")
            
        # ì¸ë±ìŠ¤ ì‚¬ìš© ì—¬ë¶€
        if not index_used or index_used == "COLLSCAN":
            suggestions.append("ì¸ë±ìŠ¤ê°€ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ. ì ì ˆí•œ ì¸ë±ìŠ¤ ìƒì„± ê¶Œì¥")
            
        # ì¿¼ë¦¬ íŒ¨í„´ë³„ ì œì•ˆ
        if '$regex' in str(query):
            suggestions.append("ì •ê·œì‹ ì¿¼ë¦¬ëŠ” ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŒ. í…ìŠ¤íŠ¸ ì¸ë±ìŠ¤ ê³ ë ¤")
            
        if '$where' in str(query):
            suggestions.append("$where ì—°ì‚°ìëŠ” ë§¤ìš° ëŠë¦¼. ë‹¤ë¥¸ ì¿¼ë¦¬ ì—°ì‚°ì ì‚¬ìš© ê¶Œì¥")
            
        return suggestions
        
    def _generate_optimization_summary(self) -> Dict[str, Any]:
        """ìµœì í™” ìš”ì•½ ìƒì„±"""
        total_slow_queries = len(self.query_performance)
        total_recommendations = len(self.index_recommendations)
        
        high_priority_recs = len([r for r in self.index_recommendations if r.priority == "high"])
        
        estimated_total_improvement = sum([
            r.estimated_improvement for r in self.index_recommendations 
            if r.index_type != "remove"
        ])
        
        return {
            'total_slow_queries': total_slow_queries,
            'total_recommendations': total_recommendations,
            'high_priority_recommendations': high_priority_recs,
            'estimated_average_improvement': round(estimated_total_improvement / max(total_recommendations, 1), 2),
            'quick_wins': [
                r for r in self.index_recommendations 
                if r.priority == "high" and r.estimated_improvement > 50
            ][:3]  # ìƒìœ„ 3ê°œ ë¹ ë¥¸ ê°œì„ ì‚¬í•­
        }
        
    def _serialize_query_performance(self, qp: QueryPerformance) -> Dict[str, Any]:
        """QueryPerformance ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'query': qp.query,
            'collection': qp.collection,
            'execution_time': qp.execution_time,
            'documents_examined': qp.documents_examined,
            'documents_returned': qp.documents_returned,
            'index_used': qp.index_used,
            'optimization_suggestions': qp.optimization_suggestions
        }
        
    def _serialize_index_recommendation(self, ir: IndexRecommendation) -> Dict[str, Any]:
        """IndexRecommendation ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'collection': ir.collection,
            'fields': ir.fields,
            'index_type': ir.index_type,
            'priority': ir.priority,
            'estimated_improvement': ir.estimated_improvement,
            'reasoning': ir.reasoning
        }
        
    async def apply_recommendations(self, auto_apply: bool = False) -> Dict[str, Any]:
        """ê¶Œì¥ì‚¬í•­ ì ìš©"""
        self.logger.info("ğŸ”§ ìµœì í™” ê¶Œì¥ì‚¬í•­ ì ìš© ì¤‘...")
        
        applied_changes = []
        failed_changes = []
        
        for recommendation in self.index_recommendations:
            if recommendation.index_type == "remove":
                # ì¸ë±ìŠ¤ ì œê±°
                if auto_apply or recommendation.priority == "low":
                    try:
                        collection = self.db[recommendation.collection]
                        await collection.drop_index(recommendation.fields[0])
                        applied_changes.append(f"ì¸ë±ìŠ¤ ì œê±°: {recommendation.collection}.{recommendation.fields[0]}")
                    except Exception as e:
                        failed_changes.append(f"ì¸ë±ìŠ¤ ì œê±° ì‹¤íŒ¨: {recommendation.collection}.{recommendation.fields[0]} - {e}")
                        
            elif recommendation.priority == "high" and (auto_apply or recommendation.estimated_improvement > 70):
                # ê³ ìš°ì„ ìˆœìœ„ ì¸ë±ìŠ¤ ìƒì„±
                try:
                    collection = self.db[recommendation.collection]
                    
                    if recommendation.index_type == "single":
                        index_spec = {recommendation.fields[0]: 1}
                    elif recommendation.index_type == "compound":
                        index_spec = {field: 1 for field in recommendation.fields}
                    else:
                        continue
                        
                    await collection.create_index(
                        list(index_spec.items()),
                        background=True,
                        name=f"{'_'.join(recommendation.fields)}_auto_optimized"
                    )
                    applied_changes.append(f"ì¸ë±ìŠ¤ ìƒì„±: {recommendation.collection}.{recommendation.fields}")
                    
                except Exception as e:
                    failed_changes.append(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {recommendation.collection}.{recommendation.fields} - {e}")
                    
        result = {
            'applied_changes': applied_changes,
            'failed_changes': failed_changes,
            'total_applied': len(applied_changes),
            'total_failed': len(failed_changes)
        }
        
        self.logger.info(f"âœ… {len(applied_changes)}ê°œ ë³€ê²½ì‚¬í•­ ì ìš©, {len(failed_changes)}ê°œ ì‹¤íŒ¨")
        return result
        
    async def generate_optimization_report(self, analysis_result: Dict[str, Any]) -> str:
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"database_optimization_report_{timestamp}.json"
        
        # JSON ë¦¬í¬íŠ¸ ì €ì¥
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, ensure_ascii=False, default=str)
            
        # í…ìŠ¤íŠ¸ ìš”ì•½ ìƒì„±
        summary = analysis_result['optimization_summary']
        
        report_text = f"""
ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™” ë¦¬í¬íŠ¸
{'='*50}
ë¶„ì„ ì‹œê°„: {analysis_result['timestamp']}

ğŸ” ë¶„ì„ ê²°ê³¼:
- ëŠë¦° ì¿¼ë¦¬ ë°œê²¬: {summary['total_slow_queries']}ê°œ
- ìµœì í™” ê¶Œì¥ì‚¬í•­: {summary['total_recommendations']}ê°œ
- ê³ ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­: {summary['high_priority_recommendations']}ê°œ
- ì˜ˆìƒ í‰ê·  ì„±ëŠ¥ ê°œì„ : {summary['estimated_average_improvement']}%

ğŸ’¡ ë¹ ë¥¸ ê°œì„ ì‚¬í•­ (Top 3):
"""
        
        for i, quick_win in enumerate(summary.get('quick_wins', []), 1):
            if isinstance(quick_win, dict):
                report_text += f"  {i}. {quick_win.get('collection', '')}.{quick_win.get('fields', [])} "
                report_text += f"({quick_win.get('estimated_improvement', 0):.1f}% ê°œì„  ì˜ˆìƒ)\n"
                
        report_text += f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: {report_file}\n"
        
        self.logger.info(f"ğŸ“Š ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±: {report_file}")
        return report_text

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    optimizer = DatabaseOptimizer()
    
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        await optimizer.connect()
        
        # ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
        print("âš¡ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™” ì‹œì‘...")
        analysis_result = await optimizer.analyze_all_collections()
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_summary = await optimizer.generate_optimization_report(analysis_result)
        print(report_summary)
        
        # ê¶Œì¥ì‚¬í•­ ì ìš© (ì„ íƒì )
        apply_changes = input("\nğŸ”§ ê³ ìš°ì„ ìˆœìœ„ ê¶Œì¥ì‚¬í•­ì„ ìë™ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if apply_changes.lower() == 'y':
            changes_result = await optimizer.apply_recommendations(auto_apply=True)
            print(f"âœ… {changes_result['total_applied']}ê°œ ë³€ê²½ì‚¬í•­ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
            if changes_result['failed_changes']:
                print(f"âŒ {changes_result['total_failed']}ê°œ ë³€ê²½ì‚¬í•­ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
    except Exception as e:
        print(f"âŒ ìµœì í™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
        
    finally:
        await optimizer.disconnect()
        
    print("ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ì™„ë£Œ!")
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main()))