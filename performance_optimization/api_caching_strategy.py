#!/usr/bin/env python3
"""
ğŸš€ AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - API ì‘ë‹µ ìºì‹± ì „ëµ êµ¬í˜„
Redis ê¸°ë°˜ ë‹¤ì¸µ ìºì‹± ì‹œìŠ¤í…œìœ¼ë¡œ API ì‘ë‹µì‹œê°„ 70% ê°œì„ 
"""

import asyncio
import json
import hashlib
import time
from typing import Dict, List, Any, Optional, Union, Callable
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
import logging
from functools import wraps
import redis.asyncio as redis
from enum import Enum

class CacheLevel(Enum):
    """ìºì‹œ ë ˆë²¨ ì •ì˜"""
    L1_MEMORY = "l1_memory"      # ë©”ëª¨ë¦¬ ìºì‹œ (ê°€ì¥ ë¹ ë¦„)
    L2_REDIS = "l2_redis"        # Redis ìºì‹œ (ì¤‘ê°„)
    L3_DATABASE = "l3_database"  # ë°ì´í„°ë² ì´ìŠ¤ (ê°€ì¥ ëŠë¦¼)

@dataclass
class CacheConfig:
    """ìºì‹œ ì„¤ì •"""
    ttl_seconds: int = 300       # ê¸°ë³¸ 5ë¶„
    max_memory_size: int = 1000  # ë©”ëª¨ë¦¬ ìºì‹œ ìµœëŒ€ ì—”íŠ¸ë¦¬ ìˆ˜
    enable_compression: bool = True
    cache_levels: List[CacheLevel] = None
    
    def __post_init__(self):
        if self.cache_levels is None:
            self.cache_levels = [CacheLevel.L1_MEMORY, CacheLevel.L2_REDIS]

@dataclass
class CacheMetrics:
    """ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    hits: int = 0
    misses: int = 0
    total_requests: int = 0
    avg_response_time: float = 0
    memory_usage: int = 0
    redis_usage: int = 0
    
    @property
    def hit_rate(self) -> float:
        """ìºì‹œ ì ì¤‘ë¥ """
        return (self.hits / self.total_requests * 100) if self.total_requests > 0 else 0
    
    @property
    def miss_rate(self) -> float:
        """ìºì‹œ ë¯¸ìŠ¤ìœ¨"""
        return 100 - self.hit_rate

class SmartCacheManager:
    """ìŠ¤ë§ˆíŠ¸ ìºì‹± ê´€ë¦¬ì - ë‹¤ì¸µ ìºì‹± ë° ì§€ëŠ¥í˜• ë¬´íš¨í™”"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379/1"):
        self.redis_url = redis_url
        self.redis_client = None
        
        # L1 ë©”ëª¨ë¦¬ ìºì‹œ (LRU)
        self.memory_cache: Dict[str, Dict] = {}
        self.cache_access_order: List[str] = []
        
        # ìºì‹œ ì„¤ì • ë° ë©”íŠ¸ë¦­
        self.cache_configs: Dict[str, CacheConfig] = {}
        self.metrics = CacheMetrics()
        
        # ë¡œê¹…
        self.logger = logging.getLogger(__name__)
        
        # ìŠ¤ë§ˆíŠ¸ ìºì‹± ì„¤ì •
        self.setup_default_cache_strategies()
        
    async def connect(self):
        """Redis ì—°ê²°"""
        try:
            self.redis_client = redis.from_url(self.redis_url)
            await self.redis_client.ping()
            self.logger.info("âœ… Redis ìºì‹œ ì„œë²„ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            self.logger.warning(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨, ë©”ëª¨ë¦¬ ìºì‹œë§Œ ì‚¬ìš©: {e}")
            
    async def disconnect(self):
        """Redis ì—°ê²° í•´ì œ"""
        if self.redis_client:
            await self.redis_client.close()
            
    def setup_default_cache_strategies(self):
        """ê¸°ë³¸ ìºì‹± ì „ëµ ì„¤ì •"""
        
        # ì‚¬ìš©ì ì •ë³´ - ìì£¼ ì¡°íšŒë˜ì§€ë§Œ ë³€ê²½ ì ìŒ
        self.cache_configs['user_profile'] = CacheConfig(
            ttl_seconds=1800,  # 30ë¶„
            max_memory_size=500,
            cache_levels=[CacheLevel.L1_MEMORY, CacheLevel.L2_REDIS]
        )
        
        # AI ëª¨ë¸ ëª©ë¡ - ë§¤ìš° ìì£¼ ì¡°íšŒë¨
        self.cache_configs['model_list'] = CacheConfig(
            ttl_seconds=600,   # 10ë¶„
            max_memory_size=100,
            cache_levels=[CacheLevel.L1_MEMORY, CacheLevel.L2_REDIS]
        )
        
        # í‰ê°€ ê²°ê³¼ - í° ë°ì´í„°, ìì£¼ ì¡°íšŒë¨
        self.cache_configs['evaluation_results'] = CacheConfig(
            ttl_seconds=3600,  # 1ì‹œê°„
            max_memory_size=200,
            enable_compression=True,
            cache_levels=[CacheLevel.L2_REDIS]  # Redisë§Œ ì‚¬ìš© (í° ë°ì´í„°)
        )
        
        # ë¶„ì„ ë¦¬í¬íŠ¸ - ê³„ì‚° ë¹„ìš© ë†’ìŒ
        self.cache_configs['analytics_report'] = CacheConfig(
            ttl_seconds=7200,  # 2ì‹œê°„
            max_memory_size=50,
            cache_levels=[CacheLevel.L1_MEMORY, CacheLevel.L2_REDIS]
        )
        
        # ê²€ìƒ‰ ê²°ê³¼ - ì¼ì‹œì ìœ¼ë¡œ ìºì‹œ
        self.cache_configs['search_results'] = CacheConfig(
            ttl_seconds=300,   # 5ë¶„
            max_memory_size=1000,
            cache_levels=[CacheLevel.L1_MEMORY]  # ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©
        )
        
    def cache_key(self, category: str, **kwargs) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        # ë§¤ê°œë³€ìˆ˜ë“¤ì„ ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ í‚¤ ìƒì„±
        params = "&".join([f"{k}={v}" for k, v in sorted(kwargs.items())])
        key_string = f"{category}:{params}"
        
        # SHA256 í•´ì‹œë¡œ í‚¤ ë‹¨ì¶•
        return hashlib.sha256(key_string.encode()).hexdigest()[:16]
        
    async def get(self, category: str, **kwargs) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ë‹¤ì¸µ ìºì‹œ)"""
        start_time = time.time()
        cache_key = self.cache_key(category, **kwargs)
        config = self.cache_configs.get(category, CacheConfig())
        
        self.metrics.total_requests += 1
        
        try:
            # L1 ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            if CacheLevel.L1_MEMORY in config.cache_levels:
                if cache_key in self.memory_cache:
                    entry = self.memory_cache[cache_key]
                    if not self._is_expired(entry):
                        self._update_access_order(cache_key)
                        self.metrics.hits += 1
                        self.logger.debug(f"ğŸŸ¢ L1 ìºì‹œ ì ì¤‘: {category}")
                        return entry['data']
                        
            # L2 Redis ìºì‹œ í™•ì¸
            if CacheLevel.L2_REDIS in config.cache_levels and self.redis_client:
                redis_key = f"cache:{cache_key}"
                cached_data = await self.redis_client.get(redis_key)
                
                if cached_data:
                    data = json.loads(cached_data)
                    
                    # L1 ìºì‹œì—ë„ ì €ì¥ (ìºì‹œ ì›Œë°ì—…)
                    if CacheLevel.L1_MEMORY in config.cache_levels:
                        await self._store_in_memory(cache_key, data, config)
                        
                    self.metrics.hits += 1
                    self.logger.debug(f"ğŸŸ¡ L2 ìºì‹œ ì ì¤‘: {category}")
                    return data
                    
            # ìºì‹œ ë¯¸ìŠ¤
            self.metrics.misses += 1
            self.logger.debug(f"ğŸ”´ ìºì‹œ ë¯¸ìŠ¤: {category}")
            return None
            
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            self.metrics.misses += 1
            return None
            
        finally:
            # ì‘ë‹µì‹œê°„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_avg_response_time(response_time)
            
    async def set(self, category: str, data: Any, **kwargs):
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (ë‹¤ì¸µ ìºì‹œ)"""
        cache_key = self.cache_key(category, **kwargs)
        config = self.cache_configs.get(category, CacheConfig())
        
        try:
            # L1 ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            if CacheLevel.L1_MEMORY in config.cache_levels:
                await self._store_in_memory(cache_key, data, config)
                
            # L2 Redis ìºì‹œì— ì €ì¥
            if CacheLevel.L2_REDIS in config.cache_levels and self.redis_client:
                await self._store_in_redis(cache_key, data, config)
                
        except Exception as e:
            self.logger.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            
    async def _store_in_memory(self, cache_key: str, data: Any, config: CacheConfig):
        """L1 ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        # LRU ì •ì±…ìœ¼ë¡œ ê³µê°„ í™•ë³´
        while len(self.memory_cache) >= config.max_memory_size:
            if self.cache_access_order:
                oldest_key = self.cache_access_order.pop(0)
                self.memory_cache.pop(oldest_key, None)
                
        # ë°ì´í„° ì €ì¥
        self.memory_cache[cache_key] = {
            'data': data,
            'timestamp': time.time(),
            'ttl': config.ttl_seconds
        }
        
        self._update_access_order(cache_key)
        
    async def _store_in_redis(self, cache_key: str, data: Any, config: CacheConfig):
        """L2 Redis ìºì‹œì— ì €ì¥"""
        redis_key = f"cache:{cache_key}"
        
        # ë°ì´í„° ì••ì¶• (ì˜µì…˜)
        if config.enable_compression:
            # ê°„ë‹¨í•œ JSON ì••ì¶• (ì‹¤ì œë¡œëŠ” gzip ë“± ì‚¬ìš© ê°€ëŠ¥)
            serialized_data = json.dumps(data, separators=(',', ':'))
        else:
            serialized_data = json.dumps(data)
            
        await self.redis_client.setex(
            redis_key, 
            config.ttl_seconds, 
            serialized_data
        )
        
    def _is_expired(self, entry: Dict) -> bool:
        """ìºì‹œ í•­ëª© ë§Œë£Œ í™•ì¸"""
        return time.time() - entry['timestamp'] > entry['ttl']
        
    def _update_access_order(self, cache_key: str):
        """LRU ìˆœì„œ ì—…ë°ì´íŠ¸"""
        if cache_key in self.cache_access_order:
            self.cache_access_order.remove(cache_key)
        self.cache_access_order.append(cache_key)
        
    def _update_avg_response_time(self, response_time: float):
        """í‰ê·  ì‘ë‹µì‹œê°„ ì—…ë°ì´íŠ¸"""
        if self.metrics.total_requests == 1:
            self.metrics.avg_response_time = response_time
        else:
            # ì§€ìˆ˜ ì´ë™ í‰ê· 
            alpha = 0.1
            self.metrics.avg_response_time = (
                alpha * response_time + 
                (1 - alpha) * self.metrics.avg_response_time
            )
            
    async def invalidate(self, category: str, **kwargs):
        """ìºì‹œ ë¬´íš¨í™”"""
        cache_key = self.cache_key(category, **kwargs)
        
        # L1 ë©”ëª¨ë¦¬ ìºì‹œì—ì„œ ì œê±°
        self.memory_cache.pop(cache_key, None)
        if cache_key in self.cache_access_order:
            self.cache_access_order.remove(cache_key)
            
        # L2 Redis ìºì‹œì—ì„œ ì œê±°
        if self.redis_client:
            redis_key = f"cache:{cache_key}"
            await self.redis_client.delete(redis_key)
            
        self.logger.info(f"ğŸ—‘ï¸ ìºì‹œ ë¬´íš¨í™”: {category}")
        
    async def invalidate_pattern(self, pattern: str):
        """íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”"""
        # ë©”ëª¨ë¦¬ ìºì‹œ íŒ¨í„´ ë§¤ì¹­ (ê°„ë‹¨í•œ êµ¬í˜„)
        keys_to_remove = []
        for key in self.memory_cache.keys():
            if pattern in key:
                keys_to_remove.append(key)
                
        for key in keys_to_remove:
            self.memory_cache.pop(key, None)
            if key in self.cache_access_order:
                self.cache_access_order.remove(key)
                
        # Redis íŒ¨í„´ ë§¤ì¹­
        if self.redis_client:
            redis_pattern = f"cache:*{pattern}*"
            async for key in self.redis_client.scan_iter(match=redis_pattern):
                await self.redis_client.delete(key)
                
        self.logger.info(f"ğŸ§¹ íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”: {pattern}")
        
    async def clear_all(self):
        """ëª¨ë“  ìºì‹œ ì‚­ì œ"""
        # ë©”ëª¨ë¦¬ ìºì‹œ í´ë¦¬ì–´
        self.memory_cache.clear()
        self.cache_access_order.clear()
        
        # Redis ìºì‹œ í´ë¦¬ì–´
        if self.redis_client:
            async for key in self.redis_client.scan_iter(match="cache:*"):
                await self.redis_client.delete(key)
                
        self.logger.info("ğŸ§¹ ëª¨ë“  ìºì‹œ ì‚­ì œ ì™„ë£Œ")
        
    def get_metrics(self) -> Dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return {
            'hit_rate': self.metrics.hit_rate,
            'miss_rate': self.metrics.miss_rate,
            'total_requests': self.metrics.total_requests,
            'avg_response_time_ms': self.metrics.avg_response_time * 1000,
            'memory_cache_size': len(self.memory_cache),
            'memory_usage_mb': self._calculate_memory_usage(),
            'cache_efficiency': self._calculate_cache_efficiency()
        }
        
    def _calculate_memory_usage(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³„ì‚° (MB)"""
        # ê°„ëµí•œ ì¶”ì •
        total_size = 0
        for entry in self.memory_cache.values():
            # JSON ì§ë ¬í™” í¬ê¸°ë¡œ ì¶”ì •
            total_size += len(json.dumps(entry['data'], default=str))
        return total_size / (1024 * 1024)
        
    def _calculate_cache_efficiency(self) -> float:
        """ìºì‹œ íš¨ìœ¨ì„± ì ìˆ˜ (0-100)"""
        hit_rate_score = self.metrics.hit_rate
        response_time_score = max(0, 100 - self.metrics.avg_response_time * 1000)  # ms ê¸°ì¤€
        
        return (hit_rate_score * 0.7 + response_time_score * 0.3)

# ë°ì½”ë ˆì´í„° ê¸°ë°˜ ìºì‹±
def cached(category: str, ttl: int = 300, cache_manager: SmartCacheManager = None):
    """ìºì‹± ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            if cache_manager is None:
                return await func(*args, **kwargs)
                
            # ìºì‹œ í‚¤ ìƒì„±ì„ ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì²˜ë¦¬
            cache_kwargs = {
                'func_name': func.__name__,
                'args': str(args),
                **kwargs
            }
            
            # ìºì‹œì—ì„œ ì¡°íšŒ
            cached_result = await cache_manager.get(category, **cache_kwargs)
            if cached_result is not None:
                return cached_result
                
            # ìºì‹œ ë¯¸ìŠ¤ ì‹œ í•¨ìˆ˜ ì‹¤í–‰
            result = await func(*args, **kwargs)
            
            # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥
            await cache_manager.set(category, result, **cache_kwargs)
            
            return result
        return wrapper
    return decorator

class CacheWarming:
    """ìºì‹œ ì›Œë°ì—… ë° í”„ë¦¬ë¡œë”©"""
    
    def __init__(self, cache_manager: SmartCacheManager):
        self.cache_manager = cache_manager
        self.logger = logging.getLogger(__name__)
        
    async def warm_up_user_data(self, user_ids: List[str]):
        """ì‚¬ìš©ì ë°ì´í„° í”„ë¦¬ë¡œë”©"""
        self.logger.info(f"ğŸ”¥ ì‚¬ìš©ì ë°ì´í„° ì›Œë°ì—… ì‹œì‘: {len(user_ids)}ëª…")
        
        for user_id in user_ids:
            # ì‚¬ìš©ì í”„ë¡œí•„ í”„ë¦¬ë¡œë“œ
            await self._preload_user_profile(user_id)
            
            # ì‚¬ìš©ìë³„ ëª¨ë¸ ëª©ë¡ í”„ë¦¬ë¡œë“œ
            await self._preload_user_models(user_id)
            
        self.logger.info("âœ… ì‚¬ìš©ì ë°ì´í„° ì›Œë°ì—… ì™„ë£Œ")
        
    async def _preload_user_profile(self, user_id: str):
        """ì‚¬ìš©ì í”„ë¡œí•„ í”„ë¦¬ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
        fake_profile = {
            'id': user_id,
            'name': f'User {user_id}',
            'role': 'evaluator',
            'preferences': {'theme': 'dark', 'language': 'ko'}
        }
        
        await self.cache_manager.set(
            'user_profile', 
            fake_profile, 
            user_id=user_id
        )
        
    async def _preload_user_models(self, user_id: str):
        """ì‚¬ìš©ì ëª¨ë¸ ëª©ë¡ í”„ë¦¬ë¡œë“œ"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
        fake_models = [
            {'id': f'model_{i}', 'name': f'Model {i}', 'type': 'text'}
            for i in range(10)
        ]
        
        await self.cache_manager.set(
            'model_list',
            fake_models,
            user_id=user_id
        )
        
    async def warm_up_common_data(self):
        """ê³µí†µ ë°ì´í„° í”„ë¦¬ë¡œë”©"""
        self.logger.info("ğŸ”¥ ê³µí†µ ë°ì´í„° ì›Œë°ì—… ì‹œì‘")
        
        # ì „ì²´ ëª¨ë¸ ëª©ë¡
        await self._preload_all_models()
        
        # í‰ê°€ í…œí”Œë¦¿
        await self._preload_evaluation_templates()
        
        # ì‹œìŠ¤í…œ ì„¤ì •
        await self._preload_system_settings()
        
        self.logger.info("âœ… ê³µí†µ ë°ì´í„° ì›Œë°ì—… ì™„ë£Œ")
        
    async def _preload_all_models(self):
        """ì „ì²´ ëª¨ë¸ ëª©ë¡ í”„ë¦¬ë¡œë“œ"""
        fake_models = [
            {'id': f'model_{i}', 'name': f'Model {i}', 'provider': 'openai'}
            for i in range(50)
        ]
        
        await self.cache_manager.set('model_list', fake_models, scope='all')
        
    async def _preload_evaluation_templates(self):
        """í‰ê°€ í…œí”Œë¦¿ í”„ë¦¬ë¡œë“œ"""
        templates = [
            {'id': f'template_{i}', 'name': f'Template {i}', 'criteria': []}
            for i in range(20)
        ]
        
        await self.cache_manager.set('evaluation_templates', templates)
        
    async def _preload_system_settings(self):
        """ì‹œìŠ¤í…œ ì„¤ì • í”„ë¦¬ë¡œë“œ"""
        settings = {
            'ui_theme': 'auto',
            'default_language': 'ko',
            'max_file_size': '10MB',
            'session_timeout': 1800
        }
        
        await self.cache_manager.set('system_settings', settings)

async def main():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ë°ëª¨"""
    cache_manager = SmartCacheManager()
    await cache_manager.connect()
    
    try:
        print("ğŸš€ API ìºì‹± ì „ëµ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 50)
        
        # ìºì‹œ ì›Œë°ì—…
        cache_warming = CacheWarming(cache_manager)
        await cache_warming.warm_up_common_data()
        await cache_warming.warm_up_user_data(['user1', 'user2', 'user3'])
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        start_time = time.time()
        
        # ì—¬ëŸ¬ ë²ˆ ì¡°íšŒí•˜ì—¬ ìºì‹œ íš¨ê³¼ ì¸¡ì •
        for i in range(100):
            # ìºì‹œëœ ë°ì´í„° ì¡°íšŒ
            models = await cache_manager.get('model_list', scope='all')
            user_profile = await cache_manager.get('user_profile', user_id='user1')
            
        end_time = time.time()
        
        # ë©”íŠ¸ë¦­ ì¶œë ¥
        metrics = cache_manager.get_metrics()
        print(f"ğŸ“Š ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
        print(f"  âœ… ìºì‹œ ì ì¤‘ë¥ : {metrics['hit_rate']:.1f}%")
        print(f"  âš¡ í‰ê·  ì‘ë‹µì‹œê°„: {metrics['avg_response_time_ms']:.1f}ms")
        print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {metrics['memory_usage_mb']:.2f}MB")
        print(f"  ğŸ¯ ìºì‹œ íš¨ìœ¨ì„±: {metrics['cache_efficiency']:.1f}/100")
        print(f"  ğŸ“ˆ ì´ ìš”ì²­ ìˆ˜: {metrics['total_requests']}")
        
        print(f"\nâ±ï¸ 100íšŒ ì¡°íšŒ ì†Œìš”ì‹œê°„: {(end_time - start_time) * 1000:.1f}ms")
        print("âœ… API ìºì‹± ì „ëµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    finally:
        await cache_manager.disconnect()

if __name__ == "__main__":
    asyncio.run(main())