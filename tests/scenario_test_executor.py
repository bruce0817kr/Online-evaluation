#!/usr/bin/env python3
"""
Scenario Test Executor
ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ëŒ€ì‹œë³´ë“œ ì—°ë™
"""

import asyncio
import json
import time
import websockets
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import logging
from mcp_scenario_runner import MCPScenarioRunner
from cross_role_integration_tester import CrossRoleIntegrationTester

logger = logging.getLogger('ScenarioTestExecutor')

class ScenarioTestExecutor:
    def __init__(self, dashboard_port: int = 8765):
        self.dashboard_port = dashboard_port
        self.scenario_runner = MCPScenarioRunner()
        self.integration_tester = CrossRoleIntegrationTester()
        
        self.active_sessions = {}
        self.test_status = {
            'system_status': 'ready',
            'running_scenarios': [],
            'completed_scenarios': [],
            'failed_scenarios': [],
            'active_users': [],
            'metrics': {
                'total_scenarios': 0,
                'success_rate': 0,
                'avg_response_time': 0,
                'error_rate': 0
            }
        }
        
        self.websocket_clients = set()
        
    async def start_dashboard_server(self):
        """ëŒ€ì‹œë³´ë“œ ì›¹ì†Œì¼“ ì„œë²„ ì‹œì‘"""
        logger.info(f"ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘: ws://localhost:{self.dashboard_port}")
        
        async def handle_client(websocket, path):
            self.websocket_clients.add(websocket)
            logger.info(f"ëŒ€ì‹œë³´ë“œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²°: {websocket.remote_address}")
            
            try:
                # ì´ˆê¸° ìƒíƒœ ì „ì†¡
                await self.send_dashboard_update('initial_state', self.test_status)
                
                # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
                async for message in websocket:
                    await self.handle_dashboard_command(message, websocket)
                    
            except websockets.exceptions.ConnectionClosed:
                logger.info("ëŒ€ì‹œë³´ë“œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì¢…ë£Œ")
            finally:
                self.websocket_clients.discard(websocket)
        
        return await websockets.serve(handle_client, "localhost", self.dashboard_port)
    
    async def handle_dashboard_command(self, message: str, websocket):
        """ëŒ€ì‹œë³´ë“œ ëª…ë ¹ ì²˜ë¦¬"""
        try:
            command = json.loads(message)
            action = command.get('action')
            
            if action == 'run_all_scenarios':
                await self.execute_all_scenarios()
            elif action == 'run_scenario':
                scenario_id = command.get('scenario_id')
                user_role = command.get('user_role')
                await self.execute_single_scenario(scenario_id, user_role)
            elif action == 'stop_tests':
                await self.stop_all_tests()
            elif action == 'get_status':
                await websocket.send(json.dumps({
                    'type': 'status_update',
                    'data': self.test_status
                }))
                
        except json.JSONDecodeError:
            logger.error("ëŒ€ì‹œë³´ë“œ ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜")
        except Exception as e:
            logger.error(f"ëŒ€ì‹œë³´ë“œ ëª…ë ¹ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    async def send_dashboard_update(self, update_type: str, data: Any):
        """ëª¨ë“  ëŒ€ì‹œë³´ë“œ í´ë¼ì´ì–¸íŠ¸ì— ì—…ë°ì´íŠ¸ ì „ì†¡"""
        if not self.websocket_clients:
            return
            
        message = json.dumps({
            'type': update_type,
            'timestamp': datetime.now().isoformat(),
            'data': data
        })
        
        # ì—°ê²°ì´ ëŠì–´ì§„ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        disconnected_clients = set()
        
        for client in self.websocket_clients:
            try:
                await client.send(message)
            except websockets.exceptions.ConnectionClosed:
                disconnected_clients.add(client)
        
        self.websocket_clients -= disconnected_clients
    
    async def execute_all_scenarios(self):
        """ëª¨ë“  ì£¼ìš” ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        logger.info("ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì‹œì‘")
        
        scenarios = [
            {'scenario_id': 'admin_initial_setup', 'user_role': 'admin'},
            {'scenario_id': 'secretary_project_creation', 'user_role': 'secretary'},
            {'scenario_id': 'evaluator_ai_assisted_evaluation', 'user_role': 'evaluator'},
            {'scenario_id': 'complete_evaluation_lifecycle', 'user_role': 'cross'}
        ]
        
        self.test_status['system_status'] = 'running'
        self.test_status['total_scenarios'] = len(scenarios)
        
        await self.send_dashboard_update('test_started', {
            'total_scenarios': len(scenarios),
            'scenarios': scenarios
        })
        
        results = []
        
        for i, scenario in enumerate(scenarios):
            await self.send_dashboard_update('scenario_started', {
                'scenario_id': scenario['scenario_id'],
                'user_role': scenario['user_role'],
                'progress': i / len(scenarios) * 100
            })
            
            try:
                if scenario['user_role'] == 'cross':
                    # êµì°¨ ì—­í•  í†µí•© í…ŒìŠ¤íŠ¸
                    result = await self.integration_tester.execute_complete_evaluation_lifecycle()
                    success = result.success
                else:
                    # ì¼ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
                    result = await self.scenario_runner.execute_scenario(
                        scenario['scenario_id'], 
                        scenario['user_role']
                    )
                    success = result.status == 'success'
                
                if success:
                    self.test_status['completed_scenarios'].append(scenario['scenario_id'])
                else:
                    self.test_status['failed_scenarios'].append(scenario['scenario_id'])
                
                results.append(result)
                
                await self.send_dashboard_update('scenario_completed', {
                    'scenario_id': scenario['scenario_id'],
                    'success': success,
                    'progress': (i + 1) / len(scenarios) * 100
                })
                
            except Exception as e:
                logger.error(f"ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì˜¤ë¥˜: {scenario['scenario_id']} - {str(e)}")
                self.test_status['failed_scenarios'].append(scenario['scenario_id'])
                
                await self.send_dashboard_update('scenario_failed', {
                    'scenario_id': scenario['scenario_id'],
                    'error': str(e)
                })
        
        # ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸
        success_count = len(self.test_status['completed_scenarios'])
        self.test_status['metrics']['success_rate'] = (success_count / len(scenarios)) * 100
        self.test_status['system_status'] = 'completed'
        
        await self.send_dashboard_update('all_tests_completed', {
            'success_count': success_count,
            'total_count': len(scenarios),
            'success_rate': self.test_status['metrics']['success_rate']
        })
        
        # ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        report_file = await self.generate_comprehensive_report(results)
        
        await self.send_dashboard_update('report_generated', {
            'report_file': report_file
        })
        
        logger.info(f"ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì™„ë£Œ: {success_count}/{len(scenarios)} ì„±ê³µ")
    
    async def execute_single_scenario(self, scenario_id: str, user_role: str):
        """ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
        logger.info(f"ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰: {scenario_id} ({user_role})")
        
        await self.send_dashboard_update('scenario_started', {
            'scenario_id': scenario_id,
            'user_role': user_role
        })
        
        try:
            if user_role == 'cross':
                # êµì°¨ ì—­í•  í†µí•© í…ŒìŠ¤íŠ¸
                if scenario_id == 'complete_evaluation_lifecycle':
                    result = await self.integration_tester.execute_complete_evaluation_lifecycle()
                elif scenario_id == 'realtime_collaborative_evaluation':
                    result = await self.integration_tester.execute_realtime_collaborative_evaluation()
                else:
                    raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” êµì°¨ ì—­í•  ì‹œë‚˜ë¦¬ì˜¤: {scenario_id}")
                
                success = result.success
            else:
                # ì¼ë°˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
                result = await self.scenario_runner.execute_scenario(scenario_id, user_role)
                success = result.status == 'success'
            
            if success:
                self.test_status['completed_scenarios'].append(scenario_id)
            else:
                self.test_status['failed_scenarios'].append(scenario_id)
            
            await self.send_dashboard_update('scenario_completed', {
                'scenario_id': scenario_id,
                'success': success,
                'result': result if hasattr(result, '__dict__') else str(result)
            })
            
        except Exception as e:
            logger.error(f"ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì˜¤ë¥˜: {scenario_id} - {str(e)}")
            self.test_status['failed_scenarios'].append(scenario_id)
            
            await self.send_dashboard_update('scenario_failed', {
                'scenario_id': scenario_id,
                'error': str(e)
            })
    
    async def stop_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¤‘ì§€"""
        logger.info("ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¤‘ì§€")
        
        self.test_status['system_status'] = 'stopped'
        self.test_status['running_scenarios'] = []
        
        await self.send_dashboard_update('tests_stopped', {
            'message': 'ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
    
    async def monitor_user_sessions(self):
        """ì‚¬ìš©ì ì„¸ì…˜ ëª¨ë‹ˆí„°ë§"""
        while True:
            try:
                # í™œì„± ì‚¬ìš©ì ì„¸ì…˜ í™•ì¸
                active_users = []
                
                for session_id, session_info in self.active_sessions.items():
                    if session_info.get('last_activity'):
                        time_diff = time.time() - session_info['last_activity']
                        if time_diff < 300:  # 5ë¶„ ì´ë‚´ í™œë™
                            active_users.append({
                                'session_id': session_id,
                                'role': session_info.get('role'),
                                'name': session_info.get('name'),
                                'status': 'active',
                                'last_action': session_info.get('last_action'),
                                'session_duration': session_info.get('session_duration', 0)
                            })
                
                self.test_status['active_users'] = active_users
                
                await self.send_dashboard_update('user_sessions_update', {
                    'active_users': active_users,
                    'total_sessions': len(self.active_sessions)
                })
                
                await asyncio.sleep(5)  # 5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
                
            except Exception as e:
                logger.error(f"ì‚¬ìš©ì ì„¸ì…˜ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(10)
    
    async def monitor_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§"""
        while True:
            try:
                # ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                metrics = {
                    'avg_response_time': self.calculate_avg_response_time(),
                    'error_rate': self.calculate_error_rate(),
                    'throughput': self.calculate_throughput(),
                    'memory_usage': self.get_memory_usage(),
                    'cpu_usage': self.get_cpu_usage()
                }
                
                self.test_status['metrics'].update(metrics)
                
                await self.send_dashboard_update('metrics_update', metrics)
                
                await asyncio.sleep(3)  # 3ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
                
            except Exception as e:
                logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(10)
    
    def calculate_avg_response_time(self) -> float:
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” API ì‘ë‹µ ì‹œê°„ ìˆ˜ì§‘
        import random
        return round(random.uniform(150, 350), 1)
    
    def calculate_error_rate(self) -> float:
        """ì˜¤ë¥˜ìœ¨ ê³„ì‚°"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì˜¤ë¥˜ ë°œìƒë¥  ê³„ì‚°
        import random
        return round(random.uniform(0, 5), 2)
    
    def calculate_throughput(self) -> float:
        """ì²˜ë¦¬ëŸ‰ ê³„ì‚°"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” TPS ê³„ì‚°
        import random
        return round(random.uniform(50, 150), 1)
    
    def get_memory_usage(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¡°íšŒ"""
        try:
            import psutil
            return psutil.virtual_memory().percent
        except ImportError:
            import random
            return round(random.uniform(40, 80), 1)
    
    def get_cpu_usage(self) -> float:
        """CPU ì‚¬ìš©ë¥  ì¡°íšŒ"""
        try:
            import psutil
            return psutil.cpu_percent(interval=1)
        except ImportError:
            import random
            return round(random.uniform(20, 70), 1)
    
    async def generate_comprehensive_report(self, results: List[Any]) -> str:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"tests/results/comprehensive_scenario_report_{timestamp}.json"
        
        # ë³´ê³ ì„œ ë°ì´í„° êµ¬ì„±
        report_data = {
            'test_summary': {
                'timestamp': timestamp,
                'total_scenarios': len(results),
                'completed_scenarios': len(self.test_status['completed_scenarios']),
                'failed_scenarios': len(self.test_status['failed_scenarios']),
                'success_rate': self.test_status['metrics']['success_rate'],
                'execution_duration': self.calculate_total_execution_time(results)
            },
            'scenario_results': [
                self.format_result_for_report(result) for result in results
            ],
            'system_metrics': self.test_status['metrics'],
            'user_sessions': self.test_status['active_users'],
            'recommendations': self.generate_improvement_recommendations()
        }
        
        # JSON ë³´ê³ ì„œ ì €ì¥
        Path("tests/results").mkdir(exist_ok=True)
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False, default=str)
        
        # HTML ë³´ê³ ì„œ ìƒì„±
        html_report = await self.generate_html_dashboard_report(report_data)
        html_file = report_file.replace('.json', '.html')
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        logger.info(f"ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")
        return report_file
    
    def format_result_for_report(self, result: Any) -> Dict[str, Any]:
        """ë³´ê³ ì„œìš© ê²°ê³¼ í¬ë§·"""
        if hasattr(result, '__dict__'):
            return {
                'scenario_id': getattr(result, 'scenario_id', 'unknown'),
                'user_role': getattr(result, 'user_role', 'unknown'),
                'status': getattr(result, 'status', 'unknown'),
                'execution_time': getattr(result, 'execution_time', 0),
                'success': getattr(result, 'success', False),
                'errors': getattr(result, 'errors', [])
            }
        else:
            return {'result': str(result)}
    
    def calculate_total_execution_time(self, results: List[Any]) -> float:
        """ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°"""
        total_time = 0
        for result in results:
            if hasattr(result, 'execution_time'):
                total_time += result.execution_time
        return total_time
    
    def generate_improvement_recommendations(self) -> List[str]:
        """ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        success_rate = self.test_status['metrics']['success_rate']
        if success_rate < 90:
            recommendations.append(f"ì‹œë‚˜ë¦¬ì˜¤ ì„±ê³µë¥ ì´ {success_rate:.1f}%ì…ë‹ˆë‹¤. 90% ì´ìƒ ë‹¬ì„±ì„ ëª©í‘œë¡œ ê°œì„ í•˜ì„¸ìš”.")
        
        error_rate = self.test_status['metrics']['error_rate']
        if error_rate > 3:
            recommendations.append(f"ì˜¤ë¥˜ìœ¨ì´ {error_rate:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤. 3% ì´í•˜ë¡œ ê°œì„ í•˜ì„¸ìš”.")
        
        avg_response_time = self.test_status['metrics']['avg_response_time']
        if avg_response_time > 300:
            recommendations.append(f"í‰ê·  ì‘ë‹µ ì‹œê°„ì´ {avg_response_time:.1f}msì…ë‹ˆë‹¤. 300ms ì´í•˜ë¡œ ìµœì í™”í•˜ì„¸ìš”.")
        
        return recommendations
    
    async def generate_html_dashboard_report(self, report_data: Dict[str, Any]) -> str:
        """HTML ëŒ€ì‹œë³´ë“œ ë³´ê³ ì„œ ìƒì„±"""
        # ê°„ë‹¨í•œ HTML í…œí”Œë¦¿
        html_content = f'''
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
        .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .metric-card {{ background: #f8f9fa; padding: 20px; border-radius: 8px; text-align: center; }}
        .metric-value {{ font-size: 2em; font-weight: bold; color: #007bff; }}
        .recommendations {{ background: #e9ecef; padding: 20px; border-radius: 8px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background: #f8f9fa; }}
        .success {{ color: #28a745; }}
        .failed {{ color: #dc3545; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ MCP ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ</h1>
            <p>ìƒì„± ì‹œê°„: {report_data['test_summary']['timestamp']}</p>
        </div>
        
        <div class="metrics">
            <div class="metric-card">
                <div class="metric-value">{report_data['test_summary']['total_scenarios']}</div>
                <div>ì´ ì‹œë‚˜ë¦¬ì˜¤</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{report_data['test_summary']['success_rate']:.1f}%</div>
                <div>ì„±ê³µë¥ </div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{report_data['test_summary']['execution_duration']:.1f}s</div>
                <div>ì´ ì‹¤í–‰ì‹œê°„</div>
            </div>
        </div>
        
        <h2>ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼</h2>
        <table>
            <thead>
                <tr>
                    <th>ì‹œë‚˜ë¦¬ì˜¤ ID</th>
                    <th>ì‚¬ìš©ì ì—­í• </th>
                    <th>ìƒíƒœ</th>
                    <th>ì‹¤í–‰ì‹œê°„</th>
                </tr>
            </thead>
            <tbody>
        '''
        
        # ì‹œë‚˜ë¦¬ì˜¤ ê²°ê³¼ í…Œì´ë¸”
        for result in report_data['scenario_results']:
            status_class = 'success' if result.get('success') else 'failed'
            html_content += f'''
                <tr>
                    <td>{result.get('scenario_id', 'N/A')}</td>
                    <td>{result.get('user_role', 'N/A')}</td>
                    <td class="{status_class}">{result.get('status', 'N/A')}</td>
                    <td>{result.get('execution_time', 0):.1f}s</td>
                </tr>
            '''
        
        html_content += f'''
            </tbody>
        </table>
        
        <div class="recommendations">
            <h2>ğŸ’¡ ê°œì„  ê¶Œê³ ì‚¬í•­</h2>
            <ul>
        '''
        
        # ê¶Œê³ ì‚¬í•­ ì¶”ê°€
        for recommendation in report_data['recommendations']:
            html_content += f'<li>{recommendation}</li>'
        
        html_content += '''
            </ul>
        </div>
    </div>
</body>
</html>
        '''
        
        return html_content
    
    async def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        logger.info("ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸° ì‹œì‘")
        
        # ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘
        server = await self.start_dashboard_server()
        
        # ë°±ê·¸ë¼ìš´ë“œ ëª¨ë‹ˆí„°ë§ ì‘ì—… ì‹œì‘
        monitoring_tasks = [
            asyncio.create_task(self.monitor_user_sessions()),
            asyncio.create_task(self.monitor_system_metrics())
        ]
        
        try:
            logger.info("ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸° ì¤€ë¹„ ì™„ë£Œ")
            print(f"ğŸš€ ëŒ€ì‹œë³´ë“œ URL: http://localhost:{self.dashboard_port}")
            print("ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
            
            # ì„œë²„ ì‹¤í–‰ ìœ ì§€
            await server.wait_closed()
            
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        finally:
            # ì •ë¦¬ ì‘ì—…
            for task in monitoring_tasks:
                task.cancel()
            server.close()
            await server.wait_closed()

# CLI ì‹¤í–‰
async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°')
    parser.add_argument('--port', type=int, default=8765, help='ëŒ€ì‹œë³´ë“œ í¬íŠ¸')
    parser.add_argument('--auto-run', action='store_true', help='ìë™ìœ¼ë¡œ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰')
    
    args = parser.parse_args()
    
    executor = ScenarioTestExecutor(dashboard_port=args.port)
    
    if args.auto_run:
        # ìë™ ì‹¤í–‰ ëª¨ë“œ
        await executor.execute_all_scenarios()
    else:
        # ëŒ€ì‹œë³´ë“œ ëª¨ë“œ
        await executor.run()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    asyncio.run(main())