# =================== Elasticsearch Output Configuration ===================
#
# Optimized output configuration for sending processed logs to Elasticsearch
# Includes performance tuning and error handling

output {
  # ============================= PRIMARY ELASTICSEARCH OUTPUT =============================
  
  elasticsearch {
    # Cluster configuration
    hosts => ["elasticsearch:9200"]
    
    # Index configuration with dynamic naming
    index => "%{[@metadata][index_prefix]}-%{+YYYY.MM.dd}"
    
    # Document configuration
    document_type => "_doc"
    document_id => "%{[@metadata][fingerprint]}"  # Optional: for deduplication
    
    # Performance optimization
    workers => 2
    flush_size => 1000
    idle_flush_time => 1
    
    # Connection settings
    timeout => 60
    connect_timeout => 10
    retry_initial_interval => 2
    retry_max_interval => 64
    retry_on_conflict => 3
    
    # Bulk request settings
    http_compression => true
    
    # Template management (disabled - using index templates from ES)
    manage_template => false
    
    # ILM settings
    ilm_enabled => true
    
    # Health check
    healthcheck_enabled => true
    healthcheck_path => "/_cluster/health"
    
    # Authentication (disabled for development)
    # user => "logstash_writer"
    # password => "${ELASTICSEARCH_PASSWORD}"
    
    # SSL settings (disabled for development)
    # ssl => true
    # ssl_certificate_verification => true
    # cacert => "/etc/logstash/ssl/ca.crt"
    
    # Error handling
    action => "index"  # or "create" for strict deduplication
    
    # Failure handling
    retry_on_failure => 3
    
    # Pool settings for connection management
    pool_max => 1000
    pool_max_per_route => 100
    
    # Custom headers (optional)
    # custom_headers => {
    #   "X-Logstash-Version" => "8.0"
    # }
  }
  
  # ============================= CONDITIONAL OUTPUTS =============================
  
  # Debug output for troubleshooting (only when debug tag is present)
  if "debug" in [tags] or [@metadata][debug] == "true" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
  
  # Error output for failed processing
  if "_grokparsefailure" in [tags] or "_jsonparsefailure" in [tags] or "_dateparsefailure" in [tags] {
    file {
      path => "/var/log/logstash/failed_parsing.log"
      codec => json_lines
    }
  }
  
  # High-priority logs output (errors, critical events)
  if [level] == "ERROR" or [level] == "CRITICAL" or "server_error" in [tags] {
    # Send to priority index for faster access
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "priority-logs-%{+YYYY.MM.dd}"
      workers => 1
      flush_size => 100
      idle_flush_time => 1
    }
    
    # Optional: Send alerts to external systems
    # http {
    #   url => "http://alertmanager:9093/api/v1/alerts"
    #   http_method => "post"
    #   format => "json"
    #   mapping => {
    #     "alerts" => [
    #       {
    #         "labels" => {
    #           "alertname" => "LogError"
    #           "severity" => "%{level}"
    #           "service" => "%{service_type}"
    #           "instance" => "%{[host][name]}"
    #         }
    #         "annotations" => {
    #           "summary" => "%{log_message}"
    #           "description" => "Error log detected in %{service_type}"
    #         }
    #       }
    #     ]
    #   }
    # }
  }
  
  # ============================= DEAD LETTER QUEUE =============================
  
  # Handle documents that failed to be indexed
  if "_elasticsearch_output_failure" in [tags] {
    file {
      path => "/var/log/logstash/elasticsearch_failures_%{+YYYY_MM_dd}.log"
      codec => json_lines
    }
    
    # Optional: Send to alternative storage
    # file {
    #   path => "/backup/elasticsearch_failures_%{+YYYY_MM_dd}.log"
    #   codec => json_lines
    # }
  }
  
  # ============================= METRICS OUTPUT =============================
  
  # Output metrics to monitoring system (optional)
  # if [@metadata][metrics] {
  #   http {
  #     url => "http://prometheus:9090/api/v1/write"
  #     http_method => "post"
  #     format => "json"
  #     mapping => {
  #       "metric_name" => "logstash_events_processed"
  #       "value" => 1
  #       "labels" => {
  #         "source" => "%{log_source}"
  #         "index" => "%{[@metadata][index_prefix]}"
  #         "level" => "%{level}"
  #       }
  #     }
  #   }
  # }
  
  # ============================= DEVELOPMENT OUTPUTS =============================
  
  # File output for development/testing
  if [@metadata][environment] == "development" {
    file {
      path => "/var/log/logstash/all_logs_%{+YYYY_MM_dd}.log"
      codec => json_lines
    }
  }
}
