#!/bin/bash

# ğŸš€ AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
# ë°±ì—”ë“œ í˜ë¥´ì†Œë‚˜ ì¤‘ì‹¬ì˜ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ ë°°í¬ ìë™í™”

set -euo pipefail

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
NC='\033[0m' # No Color

# ì•„ì´ì½˜ ì •ì˜
ROCKET="ğŸš€"
CHECK="âœ…"
CROSS="âŒ"
WARNING="âš ï¸"
INFO="â„¹ï¸"
GEAR="âš™ï¸"
SHIELD="ğŸ›¡ï¸"
CHART="ğŸ“Š"

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENVIRONMENT="${ENVIRONMENT:-staging}"
PROJECT_NAME="${PROJECT_NAME:-ai-model-mgmt}"
AWS_REGION="${AWS_REGION:-ap-northeast-2}"
ECR_REGISTRY="${ECR_REGISTRY:-$(aws sts get-caller-identity --query Account --output text).dkr.ecr.${AWS_REGION}.amazonaws.com}"
IMAGE_TAG="${IMAGE_TAG:-staging-$(date +%Y%m%d-%H%M%S)}"
DEPLOY_DIR="/app"
BACKUP_DIR="/app/backups"
LOG_FILE="/var/log/deploy_${ENVIRONMENT}_$(date +%Y%m%d_%H%M%S).log"

# ë¡œê¹… í•¨ìˆ˜
log() {
    local level=$1
    shift
    local message="$*"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case $level in
        "INFO")
            echo -e "${BLUE}${INFO} ${WHITE}[${timestamp}] $message${NC}" | tee -a "$LOG_FILE"
            ;;
        "SUCCESS")
            echo -e "${GREEN}${CHECK} ${WHITE}[${timestamp}] $message${NC}" | tee -a "$LOG_FILE"
            ;;
        "ERROR")
            echo -e "${RED}${CROSS} ${WHITE}[${timestamp}] $message${NC}" | tee -a "$LOG_FILE"
            ;;
        "WARNING")
            echo -e "${YELLOW}${WARNING} ${WHITE}[${timestamp}] $message${NC}" | tee -a "$LOG_FILE"
            ;;
        "HEADER")
            echo -e "\n${CYAN}$message${NC}" | tee -a "$LOG_FILE"
            echo -e "${CYAN}$(printf '%.0s=' {1..60})${NC}" | tee -a "$LOG_FILE"
            ;;
    esac
}

# ì—ëŸ¬ í•¸ë“¤ë§
error_handler() {
    local line_no=$1
    log "ERROR" "ë°°í¬ ì‹¤íŒ¨ (ë¼ì¸ $line_no)"
    log "ERROR" "ë¡¤ë°±ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
    rollback_deployment
    exit 1
}

trap 'error_handler $LINENO' ERR

# ì‹œì‘ ë©”ì‹œì§€
log "HEADER" "${ROCKET} AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬"
log "INFO" "ë°°í¬ í™˜ê²½: $ENVIRONMENT"
log "INFO" "í”„ë¡œì íŠ¸: $PROJECT_NAME"
log "INFO" "ECR ë ˆì§€ìŠ¤íŠ¸ë¦¬: $ECR_REGISTRY"
log "INFO" "ì´ë¯¸ì§€ íƒœê·¸: $IMAGE_TAG"

# ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì‚¬
check_prerequisites() {
    log "HEADER" "${GEAR} ì‚¬ì „ ìš”êµ¬ì‚¬í•­ ê²€ì‚¬"
    
    # í•„ìˆ˜ ëª…ë ¹ì–´ í™•ì¸
    local required_commands=("docker" "docker-compose" "aws" "curl" "jq")
    for cmd in "${required_commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null; then
            log "ERROR" "$cmd ëª…ë ¹ì–´ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            exit 1
        fi
        log "SUCCESS" "$cmd ëª…ë ¹ì–´ í™•ì¸ë¨"
    done
    
    # AWS ì¸ì¦ í™•ì¸
    if ! aws sts get-caller-identity &> /dev/null; then
        log "ERROR" "AWS ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤"
        exit 1
    fi
    log "SUCCESS" "AWS ì¸ì¦ í™•ì¸ë¨"
    
    # ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
    local available_space=$(df /app | tail -1 | awk '{print $4}')
    local required_space=5242880  # 5GB in KB
    
    if [ "$available_space" -lt "$required_space" ]; then
        log "ERROR" "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± (í•„ìš”: 5GB, ì‚¬ìš©ê°€ëŠ¥: $((available_space/1024/1024))GB)"
        exit 1
    fi
    log "SUCCESS" "ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ë¨ ($((available_space/1024/1024))GB ì‚¬ìš©ê°€ëŠ¥)"
    
    # ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
    if ! curl -s --max-time 10 https://api.github.com > /dev/null; then
        log "ERROR" "ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨"
        exit 1
    fi
    log "SUCCESS" "ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ë¨"
}

# ë°±ì—… ìƒì„±
create_backup() {
    log "HEADER" "${GEAR} í˜„ì¬ ìƒíƒœ ë°±ì—…"
    
    local backup_timestamp=$(date +%Y%m%d_%H%M%S)
    local backup_path="$BACKUP_DIR/backup_$backup_timestamp"
    
    mkdir -p "$backup_path"
    
    # í˜„ì¬ Docker Compose ì„¤ì • ë°±ì—…
    if [ -f "$DEPLOY_DIR/docker-compose.yml" ]; then
        cp "$DEPLOY_DIR/docker-compose.yml" "$backup_path/"
        log "SUCCESS" "Docker Compose ì„¤ì • ë°±ì—…ë¨"
    fi
    
    # í™˜ê²½ ë³€ìˆ˜ ë°±ì—…
    if [ -f "$DEPLOY_DIR/.env" ]; then
        cp "$DEPLOY_DIR/.env" "$backup_path/"
        log "SUCCESS" "í™˜ê²½ ë³€ìˆ˜ ë°±ì—…ë¨"
    fi
    
    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ ì •ë³´ ë°±ì—…
    docker ps --format "table {{.Names}}\t{{.Image}}\t{{.Status}}" > "$backup_path/containers.txt"
    log "SUCCESS" "ì»¨í…Œì´ë„ˆ ìƒíƒœ ë°±ì—…ë¨"
    
    # ì—…ë¡œë“œëœ íŒŒì¼ ë°±ì—… (ì‹¬ë³¼ë¦­ ë§í¬ë¡œ ê³µê°„ ì ˆì•½)
    if [ -d "$DEPLOY_DIR/uploads" ]; then
        ln -s "$DEPLOY_DIR/uploads" "$backup_path/uploads_link"
        log "SUCCESS" "ì—…ë¡œë“œ íŒŒì¼ ë§í¬ ìƒì„±ë¨"
    fi
    
    echo "$backup_path" > "$DEPLOY_DIR/.last_backup"
    log "SUCCESS" "ë°±ì—… ìƒì„± ì™„ë£Œ: $backup_path"
}

# ECR ë¡œê·¸ì¸ ë° ì´ë¯¸ì§€ ì¤€ë¹„
prepare_images() {
    log "HEADER" "${GEAR} ì´ë¯¸ì§€ ì¤€ë¹„"
    
    # ECR ë¡œê·¸ì¸
    log "INFO" "ECRì— ë¡œê·¸ì¸ ì¤‘..."
    aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$ECR_REGISTRY"
    log "SUCCESS" "ECR ë¡œê·¸ì¸ ì„±ê³µ"
    
    # ë°±ì—”ë“œ ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
    log "INFO" "ë°±ì—”ë“œ ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
    cd "$(dirname "$0")/.."
    
    # Docker ì´ë¯¸ì§€ ë¹Œë“œ
    docker build \
        --target production \
        --build-arg BUILD_ENV="$ENVIRONMENT" \
        --build-arg BUILD_TIME="$(date -u +'%Y-%m-%dT%H:%M:%SZ')" \
        --build-arg GIT_COMMIT="$(git rev-parse --short HEAD 2>/dev/null || echo 'unknown')" \
        -t "$ECR_REGISTRY/$PROJECT_NAME/backend:$IMAGE_TAG" \
        -t "$ECR_REGISTRY/$PROJECT_NAME/backend:latest" \
        ./backend
    
    log "SUCCESS" "ì´ë¯¸ì§€ ë¹Œë“œ ì™„ë£Œ"
    
    # ì´ë¯¸ì§€ í‘¸ì‹œ
    log "INFO" "ì´ë¯¸ì§€ë¥¼ ECRì— í‘¸ì‹œ ì¤‘..."
    docker push "$ECR_REGISTRY/$PROJECT_NAME/backend:$IMAGE_TAG"
    docker push "$ECR_REGISTRY/$PROJECT_NAME/backend:latest"
    log "SUCCESS" "ì´ë¯¸ì§€ í‘¸ì‹œ ì™„ë£Œ"
    
    # ì´ë¯¸ì§€ ë³´ì•ˆ ìŠ¤ìº” ê²°ê³¼ í™•ì¸
    log "INFO" "ì´ë¯¸ì§€ ë³´ì•ˆ ìŠ¤ìº” ê²°ê³¼ í™•ì¸ ì¤‘..."
    sleep 30  # ìŠ¤ìº” ì™„ë£Œ ëŒ€ê¸°
    
    scan_result=$(aws ecr describe-image-scan-findings \
        --repository-name "$PROJECT_NAME/backend" \
        --image-id imageTag="$IMAGE_TAG" \
        --query 'imageScanFindingsSummary.findingCounts' \
        --output json 2>/dev/null || echo '{}')
    
    critical_count=$(echo "$scan_result" | jq -r '.CRITICAL // 0')
    high_count=$(echo "$scan_result" | jq -r '.HIGH // 0')
    
    if [ "$critical_count" -gt 0 ] || [ "$high_count" -gt 5 ]; then
        log "WARNING" "ì´ë¯¸ì§€ì— ë³´ì•ˆ ì·¨ì•½ì  ë°œê²¬ (Critical: $critical_count, High: $high_count)"
        log "WARNING" "ë°°í¬ë¥¼ ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (5ì´ˆ í›„ ìë™ ê³„ì†)"
        sleep 5
    else
        log "SUCCESS" "ì´ë¯¸ì§€ ë³´ì•ˆ ìŠ¤ìº” í†µê³¼ (Critical: $critical_count, High: $high_count)"
    fi
}

# í™˜ê²½ ì„¤ì • êµ¬ì„±
setup_environment() {
    log "HEADER" "${GEAR} í™˜ê²½ ì„¤ì • êµ¬ì„±"
    
    cd "$DEPLOY_DIR"
    
    # .env íŒŒì¼ ìƒì„±
    cat <<EOF > .env
# AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ìŠ¤í…Œì´ì§• í™˜ê²½ ì„¤ì •
# ìƒì„±ì¼ì‹œ: $(date)

# ê¸°ë³¸ í™˜ê²½ ì„¤ì •
NODE_ENV=staging
ENVIRONMENT=staging
PROJECT_NAME=$PROJECT_NAME

# Docker ì´ë¯¸ì§€ ì„¤ì •
ECR_REGISTRY=$ECR_REGISTRY
IMAGE_TAG=$IMAGE_TAG

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
MONGO_URL=$MONGO_URL
REDIS_URL=$REDIS_URL

# ë³´ì•ˆ ì„¤ì •
JWT_SECRET=$JWT_SECRET
API_RATE_LIMIT=1000
CORS_ORIGINS=https://staging.ai-model-mgmt.com,https://api-staging.ai-model-mgmt.com

# ì„±ëŠ¥ ì„¤ì •
UVICORN_WORKERS=4
UVICORN_MAX_REQUESTS=1000
UVICORN_MAX_REQUESTS_JITTER=100
DATABASE_POOL_SIZE=20
REDIS_POOL_SIZE=10
CACHE_TTL=300

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
LOG_LEVEL=INFO
MONITORING_ENABLED=true
GRAFANA_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}

# íŒŒì¼ ì—…ë¡œë“œ ì„¤ì •
MAX_FILE_SIZE=50MB
ALLOWED_FILE_TYPES=pdf,docx,xlsx,txt,json
EOF
    
    log "SUCCESS" "í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±ë¨"
    
    # ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±
    mkdir -p uploads logs config data/prometheus data/grafana
    mkdir -p monitoring/{prometheus,grafana,fluent-bit}
    mkdir -p nginx/conf.d
    
    # ê¶Œí•œ ì„¤ì •
    chmod 755 uploads logs config
    chmod 777 data/prometheus data/grafana  # Prometheus/Grafana ì»¨í…Œì´ë„ˆ ê¶Œí•œ
    
    log "SUCCESS" "ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±ë¨"
}

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
setup_monitoring() {
    log "HEADER" "${CHART} ëª¨ë‹ˆí„°ë§ ì„¤ì •"
    
    # Prometheus ì„¤ì •
    cat <<EOF > monitoring/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "rules/*.yml"

scrape_configs:
  - job_name: 'backend-services'
    static_configs:
      - targets: 
        - 'backend-1:9090'
        - 'backend-2:9091'
        - 'backend-3:9092'
        - 'worker:9093'
    metrics_path: '/metrics'
    scrape_interval: 15s
    
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    metrics_path: '/metrics'
    
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

alerting:
  alertmanagers:
    - static_configs:
        - targets: []
EOF
    
    # Grafana í”„ë¡œë¹„ì €ë‹ ì„¤ì •
    mkdir -p monitoring/grafana/provisioning/{datasources,dashboards}
    
    cat <<EOF > monitoring/grafana/provisioning/datasources/prometheus.yml
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: false
EOF
    
    cat <<EOF > monitoring/grafana/provisioning/dashboards/dashboards.yml
apiVersion: 1

providers:
  - name: 'AI Model Management'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
EOF
    
    # Nginx ì„¤ì •
    cat <<EOF > nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    log_format main '\$remote_addr - \$remote_user [\$time_local] "\$request" '
                    '\$status \$body_bytes_sent "\$http_referer" '
                    '"\$http_user_agent" "\$http_x_forwarded_for" '
                    'rt=\$request_time ut=\$upstream_response_time';
    
    access_log /var/log/nginx/access.log main;
    
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
    
    upstream backend {
        least_conn;
        server backend-1:8000 max_fails=3 fail_timeout=30s;
        server backend-2:8001 max_fails=3 fail_timeout=30s;
        server backend-3:8002 max_fails=3 fail_timeout=30s;
    }
    
    server {
        listen 80;
        server_name _;
        
        location /health {
            access_log off;
            return 200 "OK";
            add_header Content-Type text/plain;
        }
        
        location / {
            proxy_pass http://backend;
            proxy_set_header Host \$host;
            proxy_set_header X-Real-IP \$remote_addr;
            proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto \$scheme;
            
            proxy_connect_timeout 30s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
        }
    }
}
EOF
    
    log "SUCCESS" "ëª¨ë‹ˆí„°ë§ ë° Nginx ì„¤ì • ì™„ë£Œ"
}

# ì„œë¹„ìŠ¤ ë°°í¬
deploy_services() {
    log "HEADER" "${ROCKET} ì„œë¹„ìŠ¤ ë°°í¬"
    
    cd "$DEPLOY_DIR"
    
    # Docker Compose ì„¤ì • ë³µì‚¬
    cp "$(dirname "$0")/docker-compose.staging.yml" ./docker-compose.yml
    
    # ê¸°ì¡´ ì„œë¹„ìŠ¤ ì¤‘ì§€ (ê·¸ë ˆì´ìŠ¤í’€)
    log "INFO" "ê¸°ì¡´ ì„œë¹„ìŠ¤ ê·¸ë ˆì´ìŠ¤í’€ ì¤‘ì§€ ì¤‘..."
    if docker-compose ps -q | grep -q .; then
        docker-compose stop --timeout 30
        log "SUCCESS" "ê¸°ì¡´ ì„œë¹„ìŠ¤ ì¤‘ì§€ë¨"
    fi
    
    # ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì •ë¦¬
    log "INFO" "ì˜¤ë˜ëœ Docker ì´ë¯¸ì§€ ì •ë¦¬ ì¤‘..."
    docker image prune -f
    docker system prune -f --volumes
    
    # ìƒˆ ì„œë¹„ìŠ¤ ì‹œì‘
    log "INFO" "ìƒˆ ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
    docker-compose up -d --remove-orphans
    
    log "SUCCESS" "ì„œë¹„ìŠ¤ ë°°í¬ ì™„ë£Œ"
}

# í—¬ìŠ¤ì²´í¬ ë° ê²€ì¦
verify_deployment() {
    log "HEADER" "${SHIELD} ë°°í¬ ê²€ì¦"
    
    local max_attempts=30
    local attempt=1
    local all_healthy=false
    
    # ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬
    while [ $attempt -le $max_attempts ] && [ "$all_healthy" = false ]; do
        log "INFO" "í—¬ìŠ¤ì²´í¬ ì‹œë„ $attempt/$max_attempts"
        
        local healthy_count=0
        local total_services=3
        
        # ê° ë°±ì—”ë“œ ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬
        for port in 8000 8001 8002; do
            if curl -sf "http://localhost:$port/health" > /dev/null 2>&1; then
                healthy_count=$((healthy_count + 1))
                log "SUCCESS" "ë°±ì—”ë“œ ì„œë¹„ìŠ¤ í¬íŠ¸ $port ì •ìƒ"
            else
                log "WARNING" "ë°±ì—”ë“œ ì„œë¹„ìŠ¤ í¬íŠ¸ $port ëŒ€ê¸° ì¤‘..."
            fi
        done
        
        if [ $healthy_count -eq $total_services ]; then
            all_healthy=true
            log "SUCCESS" "ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒ ë™ì‘ ì¤‘"
        else
            log "INFO" "$healthy_count/$total_services ì„œë¹„ìŠ¤ ì •ìƒ, 20ì´ˆ í›„ ì¬ì‹œë„..."
            sleep 20
            attempt=$((attempt + 1))
        fi
    done
    
    if [ "$all_healthy" = false ]; then
        log "ERROR" "í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨, ë¡¤ë°±ì„ ì‹œì‘í•©ë‹ˆë‹¤"
        return 1
    fi
    
    # API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    log "INFO" "API ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
    
    # ê¸°ë³¸ API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
    local api_endpoints=("/health" "/api/health" "/api/models" "/api/users")
    for endpoint in "${api_endpoints[@]}"; do
        if curl -sf "http://localhost:8000$endpoint" > /dev/null 2>&1; then
            log "SUCCESS" "API ì—”ë“œí¬ì¸íŠ¸ $endpoint ì •ìƒ"
        else
            log "WARNING" "API ì—”ë“œí¬ì¸íŠ¸ $endpoint ì ‘ê·¼ ë¶ˆê°€ (ì •ìƒì¼ ìˆ˜ ìˆìŒ)"
        fi
    done
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    log "INFO" "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘..."
    local response_time=$(curl -w "%{time_total}" -s -o /dev/null "http://localhost:8000/health")
    local response_time_ms=$(echo "$response_time * 1000" | bc -l | cut -d. -f1)
    
    if [ "$response_time_ms" -lt 500 ]; then
        log "SUCCESS" "ì‘ë‹µì‹œê°„ í…ŒìŠ¤íŠ¸ í†µê³¼ (${response_time_ms}ms)"
    else
        log "WARNING" "ì‘ë‹µì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤ (${response_time_ms}ms)"
    fi
    
    # ë¡œê·¸ í™•ì¸
    log "INFO" "ì„œë¹„ìŠ¤ ë¡œê·¸ í™•ì¸ ì¤‘..."
    if docker-compose logs --tail=50 | grep -i error; then
        log "WARNING" "ì„œë¹„ìŠ¤ ë¡œê·¸ì— ì—ëŸ¬ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
    else
        log "SUCCESS" "ì„œë¹„ìŠ¤ ë¡œê·¸ ì •ìƒ"
    fi
    
    log "SUCCESS" "ë°°í¬ ê²€ì¦ ì™„ë£Œ"
}

# ëª¨ë‹ˆí„°ë§ ê²€ì¦
verify_monitoring() {
    log "HEADER" "${CHART} ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦"
    
    # Prometheus í—¬ìŠ¤ì²´í¬
    local max_attempts=10
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if curl -sf "http://localhost:9090/-/healthy" > /dev/null 2>&1; then
            log "SUCCESS" "Prometheus ì •ìƒ ë™ì‘"
            break
        else
            log "INFO" "Prometheus ëŒ€ê¸° ì¤‘... (ì‹œë„ $attempt/$max_attempts)"
            sleep 15
            attempt=$((attempt + 1))
        fi
    done
    
    if [ $attempt -gt $max_attempts ]; then
        log "WARNING" "Prometheus í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨"
    fi
    
    # Grafana í—¬ìŠ¤ì²´í¬
    attempt=1
    while [ $attempt -le $max_attempts ]; do
        if curl -sf "http://localhost:3000/api/health" > /dev/null 2>&1; then
            log "SUCCESS" "Grafana ì •ìƒ ë™ì‘"
            break
        else
            log "INFO" "Grafana ëŒ€ê¸° ì¤‘... (ì‹œë„ $attempt/$max_attempts)"
            sleep 15
            attempt=$((attempt + 1))
        fi
    done
    
    if [ $attempt -gt $max_attempts ]; then
        log "WARNING" "Grafana í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨"
    fi
    
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸
    log "INFO" "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸ ì¤‘..."
    sleep 30  # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ëŒ€ê¸°
    
    local targets_up=$(curl -s "http://localhost:9090/api/v1/query?query=up" | jq -r '.data.result | length')
    if [ "$targets_up" -gt 0 ]; then
        log "SUCCESS" "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì •ìƒ ($targets_up ê°œ íƒ€ê²Ÿ)"
    else
        log "WARNING" "ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ìƒíƒœ í™•ì¸ í•„ìš”"
    fi
    
    log "SUCCESS" "ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ"
}

# ë¡¤ë°± í•¨ìˆ˜
rollback_deployment() {
    log "HEADER" "${WARNING} ë°°í¬ ë¡¤ë°±"
    
    if [ -f "$DEPLOY_DIR/.last_backup" ]; then
        local backup_path=$(cat "$DEPLOY_DIR/.last_backup")
        
        if [ -d "$backup_path" ]; then
            log "INFO" "ë°±ì—…ì—ì„œ ë³µêµ¬ ì¤‘: $backup_path"
            
            # í˜„ì¬ ì„œë¹„ìŠ¤ ì¤‘ì§€
            cd "$DEPLOY_DIR"
            docker-compose down --timeout 30 || true
            
            # ë°±ì—… ë³µêµ¬
            if [ -f "$backup_path/docker-compose.yml" ]; then
                cp "$backup_path/docker-compose.yml" "$DEPLOY_DIR/"
                log "SUCCESS" "Docker Compose ì„¤ì • ë³µêµ¬ë¨"
            fi
            
            if [ -f "$backup_path/.env" ]; then
                cp "$backup_path/.env" "$DEPLOY_DIR/"
                log "SUCCESS" "í™˜ê²½ ë³€ìˆ˜ ë³µêµ¬ë¨"
            fi
            
            # ì´ì „ ì„œë¹„ìŠ¤ ì‹œì‘
            docker-compose up -d
            
            # ë³µêµ¬ í™•ì¸
            sleep 30
            if curl -sf "http://localhost:8000/health" > /dev/null 2>&1; then
                log "SUCCESS" "ë¡¤ë°± ì™„ë£Œ, ì„œë¹„ìŠ¤ ì •ìƒ ë™ì‘"
            else
                log "ERROR" "ë¡¤ë°± í›„ì—ë„ ì„œë¹„ìŠ¤ ì´ìƒ"
            fi
        else
            log "ERROR" "ë°±ì—… ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $backup_path"
        fi
    else
        log "ERROR" "ë°±ì—… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    fi
}

# ë°°í¬ í›„ ì •ë¦¬
post_deployment_cleanup() {
    log "HEADER" "${GEAR} ë°°í¬ í›„ ì •ë¦¬"
    
    # ì˜¤ë˜ëœ Docker ì´ë¯¸ì§€ ì •ë¦¬
    log "INFO" "ì˜¤ë˜ëœ Docker ì´ë¯¸ì§€ ì •ë¦¬ ì¤‘..."
    docker image prune -f --filter "until=72h"
    
    # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ (7ì¼ ì´ìƒ)
    log "INFO" "ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬ ì¤‘..."
    find "$BACKUP_DIR" -type d -name "backup_*" -mtime +7 -exec rm -rf {} \; 2>/dev/null || true
    
    # ì˜¤ë˜ëœ ë¡œê·¸ ì •ë¦¬ (30ì¼ ì´ìƒ)
    log "INFO" "ì˜¤ë˜ëœ ë¡œê·¸ ì •ë¦¬ ì¤‘..."
    find /var/log -name "deploy_*.log" -mtime +30 -delete 2>/dev/null || true
    
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¶œë ¥
    log "INFO" "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í˜„í™©:"
    echo "CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')% ì‚¬ìš©ì¤‘"
    echo "ë©”ëª¨ë¦¬: $(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')% ì‚¬ìš©ì¤‘"
    echo "ë””ìŠ¤í¬: $(df -h /app | tail -1 | awk '{print $5}') ì‚¬ìš©ì¤‘"
    echo "Docker ì´ë¯¸ì§€: $(docker images | wc -l)ê°œ"
    echo "ì‹¤í–‰ ì¤‘ì¸ ì»¨í…Œì´ë„ˆ: $(docker ps | wc -l)ê°œ"
    
    log "SUCCESS" "ë°°í¬ í›„ ì •ë¦¬ ì™„ë£Œ"
}

# ë°°í¬ ë¦¬í¬íŠ¸ ìƒì„±
generate_deployment_report() {
    log "HEADER" "${CHART} ë°°í¬ ë¦¬í¬íŠ¸ ìƒì„±"
    
    local report_file="/tmp/deployment_report_$(date +%Y%m%d_%H%M%S).json"
    
    cat <<EOF > "$report_file"
{
    "deployment_info": {
        "timestamp": "$(date -u +'%Y-%m-%dT%H:%M:%SZ')",
        "environment": "$ENVIRONMENT",
        "project_name": "$PROJECT_NAME",
        "image_tag": "$IMAGE_TAG",
        "deployed_by": "$(whoami)",
        "deployment_duration": "$(($(date +%s) - ${DEPLOY_START_TIME:-$(date +%s)})) seconds"
    },
    "services": {
        "backend_instances": 3,
        "worker_instances": 1,
        "monitoring": {
            "prometheus": "$(curl -sf http://localhost:9090/-/healthy && echo 'healthy' || echo 'unhealthy')",
            "grafana": "$(curl -sf http://localhost:3000/api/health && echo 'healthy' || echo 'unhealthy')"
        }
    },
    "health_check": {
        "api_response_time": "$(curl -w '%{time_total}' -s -o /dev/null http://localhost:8000/health)s",
        "all_services_healthy": true
    },
    "system_resources": {
        "cpu_usage": "$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')%",
        "memory_usage": "$(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')%",
        "disk_usage": "$(df -h /app | tail -1 | awk '{print $5}')"
    }
}
EOF
    
    log "SUCCESS" "ë°°í¬ ë¦¬í¬íŠ¸ ìƒì„±ë¨: $report_file"
    
    # ë¦¬í¬íŠ¸ ìš”ì•½ ì¶œë ¥
    echo
    log "HEADER" "${ROCKET} ë°°í¬ ì™„ë£Œ ìš”ì•½"
    echo -e "${GREEN}âœ… ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬ ì„±ê³µ!${NC}"
    echo
    echo -e "${WHITE}ğŸ¯ ë°°í¬ ì •ë³´:${NC}"
    echo -e "  í™˜ê²½: ${CYAN}$ENVIRONMENT${NC}"
    echo -e "  ì´ë¯¸ì§€: ${CYAN}$ECR_REGISTRY/$PROJECT_NAME/backend:$IMAGE_TAG${NC}"
    echo -e "  ì„œë¹„ìŠ¤: ${GREEN}3ê°œ ë°±ì—”ë“œ + 1ê°œ ì›Œì»¤${NC}"
    echo
    echo -e "${WHITE}ğŸ”— ì ‘ì† ì •ë³´:${NC}"
    echo -e "  API: ${BLUE}http://localhost:8000${NC}"
    echo -e "  Prometheus: ${BLUE}http://localhost:9090${NC}"
    echo -e "  Grafana: ${BLUE}http://localhost:3000${NC} (admin/admin)"
    echo
    echo -e "${WHITE}ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:${NC}"
    echo -e "  CPU: ${GREEN}$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')%${NC}"
    echo -e "  ë©”ëª¨ë¦¬: ${GREEN}$(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')%${NC}"
    echo -e "  ë””ìŠ¤í¬: ${GREEN}$(df -h /app | tail -1 | awk '{print $5}')${NC}"
    echo
    echo -e "${WHITE}ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:${NC}"
    echo -e "  1. ${YELLOW}ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰${NC}"
    echo -e "  2. ${YELLOW}ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰${NC}"
    echo -e "  3. ${YELLOW}ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì‹¤í–‰${NC}"
    echo -e "  4. ${YELLOW}í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¹ì¸${NC}"
    echo
}

# ë©”ì¸ ë°°í¬ ì‹¤í–‰
main() {
    local DEPLOY_START_TIME=$(date +%s)
    
    # ë°°í¬ ë‹¨ê³„ ì‹¤í–‰
    check_prerequisites
    create_backup
    prepare_images
    setup_environment
    setup_monitoring
    deploy_services
    verify_deployment
    verify_monitoring
    post_deployment_cleanup
    generate_deployment_report
    
    log "SUCCESS" "ğŸ‰ ìŠ¤í…Œì´ì§• í™˜ê²½ ë°°í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi