#!/usr/bin/env python3
"""
ğŸ—„ï¸ AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
ìŠ¤í…Œì´ì§• í™˜ê²½ DocumentDB í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” ë° ìµœì í™”

ê¸°ëŠ¥:
- MongoDB ìŠ¤í‚¤ë§ˆ ë° ì¸ë±ìŠ¤ ìƒì„±
- ì„±ëŠ¥ ìµœì í™”ëœ ì¸ë±ìŠ¤ êµ¬ì„±
- ì´ˆê¸° ë°ì´í„° ì‹œë”©
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
"""

import asyncio
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import motor.motor_asyncio
from pymongo import ASCENDING, DESCENDING, TEXT, GEO2D
from pymongo.errors import DuplicateKeyError, OperationFailure
import bcrypt

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class IndexDefinition:
    """ì¸ë±ìŠ¤ ì •ì˜"""
    collection: str
    fields: List[tuple]
    name: str
    unique: bool = False
    sparse: bool = False
    background: bool = True

@dataclass
class MigrationResult:
    """ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼"""
    collection: str
    operation: str
    status: str
    duration_ms: float
    details: str

class DatabaseMigrator:
    """ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬ì"""
    
    def __init__(self, connection_string: str):
        self.connection_string = connection_string
        self.client = None
        self.db = None
        self.migration_results: List[MigrationResult] = []
        
    async def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            self.client = motor.motor_asyncio.AsyncIOMotorClient(self.connection_string)
            self.db = self.client.online_evaluation
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.client.admin.command('ping')
            logger.info("âœ… DocumentDB ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    async def disconnect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ"""
        if self.client:
            self.client.close()
            logger.info("ğŸ”Œ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ")
    
    def _define_optimized_indexes(self) -> List[IndexDefinition]:
        """ì„±ëŠ¥ ìµœì í™”ëœ ì¸ë±ìŠ¤ ì •ì˜"""
        return [
            # ì‚¬ìš©ì ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="users",
                fields=[("login_id", ASCENDING)],
                name="idx_users_login_id",
                unique=True
            ),
            IndexDefinition(
                collection="users",
                fields=[("email", ASCENDING)],
                name="idx_users_email",
                unique=True
            ),
            IndexDefinition(
                collection="users",
                fields=[("role", ASCENDING), ("company_id", ASCENDING)],
                name="idx_users_role_company"
            ),
            IndexDefinition(
                collection="users",
                fields=[("created_at", DESCENDING)],
                name="idx_users_created_at"
            ),
            
            # íšŒì‚¬ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="companies",
                fields=[("name", ASCENDING)],
                name="idx_companies_name",
                unique=True
            ),
            IndexDefinition(
                collection="companies",
                fields=[("created_at", DESCENDING)],
                name="idx_companies_created_at"
            ),
            
            # í”„ë¡œì íŠ¸ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="projects",
                fields=[("company_id", ASCENDING), ("name", ASCENDING)],
                name="idx_projects_company_name"
            ),
            IndexDefinition(
                collection="projects",
                fields=[("status", ASCENDING), ("created_at", DESCENDING)],
                name="idx_projects_status_created"
            ),
            IndexDefinition(
                collection="projects",
                fields=[("manager_id", ASCENDING)],
                name="idx_projects_manager"
            ),
            
            # í…œí”Œë¦¿ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="templates",
                fields=[("company_id", ASCENDING), ("name", ASCENDING)],
                name="idx_templates_company_name"
            ),
            IndexDefinition(
                collection="templates",
                fields=[("category", ASCENDING), ("is_active", ASCENDING)],
                name="idx_templates_category_active"
            ),
            IndexDefinition(
                collection="templates",
                fields=[("created_by", ASCENDING), ("created_at", DESCENDING)],
                name="idx_templates_created_by_date"
            ),
            
            # í‰ê°€ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="evaluations",
                fields=[("project_id", ASCENDING), ("evaluator_id", ASCENDING)],
                name="idx_evaluations_project_evaluator"
            ),
            IndexDefinition(
                collection="evaluations",
                fields=[("status", ASCENDING), ("submitted_at", DESCENDING)],
                name="idx_evaluations_status_submitted"
            ),
            IndexDefinition(
                collection="evaluations",
                fields=[("company_id", ASCENDING), ("created_at", DESCENDING)],
                name="idx_evaluations_company_created"
            ),
            IndexDefinition(
                collection="evaluations",
                fields=[("total_score", DESCENDING)],
                name="idx_evaluations_total_score"
            ),
            
            # íŒŒì¼ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="files",
                fields=[("company_id", ASCENDING), ("file_type", ASCENDING)],
                name="idx_files_company_type"
            ),
            IndexDefinition(
                collection="files",
                fields=[("uploaded_by", ASCENDING), ("uploaded_at", DESCENDING)],
                name="idx_files_uploaded_by_date"
            ),
            IndexDefinition(
                collection="files",
                fields=[("file_hash", ASCENDING)],
                name="idx_files_hash",
                unique=True
            ),
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤
            IndexDefinition(
                collection="templates",
                fields=[("name", TEXT), ("description", TEXT)],
                name="idx_templates_text_search"
            ),
            IndexDefinition(
                collection="projects",
                fields=[("name", TEXT), ("description", TEXT)],
                name="idx_projects_text_search"
            )
        ]
    
    async def create_collections_and_indexes(self) -> Dict[str, Any]:
        """ì»¬ë ‰ì…˜ ë° ì¸ë±ìŠ¤ ìƒì„±"""
        logger.info("ğŸ—‚ï¸ ì»¬ë ‰ì…˜ ë° ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘")
        
        collections = ["users", "companies", "projects", "templates", "evaluations", "files"]
        index_definitions = self._define_optimized_indexes()
        
        results = {
            "collections_created": [],
            "indexes_created": [],
            "errors": []
        }
        
        # ì»¬ë ‰ì…˜ ìƒì„±
        for collection_name in collections:
            try:
                start_time = datetime.now()
                
                # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
                if collection_name not in await self.db.list_collection_names():
                    await self.db.create_collection(collection_name)
                    duration = (datetime.now() - start_time).total_seconds() * 1000
                    
                    result = MigrationResult(
                        collection=collection_name,
                        operation="create_collection",
                        status="success",
                        duration_ms=duration,
                        details=f"ì»¬ë ‰ì…˜ {collection_name} ìƒì„± ì™„ë£Œ"
                    )
                    self.migration_results.append(result)
                    results["collections_created"].append(collection_name)
                    logger.info(f"âœ… ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
                else:
                    logger.info(f"âš ï¸ ì»¬ë ‰ì…˜ ì´ë¯¸ ì¡´ì¬: {collection_name}")
                    
            except Exception as e:
                error_msg = f"ì»¬ë ‰ì…˜ {collection_name} ìƒì„± ì‹¤íŒ¨: {e}"
                results["errors"].append(error_msg)
                logger.error(f"âŒ {error_msg}")
        
        # ì¸ë±ìŠ¤ ìƒì„±
        for index_def in index_definitions:
            try:
                start_time = datetime.now()
                collection = self.db[index_def.collection]
                
                # ì¸ë±ìŠ¤ ìƒì„± ì˜µì…˜
                index_options = {
                    "name": index_def.name,
                    "unique": index_def.unique,
                    "sparse": index_def.sparse,
                    "background": index_def.background
                }
                
                # ì¸ë±ìŠ¤ ìƒì„±
                await collection.create_index(
                    index_def.fields,
                    **index_options
                )
                
                duration = (datetime.now() - start_time).total_seconds() * 1000
                
                result = MigrationResult(
                    collection=index_def.collection,
                    operation="create_index",
                    status="success",
                    duration_ms=duration,
                    details=f"ì¸ë±ìŠ¤ {index_def.name} ìƒì„± ì™„ë£Œ"
                )
                self.migration_results.append(result)
                results["indexes_created"].append(index_def.name)
                logger.info(f"âœ… ì¸ë±ìŠ¤ ìƒì„±: {index_def.name} on {index_def.collection}")
                
            except DuplicateKeyError:
                logger.info(f"âš ï¸ ì¸ë±ìŠ¤ ì´ë¯¸ ì¡´ì¬: {index_def.name}")
            except Exception as e:
                error_msg = f"ì¸ë±ìŠ¤ {index_def.name} ìƒì„± ì‹¤íŒ¨: {e}"
                results["errors"].append(error_msg)
                logger.error(f"âŒ {error_msg}")
        
        logger.info("âœ… ì»¬ë ‰ì…˜ ë° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
        return results
    
    async def seed_initial_data(self) -> Dict[str, Any]:
        """ì´ˆê¸° ë°ì´í„° ì‹œë”©"""
        logger.info("ğŸŒ± ì´ˆê¸° ë°ì´í„° ì‹œë”© ì‹œì‘")
        
        results = {
            "data_seeded": [],
            "errors": []
        }
        
        try:
            # 1. ì‹œìŠ¤í…œ ê´€ë¦¬ì ìƒì„±
            admin_data = await self._create_system_admin()
            if admin_data:
                results["data_seeded"].append("system_admin")
                logger.info("âœ… ì‹œìŠ¤í…œ ê´€ë¦¬ì ìƒì„± ì™„ë£Œ")
            
            # 2. ê¸°ë³¸ íšŒì‚¬ ìƒì„±
            company_data = await self._create_default_companies()
            if company_data:
                results["data_seeded"].extend(company_data)
                logger.info("âœ… ê¸°ë³¸ íšŒì‚¬ ë°ì´í„° ìƒì„± ì™„ë£Œ")
            
            # 3. ìƒ˜í”Œ í…œí”Œë¦¿ ìƒì„±
            template_data = await self._create_sample_templates()
            if template_data:
                results["data_seeded"].extend(template_data)
                logger.info("âœ… ìƒ˜í”Œ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
            
            # 4. í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„±
            user_data = await self._create_test_users()
            if user_data:
                results["data_seeded"].extend(user_data)
                logger.info("âœ… í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„± ì™„ë£Œ")
                
        except Exception as e:
            error_msg = f"ì´ˆê¸° ë°ì´í„° ì‹œë”© ì‹¤íŒ¨: {e}"
            results["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
        
        logger.info("âœ… ì´ˆê¸° ë°ì´í„° ì‹œë”© ì™„ë£Œ")
        return results
    
    async def _create_system_admin(self) -> Optional[str]:
        """ì‹œìŠ¤í…œ ê´€ë¦¬ì ìƒì„±"""
        try:
            # ê´€ë¦¬ìê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing_admin = await self.db.users.find_one({"login_id": "admin"})
            if existing_admin:
                logger.info("âš ï¸ ì‹œìŠ¤í…œ ê´€ë¦¬ì ì´ë¯¸ ì¡´ì¬")
                return None
            
            # ë¹„ë°€ë²ˆí˜¸ í•´ì‹±
            password_hash = bcrypt.hashpw("admin123!".encode('utf-8'), bcrypt.gensalt())
            
            admin_user = {
                "_id": "admin_001",
                "login_id": "admin",
                "name": "ì‹œìŠ¤í…œ ê´€ë¦¬ì",
                "email": "admin@system.com",
                "password_hash": password_hash.decode('utf-8'),
                "role": "admin",
                "company_id": "system",
                "is_active": True,
                "created_at": datetime.utcnow(),
                "updated_at": datetime.utcnow(),
                "last_login": None,
                "login_attempts": 0,
                "profile": {
                    "phone": "010-0000-0000",
                    "department": "ì‹œìŠ¤í…œ",
                    "position": "ê´€ë¦¬ì"
                }
            }
            
            await self.db.users.insert_one(admin_user)
            return "admin_user"
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ê´€ë¦¬ì ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    async def _create_default_companies(self) -> List[str]:
        """ê¸°ë³¸ íšŒì‚¬ ìƒì„±"""
        try:
            companies = [
                {
                    "_id": "company_001",
                    "name": "ì‹œìŠ¤í…œ íšŒì‚¬",
                    "business_number": "000-00-00000",
                    "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬",
                    "contact_email": "contact@system.com",
                    "contact_phone": "02-0000-0000",
                    "is_active": True,
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow(),
                    "settings": {
                        "max_users": 1000,
                        "max_projects": 100,
                        "storage_limit_gb": 10
                    }
                },
                {
                    "_id": "company_002", 
                    "name": "í…ŒìŠ¤íŠ¸ íšŒì‚¬",
                    "business_number": "111-11-11111",
                    "address": "ì„œìš¸ì‹œ ì„œì´ˆêµ¬",
                    "contact_email": "test@company.com",
                    "contact_phone": "02-1111-1111",
                    "is_active": True,
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow(),
                    "settings": {
                        "max_users": 50,
                        "max_projects": 20,
                        "storage_limit_gb": 5
                    }
                }
            ]
            
            created_companies = []
            for company in companies:
                try:
                    # íšŒì‚¬ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    existing = await self.db.companies.find_one({"name": company["name"]})
                    if not existing:
                        await self.db.companies.insert_one(company)
                        created_companies.append(f"company_{company['name']}")
                        logger.info(f"âœ… íšŒì‚¬ ìƒì„±: {company['name']}")
                    else:
                        logger.info(f"âš ï¸ íšŒì‚¬ ì´ë¯¸ ì¡´ì¬: {company['name']}")
                except Exception as e:
                    logger.error(f"âŒ íšŒì‚¬ ìƒì„± ì‹¤íŒ¨ {company['name']}: {e}")
            
            return created_companies
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ íšŒì‚¬ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def _create_sample_templates(self) -> List[str]:
        """ìƒ˜í”Œ í…œí”Œë¦¿ ìƒì„±"""
        try:
            templates = [
                {
                    "_id": "template_001",
                    "name": "ê¸°ë³¸ í‰ê°€ í…œí”Œë¦¿",
                    "description": "ì¼ë°˜ì ì¸ í‰ê°€ë¥¼ ìœ„í•œ ê¸°ë³¸ í…œí”Œë¦¿",
                    "company_id": "company_001",
                    "category": "general",
                    "criteria": [
                        {
                            "id": "quality",
                            "name": "í’ˆì§ˆ",
                            "description": "ì‘ì—…ì˜ ì „ë°˜ì ì¸ í’ˆì§ˆ",
                            "weight": 30,
                            "max_score": 100
                        },
                        {
                            "id": "efficiency",
                            "name": "íš¨ìœ¨ì„±",
                            "description": "ì‘ì—…ì˜ íš¨ìœ¨ì„±ê³¼ ì†ë„",
                            "weight": 25,
                            "max_score": 100
                        },
                        {
                            "id": "creativity",
                            "name": "ì°½ì˜ì„±",
                            "description": "ì°½ì˜ì  ì ‘ê·¼ê³¼ í˜ì‹ ì„±",
                            "weight": 20,
                            "max_score": 100
                        },
                        {
                            "id": "communication",
                            "name": "ì†Œí†µ",
                            "description": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥",
                            "weight": 15,
                            "max_score": 100
                        },
                        {
                            "id": "teamwork",
                            "name": "íŒ€ì›Œí¬",
                            "description": "íŒ€ í˜‘ë ¥ ëŠ¥ë ¥",
                            "weight": 10,
                            "max_score": 100
                        }
                    ],
                    "is_active": True,
                    "created_by": "admin_001",
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow()
                },
                {
                    "_id": "template_002",
                    "name": "AI ëª¨ë¸ í‰ê°€ í…œí”Œë¦¿",
                    "description": "AI ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ ì „ë¬¸ í…œí”Œë¦¿",
                    "company_id": "company_001",
                    "category": "ai_model",
                    "criteria": [
                        {
                            "id": "accuracy",
                            "name": "ì •í™•ë„",
                            "description": "ëª¨ë¸ ì˜ˆì¸¡ ì •í™•ë„",
                            "weight": 40,
                            "max_score": 100
                        },
                        {
                            "id": "performance",
                            "name": "ì„±ëŠ¥",
                            "description": "ì²˜ë¦¬ ì†ë„ ë° ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±",
                            "weight": 30,
                            "max_score": 100
                        },
                        {
                            "id": "robustness",
                            "name": "ê²¬ê³ ì„±",
                            "description": "ë‹¤ì–‘í•œ ì…ë ¥ì— ëŒ€í•œ ì•ˆì •ì„±",
                            "weight": 20,
                            "max_score": 100
                        },
                        {
                            "id": "interpretability",
                            "name": "í•´ì„ê°€ëŠ¥ì„±",
                            "description": "ëª¨ë¸ ê²°ê³¼ì˜ í•´ì„ ìš©ì´ì„±",
                            "weight": 10,
                            "max_score": 100
                        }
                    ],
                    "is_active": True,
                    "created_by": "admin_001",
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow()
                }
            ]
            
            created_templates = []
            for template in templates:
                try:
                    # í…œí”Œë¦¿ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    existing = await self.db.templates.find_one({"name": template["name"]})
                    if not existing:
                        await self.db.templates.insert_one(template)
                        created_templates.append(f"template_{template['name']}")
                        logger.info(f"âœ… í…œí”Œë¦¿ ìƒì„±: {template['name']}")
                    else:
                        logger.info(f"âš ï¸ í…œí”Œë¦¿ ì´ë¯¸ ì¡´ì¬: {template['name']}")
                except Exception as e:
                    logger.error(f"âŒ í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨ {template['name']}: {e}")
            
            return created_templates
            
        except Exception as e:
            logger.error(f"âŒ ìƒ˜í”Œ í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def _create_test_users(self) -> List[str]:
        """í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„±"""
        try:
            # ë¹„ë°€ë²ˆí˜¸ í•´ì‹±
            password_hash = bcrypt.hashpw("test123!".encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
            
            users = [
                {
                    "_id": "user_001",
                    "login_id": "manager1",
                    "name": "ê¹€ë§¤ë‹ˆì €",
                    "email": "manager1@test.com",
                    "password_hash": password_hash,
                    "role": "manager",
                    "company_id": "company_002",
                    "is_active": True,
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow(),
                    "profile": {
                        "phone": "010-1234-5678",
                        "department": "ê°œë°œíŒ€",
                        "position": "íŒ€ì¥"
                    }
                },
                {
                    "_id": "user_002",
                    "login_id": "evaluator1",
                    "name": "ì´í‰ê°€ì",
                    "email": "evaluator1@test.com",
                    "password_hash": password_hash,
                    "role": "evaluator",
                    "company_id": "company_002",
                    "is_active": True,
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow(),
                    "profile": {
                        "phone": "010-2345-6789",
                        "department": "QAíŒ€",
                        "position": "ìˆ˜ì„ì—°êµ¬ì›"
                    }
                },
                {
                    "_id": "user_003",
                    "login_id": "secretary1",
                    "name": "ë°•ê°„ì‚¬",
                    "email": "secretary1@test.com",
                    "password_hash": password_hash,
                    "role": "secretary",
                    "company_id": "company_002",
                    "is_active": True,
                    "created_at": datetime.utcnow(),
                    "updated_at": datetime.utcnow(),
                    "profile": {
                        "phone": "010-3456-7890",
                        "department": "ê²½ì˜ì§€ì›íŒ€",
                        "position": "ëŒ€ë¦¬"
                    }
                }
            ]
            
            created_users = []
            for user in users:
                try:
                    # ì‚¬ìš©ìê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                    existing = await self.db.users.find_one({"login_id": user["login_id"]})
                    if not existing:
                        await self.db.users.insert_one(user)
                        created_users.append(f"user_{user['login_id']}")
                        logger.info(f"âœ… ì‚¬ìš©ì ìƒì„±: {user['login_id']}")
                    else:
                        logger.info(f"âš ï¸ ì‚¬ìš©ì ì´ë¯¸ ì¡´ì¬: {user['login_id']}")
                except Exception as e:
                    logger.error(f"âŒ ì‚¬ìš©ì ìƒì„± ì‹¤íŒ¨ {user['login_id']}: {e}")
            
            return created_users
            
        except Exception as e:
            logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    async def verify_data_integrity(self) -> Dict[str, Any]:
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        logger.info("ğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘")
        
        verification_results = {
            "collection_counts": {},
            "index_verification": {},
            "data_integrity_checks": [],
            "errors": []
        }
        
        try:
            # 1. ì»¬ë ‰ì…˜ë³„ ë¬¸ì„œ ìˆ˜ í™•ì¸
            collections = ["users", "companies", "projects", "templates", "evaluations", "files"]
            for collection_name in collections:
                count = await self.db[collection_name].count_documents({})
                verification_results["collection_counts"][collection_name] = count
                logger.info(f"ğŸ“Š {collection_name}: {count}ê°œ ë¬¸ì„œ")
            
            # 2. ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
            index_definitions = self._define_optimized_indexes()
            for index_def in index_definitions:
                try:
                    collection = self.db[index_def.collection]
                    indexes = await collection.list_indexes().to_list(length=None)
                    index_names = [idx["name"] for idx in indexes]
                    
                    exists = index_def.name in index_names
                    verification_results["index_verification"][index_def.name] = exists
                    
                    if exists:
                        logger.info(f"âœ… ì¸ë±ìŠ¤ í™•ì¸: {index_def.name}")
                    else:
                        logger.warning(f"âš ï¸ ì¸ë±ìŠ¤ ëˆ„ë½: {index_def.name}")
                        
                except Exception as e:
                    error_msg = f"ì¸ë±ìŠ¤ í™•ì¸ ì‹¤íŒ¨ {index_def.name}: {e}"
                    verification_results["errors"].append(error_msg)
                    logger.error(f"âŒ {error_msg}")
            
            # 3. ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
            integrity_checks = [
                await self._check_user_data_integrity(),
                await self._check_company_data_integrity(),
                await self._check_template_data_integrity()
            ]
            
            verification_results["data_integrity_checks"] = integrity_checks
            
            # 4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            performance_results = await self._run_performance_queries()
            verification_results["performance_test"] = performance_results
            
        except Exception as e:
            error_msg = f"ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {e}"
            verification_results["errors"].append(error_msg)
            logger.error(f"âŒ {error_msg}")
        
        logger.info("âœ… ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ")
        return verification_results
    
    async def _check_user_data_integrity(self) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        try:
            # ì¤‘ë³µ login_id ê²€ì‚¬
            pipeline = [
                {"$group": {"_id": "$login_id", "count": {"$sum": 1}}},
                {"$match": {"count": {"$gt": 1}}}
            ]
            duplicates = await self.db.users.aggregate(pipeline).to_list(length=None)
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë©”ì¼ ê²€ì‚¬
            invalid_emails = await self.db.users.count_documents({
                "email": {"$not": {"$regex": r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"}}
            })
            
            return {
                "check_name": "user_data_integrity",
                "duplicate_login_ids": len(duplicates),
                "invalid_emails": invalid_emails,
                "status": "pass" if len(duplicates) == 0 and invalid_emails == 0 else "warning"
            }
            
        except Exception as e:
            return {
                "check_name": "user_data_integrity",
                "status": "error",
                "error": str(e)
            }
    
    async def _check_company_data_integrity(self) -> Dict[str, Any]:
        """íšŒì‚¬ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        try:
            # ì¤‘ë³µ íšŒì‚¬ëª… ê²€ì‚¬
            pipeline = [
                {"$group": {"_id": "$name", "count": {"$sum": 1}}},
                {"$match": {"count": {"$gt": 1}}}
            ]
            duplicates = await self.db.companies.aggregate(pipeline).to_list(length=None)
            
            return {
                "check_name": "company_data_integrity", 
                "duplicate_company_names": len(duplicates),
                "status": "pass" if len(duplicates) == 0 else "warning"
            }
            
        except Exception as e:
            return {
                "check_name": "company_data_integrity",
                "status": "error",
                "error": str(e)
            }
    
    async def _check_template_data_integrity(self) -> Dict[str, Any]:
        """í…œí”Œë¦¿ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        try:
            # ê°€ì¤‘ì¹˜ í•©ê³„ê°€ 100ì´ ì•„ë‹Œ í…œí”Œë¦¿ ê²€ì‚¬
            templates = await self.db.templates.find({}).to_list(length=None)
            invalid_weights = []
            
            for template in templates:
                total_weight = sum(criterion.get("weight", 0) for criterion in template.get("criteria", []))
                if total_weight != 100:
                    invalid_weights.append(template["_id"])
            
            return {
                "check_name": "template_data_integrity",
                "invalid_weight_templates": len(invalid_weights),
                "status": "pass" if len(invalid_weights) == 0 else "warning"
            }
            
        except Exception as e:
            return {
                "check_name": "template_data_integrity",
                "status": "error",
                "error": str(e)
            }
    
    async def _run_performance_queries(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            performance_results = {}
            
            # 1. ì‚¬ìš©ì ì¡°íšŒ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            start_time = datetime.now()
            await self.db.users.find_one({"login_id": "admin"})
            user_query_time = (datetime.now() - start_time).total_seconds() * 1000
            performance_results["user_lookup_ms"] = user_query_time
            
            # 2. íšŒì‚¬ë³„ ì‚¬ìš©ì ìˆ˜ ì§‘ê³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            start_time = datetime.now()
            pipeline = [
                {"$group": {"_id": "$company_id", "user_count": {"$sum": 1}}}
            ]
            await self.db.users.aggregate(pipeline).to_list(length=None)
            aggregation_time = (datetime.now() - start_time).total_seconds() * 1000
            performance_results["user_aggregation_ms"] = aggregation_time
            
            # 3. í…œí”Œë¦¿ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            start_time = datetime.now()
            await self.db.templates.find({"$text": {"$search": "í‰ê°€"}}).to_list(length=10)
            text_search_time = (datetime.now() - start_time).total_seconds() * 1000
            performance_results["text_search_ms"] = text_search_time
            
            return {
                "status": "success",
                "queries": performance_results,
                "average_query_time": sum(performance_results.values()) / len(performance_results)
            }
            
        except Exception as e:
            return {
                "status": "error",
                "error": str(e)
            }
    
    async def generate_migration_report(self) -> Dict[str, Any]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±")
        
        # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
        total_operations = len(self.migration_results)
        successful_operations = len([r for r in self.migration_results if r.status == "success"])
        
        # í‰ê·  ì‹¤í–‰ ì‹œê°„
        avg_duration = sum(r.duration_ms for r in self.migration_results) / total_operations if total_operations > 0 else 0
        
        # ì»¬ë ‰ì…˜ë³„ í†µê³„
        collection_stats = {}
        for result in self.migration_results:
            if result.collection not in collection_stats:
                collection_stats[result.collection] = {"operations": 0, "avg_duration": 0}
            collection_stats[result.collection]["operations"] += 1
        
        report = {
            "migration_summary": {
                "timestamp": datetime.now().isoformat(),
                "total_operations": total_operations,
                "successful_operations": successful_operations,
                "success_rate": (successful_operations / total_operations * 100) if total_operations > 0 else 0,
                "average_duration_ms": avg_duration
            },
            "detailed_results": [
                {
                    "collection": r.collection,
                    "operation": r.operation,
                    "status": r.status,
                    "duration_ms": r.duration_ms,
                    "details": r.details
                }
                for r in self.migration_results
            ],
            "collection_statistics": collection_stats,
            "recommendations": [
                "ì •ê¸°ì ì¸ ì¸ë±ìŠ¤ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìˆ˜í–‰",
                "ë°ì´í„° ì¦ê°€ì— ë”°ë¥¸ ì¸ë±ìŠ¤ ìµœì í™” ê²€í† ",
                "ë°±ì—… ë° ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ ì •ê¸° í…ŒìŠ¤íŠ¸",
                "ì„±ëŠ¥ ì €í•˜ ì‹œ ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„"
            ]
        }
        
        return report

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    mongo_url = os.getenv('MONGO_URL', 'mongodb://admin:password123@localhost:27017/online_evaluation')
    
    migrator = DatabaseMigrator(mongo_url)
    
    try:
        print("ğŸ—„ï¸ AI ëª¨ë¸ ê´€ë¦¬ ì‹œìŠ¤í…œ - ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜")
        print("ìŠ¤í…Œì´ì§• í™˜ê²½ DocumentDB ì´ˆê¸°í™” ì‹œì‘\n")
        
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        await migrator.connect()
        
        # 2. ì»¬ë ‰ì…˜ ë° ì¸ë±ìŠ¤ ìƒì„±
        print("ğŸ—ï¸ ì»¬ë ‰ì…˜ ë° ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        schema_results = await migrator.create_collections_and_indexes()
        print(f"âœ… ì»¬ë ‰ì…˜ {len(schema_results['collections_created'])}ê°œ, ì¸ë±ìŠ¤ {len(schema_results['indexes_created'])}ê°œ ìƒì„±")
        
        # 3. ì´ˆê¸° ë°ì´í„° ì‹œë”©
        print("\nğŸŒ± ì´ˆê¸° ë°ì´í„° ì‹œë”© ì¤‘...")
        seed_results = await migrator.seed_initial_data()
        print(f"âœ… ë°ì´í„° í•­ëª© {len(seed_results['data_seeded'])}ê°œ ìƒì„±")
        
        # 4. ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        print("\nğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
        verification_results = await migrator.verify_data_integrity()
        print(f"âœ… ë¬´ê²°ì„± ê²€ì‚¬ ì™„ë£Œ - í‰ê·  ì¿¼ë¦¬ ì‹œê°„: {verification_results['performance_test']['average_query_time']:.2f}ms")
        
        # 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ìƒì„±
        report = await migrator.generate_migration_report()
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = f"/tmp/database_migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
        print("="*60)
        print(f"ğŸ—ï¸ ì´ ì‘ì—…: {report['migration_summary']['total_operations']}ê°œ")
        print(f"âœ… ì„±ê³µë¥ : {report['migration_summary']['success_rate']:.1f}%")
        print(f"â±ï¸ í‰ê·  ì‹¤í–‰ì‹œê°„: {report['migration_summary']['average_duration_ms']:.1f}ms")
        
        # ì»¬ë ‰ì…˜ë³„ ë°ì´í„° ìˆ˜ ì¶œë ¥
        print(f"\nğŸ“Š ìƒì„±ëœ ë°ì´í„°:")
        for collection, count in verification_results["collection_counts"].items():
            print(f"  - {collection}: {count}ê°œ")
        
        print("\nğŸš€ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ!")
        
    except Exception as e:
        print(f"\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        raise
    finally:
        await migrator.disconnect()

if __name__ == "__main__":
    asyncio.run(main())